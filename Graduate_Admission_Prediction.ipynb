{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Admission_Predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         400 non-null    int64  \n",
      " 1   GRE Score          400 non-null    int64  \n",
      " 2   TOEFL Score        400 non-null    int64  \n",
      " 3   University Rating  400 non-null    int64  \n",
      " 4   SOP                400 non-null    float64\n",
      " 5   LOR                400 non-null    float64\n",
      " 6   CGPA               400 non-null    float64\n",
      " 7   Research           400 non-null    int64  \n",
      " 8   Chance of Admit    400 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 28.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['Serial No.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,0:-1]\n",
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "397        330          116                  4  5.0   4.5  9.45         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "399        333          117                  4  5.0   4.0  9.66         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "395    0.82\n",
       "396    0.84\n",
       "397    0.91\n",
       "398    0.67\n",
       "399    0.95\n",
       "Name: Chance of Admit , Length: 400, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2       , 0.35714286, 0.5       , ..., 0.375     , 0.43910256,\n",
       "        0.        ],\n",
       "       [0.88      , 1.        , 1.        , ..., 1.        , 0.98397436,\n",
       "        1.        ],\n",
       "       [0.82      , 0.82142857, 1.        , ..., 0.625     , 0.82051282,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.36      , 0.64285714, 0.5       , ..., 0.5       , 0.38461538,\n",
       "        1.        ],\n",
       "       [0.46      , 0.42857143, 0.5       , ..., 0.875     , 0.59294872,\n",
       "        0.        ],\n",
       "       [0.64      , 0.82142857, 1.        , ..., 0.875     , 0.82051282,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples, validate on 64 samples\n",
      "Epoch 1/100\n",
      "256/256 [==============================] - 0s 672us/sample - loss: 0.2567 - accuracy: 0.0000e+00 - val_loss: 0.1832 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "256/256 [==============================] - 0s 114us/sample - loss: 0.1340 - accuracy: 0.0000e+00 - val_loss: 0.0886 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "256/256 [==============================] - 0s 91us/sample - loss: 0.0631 - accuracy: 0.0000e+00 - val_loss: 0.0416 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "256/256 [==============================] - 0s 99us/sample - loss: 0.0316 - accuracy: 0.0000e+00 - val_loss: 0.0243 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "256/256 [==============================] - 0s 81us/sample - loss: 0.0212 - accuracy: 0.0000e+00 - val_loss: 0.0200 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "256/256 [==============================] - 0s 76us/sample - loss: 0.0191 - accuracy: 0.0000e+00 - val_loss: 0.0197 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "256/256 [==============================] - 0s 84us/sample - loss: 0.0191 - accuracy: 0.0000e+00 - val_loss: 0.0195 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "256/256 [==============================] - 0s 120us/sample - loss: 0.0186 - accuracy: 0.0000e+00 - val_loss: 0.0186 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "256/256 [==============================] - 0s 177us/sample - loss: 0.0177 - accuracy: 0.0000e+00 - val_loss: 0.0178 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "256/256 [==============================] - 0s 139us/sample - loss: 0.0170 - accuracy: 0.0000e+00 - val_loss: 0.0171 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "256/256 [==============================] - 0s 103us/sample - loss: 0.0164 - accuracy: 0.0000e+00 - val_loss: 0.0165 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "256/256 [==============================] - 0s 96us/sample - loss: 0.0159 - accuracy: 0.0000e+00 - val_loss: 0.0160 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "256/256 [==============================] - 0s 83us/sample - loss: 0.0154 - accuracy: 0.0000e+00 - val_loss: 0.0155 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "256/256 [==============================] - 0s 115us/sample - loss: 0.0149 - accuracy: 0.0000e+00 - val_loss: 0.0150 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "256/256 [==============================] - 0s 102us/sample - loss: 0.0144 - accuracy: 0.0000e+00 - val_loss: 0.0145 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "256/256 [==============================] - 0s 148us/sample - loss: 0.0139 - accuracy: 0.0000e+00 - val_loss: 0.0140 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "256/256 [==============================] - 0s 128us/sample - loss: 0.0134 - accuracy: 0.0000e+00 - val_loss: 0.0135 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "256/256 [==============================] - 0s 114us/sample - loss: 0.0129 - accuracy: 0.0000e+00 - val_loss: 0.0131 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "256/256 [==============================] - 0s 97us/sample - loss: 0.0125 - accuracy: 0.0000e+00 - val_loss: 0.0126 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "256/256 [==============================] - 0s 121us/sample - loss: 0.0121 - accuracy: 0.0000e+00 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "256/256 [==============================] - 0s 98us/sample - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "256/256 [==============================] - 0s 138us/sample - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "256/256 [==============================] - 0s 339us/sample - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "256/256 [==============================] - 0s 197us/sample - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.0000e+ - 0s 112us/sample - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "256/256 [==============================] - 0s 137us/sample - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "256/256 [==============================] - 0s 110us/sample - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "256/256 [==============================] - 0s 100us/sample - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "256/256 [==============================] - 0s 113us/sample - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "256/256 [==============================] - 0s 89us/sample - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "256/256 [==============================] - 0s 72us/sample - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "256/256 [==============================] - 0s 110us/sample - loss: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "256/256 [==============================] - 0s 93us/sample - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "256/256 [==============================] - 0s 104us/sample - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "256/256 [==============================] - 0s 88us/sample - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "256/256 [==============================] - 0s 88us/sample - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "256/256 [==============================] - 0s 89us/sample - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "256/256 [==============================] - 0s 119us/sample - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "256/256 [==============================] - 0s 84us/sample - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "256/256 [==============================] - 0s 79us/sample - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "256/256 [==============================] - 0s 55us/sample - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "256/256 [==============================] - 0s 78us/sample - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "256/256 [==============================] - 0s 98us/sample - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "256/256 [==============================] - 0s 82us/sample - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "256/256 [==============================] - 0s 77us/sample - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "256/256 [==============================] - 0s 83us/sample - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "256/256 [==============================] - 0s 94us/sample - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "256/256 [==============================] - 0s 73us/sample - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "256/256 [==============================] - 0s 81us/sample - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "256/256 [==============================] - 0s 63us/sample - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "256/256 [==============================] - 0s 83us/sample - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "256/256 [==============================] - 0s 88us/sample - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "256/256 [==============================] - 0s 70us/sample - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "256/256 [==============================] - 0s 87us/sample - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "256/256 [==============================] - 0s 87us/sample - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "256/256 [==============================] - 0s 255us/sample - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "256/256 [==============================] - 0s 186us/sample - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "256/256 [==============================] - 0s 69us/sample - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "256/256 [==============================] - 0s 88us/sample - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "256/256 [==============================] - 0s 70us/sample - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "256/256 [==============================] - 0s 83us/sample - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "256/256 [==============================] - 0s 87us/sample - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "256/256 [==============================] - 0s 98us/sample - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "256/256 [==============================] - 0s 71us/sample - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "256/256 [==============================] - 0s 70us/sample - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "256/256 [==============================] - 0s 68us/sample - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "256/256 [==============================] - 0s 63us/sample - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "256/256 [==============================] - 0s 76us/sample - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "256/256 [==============================] - 0s 83us/sample - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "256/256 [==============================] - 0s 86us/sample - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "256/256 [==============================] - 0s 75us/sample - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "256/256 [==============================] - 0s 80us/sample - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "256/256 [==============================] - 0s 116us/sample - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "256/256 [==============================] - 0s 89us/sample - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "256/256 [==============================] - 0s 81us/sample - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "256/256 [==============================] - 0s 98us/sample - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "256/256 [==============================] - 0s 94us/sample - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "256/256 [==============================] - 0s 73us/sample - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "256/256 [==============================] - 0s 80us/sample - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "256/256 [==============================] - 0s 79us/sample - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "256/256 [==============================] - 0s 71us/sample - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "256/256 [==============================] - 0s 72us/sample - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "256/256 [==============================] - 0s 71us/sample - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "256/256 [==============================] - 0s 68us/sample - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "256/256 [==============================] - 0s 72us/sample - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "256/256 [==============================] - 0s 214us/sample - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "256/256 [==============================] - 0s 192us/sample - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "256/256 [==============================] - 0s 80us/sample - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "256/256 [==============================] - 0s 118us/sample - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "256/256 [==============================] - 0s 80us/sample - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "256/256 [==============================] - 0s 75us/sample - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "256/256 [==============================] - 0s 82us/sample - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "256/256 [==============================] - 0s 76us/sample - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "256/256 [==============================] - 0s 73us/sample - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "256/256 [==============================] - 0s 79us/sample - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "256/256 [==============================] - 0s 68us/sample - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "256/256 [==============================] - 0s 72us/sample - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "256/256 [==============================] - 0s 76us/sample - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "256/256 [==============================] - 0s 79us/sample - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "256/256 [==============================] - 0s 84us/sample - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled,y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4308331492385784"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17fa9c33608>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finished"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
