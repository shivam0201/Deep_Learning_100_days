{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential,callbacks\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=make_moons(100, noise=0.25, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0],X[:,1],c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               384       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 17,025\n",
      "Trainable params: 17,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1=Sequential()\n",
    "\n",
    "model1.add(Dense(128, input_dim=2,activation='relu'))\n",
    "model1.add(Dense(128,activation='relu'))\n",
    "model1.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mishr\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/2000\n",
      "80/80 [==============================] - 0s 5ms/sample - loss: 0.5751 - accuracy: 0.7375 - val_loss: 0.5926 - val_accuracy: 0.7000\n",
      "Epoch 2/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2923 - accuracy: 0.9000 - val_loss: 0.8166 - val_accuracy: 0.6500\n",
      "Epoch 3/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.2234 - accuracy: 0.8875 - val_loss: 0.9476 - val_accuracy: 0.6000\n",
      "Epoch 4/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2427 - accuracy: 0.9125 - val_loss: 0.9736 - val_accuracy: 0.7000\n",
      "Epoch 5/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2081 - accuracy: 0.9250 - val_loss: 0.9418 - val_accuracy: 0.6000\n",
      "Epoch 6/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.2254 - accuracy: 0.9125 - val_loss: 0.9063 - val_accuracy: 0.6000\n",
      "Epoch 7/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.1960 - accuracy: 0.9375 - val_loss: 0.8059 - val_accuracy: 0.7000\n",
      "Epoch 8/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.1854 - accuracy: 0.9125 - val_loss: 0.7905 - val_accuracy: 0.7000\n",
      "Epoch 9/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.1879 - accuracy: 0.9000 - val_loss: 0.7792 - val_accuracy: 0.7000\n",
      "Epoch 10/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.1790 - accuracy: 0.9125 - val_loss: 0.7768 - val_accuracy: 0.7000\n",
      "Epoch 11/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.1742 - accuracy: 0.9250 - val_loss: 0.7843 - val_accuracy: 0.6500\n",
      "Epoch 12/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.1659 - accuracy: 0.9375 - val_loss: 0.7564 - val_accuracy: 0.7000\n",
      "Epoch 13/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.1586 - accuracy: 0.9375 - val_loss: 0.7417 - val_accuracy: 0.7000\n",
      "Epoch 14/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.1544 - accuracy: 0.9375 - val_loss: 0.7532 - val_accuracy: 0.7000\n",
      "Epoch 15/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.1471 - accuracy: 0.9375 - val_loss: 0.7848 - val_accuracy: 0.7000\n",
      "Epoch 16/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1433 - accuracy: 0.9375 - val_loss: 0.8084 - val_accuracy: 0.7500\n",
      "Epoch 17/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.1375 - accuracy: 0.9250 - val_loss: 0.7940 - val_accuracy: 0.7500\n",
      "Epoch 18/2000\n",
      "80/80 [==============================] - 0s 175us/sample - loss: 0.1364 - accuracy: 0.9375 - val_loss: 0.7797 - val_accuracy: 0.7500\n",
      "Epoch 19/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.1255 - accuracy: 0.9375 - val_loss: 0.7972 - val_accuracy: 0.7500\n",
      "Epoch 20/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.1266 - accuracy: 0.9375 - val_loss: 0.8406 - val_accuracy: 0.7500\n",
      "Epoch 21/2000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.1168 - accuracy: 0.9375 - val_loss: 0.8391 - val_accuracy: 0.7500\n",
      "Epoch 22/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.1207 - accuracy: 0.9625 - val_loss: 0.7969 - val_accuracy: 0.7000\n",
      "Epoch 23/2000\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.1163 - accuracy: 0.9500 - val_loss: 0.7730 - val_accuracy: 0.7500\n",
      "Epoch 24/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1109 - accuracy: 0.9500 - val_loss: 0.7958 - val_accuracy: 0.8000\n",
      "Epoch 25/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.1117 - accuracy: 0.9500 - val_loss: 0.8187 - val_accuracy: 0.7500\n",
      "Epoch 26/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.1012 - accuracy: 0.9500 - val_loss: 0.8091 - val_accuracy: 0.7500\n",
      "Epoch 27/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.1033 - accuracy: 0.9625 - val_loss: 0.8461 - val_accuracy: 0.7500\n",
      "Epoch 28/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.1048 - accuracy: 0.9500 - val_loss: 0.8507 - val_accuracy: 0.7500\n",
      "Epoch 29/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.0960 - accuracy: 0.9625 - val_loss: 0.8916 - val_accuracy: 0.8000\n",
      "Epoch 30/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0972 - accuracy: 0.9625 - val_loss: 0.8553 - val_accuracy: 0.7500\n",
      "Epoch 31/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.0919 - accuracy: 0.9500 - val_loss: 0.9587 - val_accuracy: 0.7500\n",
      "Epoch 32/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.1132 - accuracy: 0.9375 - val_loss: 1.0025 - val_accuracy: 0.8000\n",
      "Epoch 33/2000\n",
      "80/80 [==============================] - 0s 543us/sample - loss: 0.1009 - accuracy: 0.9375 - val_loss: 1.0980 - val_accuracy: 0.7500\n",
      "Epoch 34/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.1101 - accuracy: 0.9625 - val_loss: 1.0396 - val_accuracy: 0.8000\n",
      "Epoch 35/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0890 - accuracy: 0.9875 - val_loss: 0.9396 - val_accuracy: 0.8000\n",
      "Epoch 36/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.0920 - accuracy: 0.9500 - val_loss: 0.9315 - val_accuracy: 0.8000\n",
      "Epoch 37/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.1017 - accuracy: 0.9375 - val_loss: 0.9613 - val_accuracy: 0.8000\n",
      "Epoch 38/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0853 - accuracy: 0.9625 - val_loss: 1.0117 - val_accuracy: 0.8000\n",
      "Epoch 39/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.0829 - accuracy: 0.9625 - val_loss: 1.0595 - val_accuracy: 0.8000\n",
      "Epoch 40/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0900 - accuracy: 0.9625 - val_loss: 1.0063 - val_accuracy: 0.8000\n",
      "Epoch 41/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0870 - accuracy: 0.9625 - val_loss: 0.9936 - val_accuracy: 0.8000\n",
      "Epoch 42/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.0848 - accuracy: 0.9500 - val_loss: 1.0527 - val_accuracy: 0.8500\n",
      "Epoch 43/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.0845 - accuracy: 0.9625 - val_loss: 1.1338 - val_accuracy: 0.8000\n",
      "Epoch 44/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.0803 - accuracy: 0.9625 - val_loss: 1.1195 - val_accuracy: 0.8000\n",
      "Epoch 45/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0756 - accuracy: 0.9625 - val_loss: 1.0710 - val_accuracy: 0.8000\n",
      "Epoch 46/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.0784 - accuracy: 0.9625 - val_loss: 1.0683 - val_accuracy: 0.7500\n",
      "Epoch 47/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.0741 - accuracy: 0.9625 - val_loss: 1.1052 - val_accuracy: 0.8000\n",
      "Epoch 48/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0697 - accuracy: 0.9750 - val_loss: 1.1803 - val_accuracy: 0.8000\n",
      "Epoch 49/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.0719 - accuracy: 0.9625 - val_loss: 1.2459 - val_accuracy: 0.8000\n",
      "Epoch 50/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.0769 - accuracy: 0.9500 - val_loss: 1.2849 - val_accuracy: 0.8500\n",
      "Epoch 51/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0675 - accuracy: 0.9625 - val_loss: 1.2873 - val_accuracy: 0.8000\n",
      "Epoch 52/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.0655 - accuracy: 0.9625 - val_loss: 1.2448 - val_accuracy: 0.8000\n",
      "Epoch 53/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0633 - accuracy: 0.9750 - val_loss: 1.2616 - val_accuracy: 0.8000\n",
      "Epoch 54/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.0626 - accuracy: 0.9625 - val_loss: 1.2938 - val_accuracy: 0.8000\n",
      "Epoch 55/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0632 - accuracy: 0.9625 - val_loss: 1.3076 - val_accuracy: 0.8000\n",
      "Epoch 56/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.0656 - accuracy: 0.9750 - val_loss: 1.3171 - val_accuracy: 0.8000\n",
      "Epoch 57/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0566 - accuracy: 0.9750 - val_loss: 1.2924 - val_accuracy: 0.8500\n",
      "Epoch 58/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0586 - accuracy: 0.9875 - val_loss: 1.3385 - val_accuracy: 0.8500\n",
      "Epoch 59/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0657 - accuracy: 0.9625 - val_loss: 1.3871 - val_accuracy: 0.8500\n",
      "Epoch 60/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.0691 - accuracy: 0.9625 - val_loss: 1.3704 - val_accuracy: 0.8000\n",
      "Epoch 61/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0593 - accuracy: 0.9750 - val_loss: 1.2379 - val_accuracy: 0.8000\n",
      "Epoch 62/2000\n",
      "80/80 [==============================] - 0s 676us/sample - loss: 0.0650 - accuracy: 0.9500 - val_loss: 1.3023 - val_accuracy: 0.8000\n",
      "Epoch 63/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.0657 - accuracy: 0.9625 - val_loss: 1.4206 - val_accuracy: 0.8000\n",
      "Epoch 64/2000\n",
      "80/80 [==============================] - 0s 330us/sample - loss: 0.0579 - accuracy: 0.9750 - val_loss: 1.4173 - val_accuracy: 0.8500\n",
      "Epoch 65/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0532 - accuracy: 0.9750 - val_loss: 1.3946 - val_accuracy: 0.8000\n",
      "Epoch 66/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0518 - accuracy: 0.9750 - val_loss: 1.3692 - val_accuracy: 0.8000\n",
      "Epoch 67/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0498 - accuracy: 0.9750 - val_loss: 1.3523 - val_accuracy: 0.8500\n",
      "Epoch 68/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0501 - accuracy: 0.9875 - val_loss: 1.4034 - val_accuracy: 0.8000\n",
      "Epoch 69/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.0615 - accuracy: 0.9750 - val_loss: 1.4082 - val_accuracy: 0.8000\n",
      "Epoch 70/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0468 - accuracy: 0.9875 - val_loss: 1.4228 - val_accuracy: 0.8000\n",
      "Epoch 71/2000\n",
      "80/80 [==============================] - 0s 166us/sample - loss: 0.0499 - accuracy: 0.9875 - val_loss: 1.4676 - val_accuracy: 0.7500\n",
      "Epoch 72/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.0470 - accuracy: 0.9750 - val_loss: 1.5312 - val_accuracy: 0.8000\n",
      "Epoch 73/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.0453 - accuracy: 0.9750 - val_loss: 1.4632 - val_accuracy: 0.8000\n",
      "Epoch 74/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.0413 - accuracy: 0.9875 - val_loss: 1.4438 - val_accuracy: 0.8000\n",
      "Epoch 75/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0423 - accuracy: 0.9750 - val_loss: 1.4932 - val_accuracy: 0.8000\n",
      "Epoch 76/2000\n",
      "80/80 [==============================] - 0s 61us/sample - loss: 0.0382 - accuracy: 0.9875 - val_loss: 1.5724 - val_accuracy: 0.8500\n",
      "Epoch 77/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.0451 - accuracy: 0.9875 - val_loss: 1.6566 - val_accuracy: 0.8000\n",
      "Epoch 78/2000\n",
      "80/80 [==============================] - 0s 186us/sample - loss: 0.0381 - accuracy: 0.9875 - val_loss: 1.6548 - val_accuracy: 0.8000\n",
      "Epoch 79/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.0512 - accuracy: 0.9625 - val_loss: 1.5659 - val_accuracy: 0.8000\n",
      "Epoch 80/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0345 - accuracy: 1.0000 - val_loss: 1.5854 - val_accuracy: 0.8500\n",
      "Epoch 81/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0414 - accuracy: 0.9875 - val_loss: 1.6248 - val_accuracy: 0.8500\n",
      "Epoch 82/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.0332 - accuracy: 0.9875 - val_loss: 1.7303 - val_accuracy: 0.8000\n",
      "Epoch 83/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.0881 - accuracy: 0.9750 - val_loss: 1.7209 - val_accuracy: 0.8000\n",
      "Epoch 84/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0323 - accuracy: 0.9875 - val_loss: 1.6701 - val_accuracy: 0.8000\n",
      "Epoch 85/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.1094 - accuracy: 0.9500 - val_loss: 1.7015 - val_accuracy: 0.8000\n",
      "Epoch 86/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0833 - accuracy: 0.9750 - val_loss: 1.9027 - val_accuracy: 0.8000\n",
      "Epoch 87/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0692 - accuracy: 0.9750 - val_loss: 1.8087 - val_accuracy: 0.8000\n",
      "Epoch 88/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.0364 - accuracy: 0.9750 - val_loss: 1.8063 - val_accuracy: 0.8000\n",
      "Epoch 89/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.0483 - accuracy: 0.9750 - val_loss: 1.7758 - val_accuracy: 0.8000\n",
      "Epoch 90/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 1.00 - 0s 80us/sample - loss: 0.0537 - accuracy: 0.9750 - val_loss: 1.7333 - val_accuracy: 0.8500\n",
      "Epoch 91/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0365 - accuracy: 0.9750 - val_loss: 1.7060 - val_accuracy: 0.7500\n",
      "Epoch 92/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0535 - accuracy: 0.9750 - val_loss: 1.6997 - val_accuracy: 0.7500\n",
      "Epoch 93/2000\n",
      "80/80 [==============================] - 0s 223us/sample - loss: 0.0560 - accuracy: 0.9750 - val_loss: 1.6653 - val_accuracy: 0.8000\n",
      "Epoch 94/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0280 - accuracy: 0.9875 - val_loss: 1.7597 - val_accuracy: 0.8000\n",
      "Epoch 95/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0636 - accuracy: 0.9875 - val_loss: 1.8774 - val_accuracy: 0.8000\n",
      "Epoch 96/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.0529 - accuracy: 0.9750 - val_loss: 1.7015 - val_accuracy: 0.8500\n",
      "Epoch 97/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0417 - accuracy: 0.9875 - val_loss: 1.6143 - val_accuracy: 0.8000\n",
      "Epoch 98/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0518 - accuracy: 0.9750 - val_loss: 1.5976 - val_accuracy: 0.8000\n",
      "Epoch 99/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0399 - accuracy: 0.9875 - val_loss: 1.7042 - val_accuracy: 0.8000\n",
      "Epoch 100/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0539 - accuracy: 0.9750 - val_loss: 1.7972 - val_accuracy: 0.8000\n",
      "Epoch 101/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0401 - accuracy: 0.9875 - val_loss: 1.8329 - val_accuracy: 0.8000\n",
      "Epoch 102/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.0450 - accuracy: 0.9750 - val_loss: 1.8395 - val_accuracy: 0.8000\n",
      "Epoch 103/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0468 - accuracy: 0.9625 - val_loss: 1.7549 - val_accuracy: 0.8000\n",
      "Epoch 104/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0346 - accuracy: 0.9875 - val_loss: 1.7051 - val_accuracy: 0.8500\n",
      "Epoch 105/2000\n",
      "80/80 [==============================] - 0s 198us/sample - loss: 0.0370 - accuracy: 0.9875 - val_loss: 1.6806 - val_accuracy: 0.8500\n",
      "Epoch 106/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.0364 - accuracy: 0.9875 - val_loss: 1.6695 - val_accuracy: 0.8500\n",
      "Epoch 107/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0256 - accuracy: 1.0000 - val_loss: 1.6997 - val_accuracy: 0.8000\n",
      "Epoch 108/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.0443 - accuracy: 0.9750 - val_loss: 1.7142 - val_accuracy: 0.8000\n",
      "Epoch 109/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.0388 - accuracy: 0.9750 - val_loss: 1.6777 - val_accuracy: 0.8000\n",
      "Epoch 110/2000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.0284 - accuracy: 0.9875 - val_loss: 1.7017 - val_accuracy: 0.8500\n",
      "Epoch 111/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0311 - accuracy: 0.9875 - val_loss: 1.6813 - val_accuracy: 0.8500\n",
      "Epoch 112/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0286 - accuracy: 0.9875 - val_loss: 1.7000 - val_accuracy: 0.8000\n",
      "Epoch 113/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0258 - accuracy: 0.9875 - val_loss: 1.7507 - val_accuracy: 0.8000\n",
      "Epoch 114/2000\n",
      "80/80 [==============================] - 0s 72us/sample - loss: 0.0258 - accuracy: 0.9875 - val_loss: 1.8206 - val_accuracy: 0.8000\n",
      "Epoch 115/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0286 - accuracy: 0.9875 - val_loss: 1.8336 - val_accuracy: 0.8000\n",
      "Epoch 116/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0264 - accuracy: 0.9875 - val_loss: 1.7943 - val_accuracy: 0.8000\n",
      "Epoch 117/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0233 - accuracy: 1.0000 - val_loss: 1.6717 - val_accuracy: 0.8000\n",
      "Epoch 118/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0373 - accuracy: 0.9875 - val_loss: 1.6085 - val_accuracy: 0.8000\n",
      "Epoch 119/2000\n",
      "80/80 [==============================] - 0s 208us/sample - loss: 0.0372 - accuracy: 0.9875 - val_loss: 1.7266 - val_accuracy: 0.8500\n",
      "Epoch 120/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0268 - accuracy: 0.9875 - val_loss: 1.8573 - val_accuracy: 0.8000\n",
      "Epoch 121/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.0265 - accuracy: 0.9875 - val_loss: 1.9221 - val_accuracy: 0.8000\n",
      "Epoch 122/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0303 - accuracy: 0.9875 - val_loss: 1.9346 - val_accuracy: 0.8000\n",
      "Epoch 123/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.0284 - accuracy: 0.9750 - val_loss: 1.9102 - val_accuracy: 0.8000\n",
      "Epoch 124/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0262 - accuracy: 0.9875 - val_loss: 1.8370 - val_accuracy: 0.8000\n",
      "Epoch 125/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.0310 - accuracy: 0.9875 - val_loss: 1.8363 - val_accuracy: 0.8000\n",
      "Epoch 126/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.0310 - accuracy: 0.9875 - val_loss: 1.8124 - val_accuracy: 0.8000\n",
      "Epoch 127/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0215 - accuracy: 1.0000 - val_loss: 1.8825 - val_accuracy: 0.8000\n",
      "Epoch 128/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0250 - accuracy: 0.9875 - val_loss: 1.9419 - val_accuracy: 0.8000\n",
      "Epoch 129/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.0325 - accuracy: 0.9875 - val_loss: 2.0141 - val_accuracy: 0.8000\n",
      "Epoch 130/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.0257 - accuracy: 0.9875 - val_loss: 1.9501 - val_accuracy: 0.8000\n",
      "Epoch 131/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.0223 - accuracy: 0.9875 - val_loss: 1.9032 - val_accuracy: 0.8000\n",
      "Epoch 132/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0214 - accuracy: 0.9875 - val_loss: 1.8641 - val_accuracy: 0.8000\n",
      "Epoch 133/2000\n",
      "80/80 [==============================] - 0s 159us/sample - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.8128 - val_accuracy: 0.8000\n",
      "Epoch 134/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0262 - accuracy: 0.9875 - val_loss: 1.8072 - val_accuracy: 0.8000\n",
      "Epoch 135/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0262 - accuracy: 0.9875 - val_loss: 1.8461 - val_accuracy: 0.8000\n",
      "Epoch 136/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0187 - accuracy: 0.9875 - val_loss: 1.8986 - val_accuracy: 0.8000\n",
      "Epoch 137/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.0292 - accuracy: 0.9875 - val_loss: 2.0253 - val_accuracy: 0.8000\n",
      "Epoch 138/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0302 - accuracy: 0.9875 - val_loss: 2.0207 - val_accuracy: 0.8000\n",
      "Epoch 139/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0226 - accuracy: 0.9875 - val_loss: 1.9980 - val_accuracy: 0.8000\n",
      "Epoch 140/2000\n",
      "80/80 [==============================] - 0s 154us/sample - loss: 0.0215 - accuracy: 1.0000 - val_loss: 1.9414 - val_accuracy: 0.8000\n",
      "Epoch 141/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0204 - accuracy: 0.9875 - val_loss: 1.8847 - val_accuracy: 0.8000\n",
      "Epoch 142/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.0227 - accuracy: 0.9875 - val_loss: 1.8774 - val_accuracy: 0.8000\n",
      "Epoch 143/2000\n",
      "80/80 [==============================] - 0s 178us/sample - loss: 0.0210 - accuracy: 0.9875 - val_loss: 1.9064 - val_accuracy: 0.8000\n",
      "Epoch 144/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0201 - accuracy: 0.9875 - val_loss: 1.9342 - val_accuracy: 0.8000\n",
      "Epoch 145/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.9832 - val_accuracy: 0.8000\n",
      "Epoch 146/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0206 - accuracy: 0.9875 - val_loss: 1.9959 - val_accuracy: 0.8000\n",
      "Epoch 147/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0214 - accuracy: 0.9875 - val_loss: 1.9880 - val_accuracy: 0.8000\n",
      "Epoch 148/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0188 - accuracy: 0.9875 - val_loss: 1.9646 - val_accuracy: 0.8000\n",
      "Epoch 149/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0198 - accuracy: 0.9875 - val_loss: 1.9491 - val_accuracy: 0.8000\n",
      "Epoch 150/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0185 - accuracy: 0.9875 - val_loss: 1.9483 - val_accuracy: 0.8000\n",
      "Epoch 151/2000\n",
      "80/80 [==============================] - 0s 151us/sample - loss: 0.0182 - accuracy: 0.9875 - val_loss: 1.9551 - val_accuracy: 0.8000\n",
      "Epoch 152/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.9908 - val_accuracy: 0.8000\n",
      "Epoch 153/2000\n",
      "80/80 [==============================] - 0s 564us/sample - loss: 0.0193 - accuracy: 0.9875 - val_loss: 2.0097 - val_accuracy: 0.8000\n",
      "Epoch 154/2000\n",
      "80/80 [==============================] - 0s 189us/sample - loss: 0.0252 - accuracy: 0.9875 - val_loss: 2.0290 - val_accuracy: 0.8000\n",
      "Epoch 155/2000\n",
      "80/80 [==============================] - 0s 209us/sample - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.9692 - val_accuracy: 0.8000\n",
      "Epoch 156/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0209 - accuracy: 0.9875 - val_loss: 1.9685 - val_accuracy: 0.8000\n",
      "Epoch 157/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0276 - accuracy: 0.9875 - val_loss: 1.9517 - val_accuracy: 0.8000\n",
      "Epoch 158/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.0179 - accuracy: 0.9875 - val_loss: 2.0682 - val_accuracy: 0.8000\n",
      "Epoch 159/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0398 - accuracy: 0.9875 - val_loss: 2.0884 - val_accuracy: 0.8000\n",
      "Epoch 160/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.0422 - accuracy: 0.9875 - val_loss: 2.1108 - val_accuracy: 0.7500\n",
      "Epoch 161/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.00 - 0s 63us/sample - loss: 0.0160 - accuracy: 0.9875 - val_loss: 2.0336 - val_accuracy: 0.8000\n",
      "Epoch 162/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.0188 - accuracy: 0.9875 - val_loss: 1.9951 - val_accuracy: 0.7500\n",
      "Epoch 163/2000\n",
      "80/80 [==============================] - 0s 192us/sample - loss: 0.0495 - accuracy: 0.9875 - val_loss: 1.8738 - val_accuracy: 0.8000\n",
      "Epoch 164/2000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.0321 - accuracy: 0.9875 - val_loss: 1.8131 - val_accuracy: 0.8500\n",
      "Epoch 165/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.0272 - accuracy: 1.0000 - val_loss: 2.0017 - val_accuracy: 0.8500\n",
      "Epoch 166/2000\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.0258 - accuracy: 0.9875 - val_loss: 2.1468 - val_accuracy: 0.8500\n",
      "Epoch 167/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0263 - accuracy: 0.9875 - val_loss: 2.2063 - val_accuracy: 0.8000\n",
      "Epoch 168/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0196 - accuracy: 0.9875 - val_loss: 2.1666 - val_accuracy: 0.8000\n",
      "Epoch 169/2000\n",
      "80/80 [==============================] - 0s 195us/sample - loss: 0.0249 - accuracy: 0.9875 - val_loss: 2.1084 - val_accuracy: 0.8000\n",
      "Epoch 170/2000\n",
      "80/80 [==============================] - 0s 152us/sample - loss: 0.0207 - accuracy: 0.9875 - val_loss: 2.0575 - val_accuracy: 0.8500\n",
      "Epoch 171/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0194 - accuracy: 0.9875 - val_loss: 2.0040 - val_accuracy: 0.8500\n",
      "Epoch 172/2000\n",
      "80/80 [==============================] - 0s 175us/sample - loss: 0.0272 - accuracy: 0.9875 - val_loss: 2.0431 - val_accuracy: 0.8000\n",
      "Epoch 173/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.0253 - accuracy: 0.9875 - val_loss: 2.1136 - val_accuracy: 0.8000\n",
      "Epoch 174/2000\n",
      "80/80 [==============================] - 0s 396us/sample - loss: 0.0226 - accuracy: 0.9875 - val_loss: 2.2232 - val_accuracy: 0.8000\n",
      "Epoch 175/2000\n",
      "80/80 [==============================] - 0s 191us/sample - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.2760 - val_accuracy: 0.8000\n",
      "Epoch 176/2000\n",
      "80/80 [==============================] - 0s 163us/sample - loss: 0.0187 - accuracy: 0.9875 - val_loss: 2.2884 - val_accuracy: 0.8000\n",
      "Epoch 177/2000\n",
      "80/80 [==============================] - 0s 217us/sample - loss: 0.0219 - accuracy: 0.9875 - val_loss: 2.2772 - val_accuracy: 0.8000\n",
      "Epoch 178/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.0208 - accuracy: 0.9875 - val_loss: 2.2425 - val_accuracy: 0.8000\n",
      "Epoch 179/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0173 - accuracy: 0.9875 - val_loss: 2.2116 - val_accuracy: 0.8000\n",
      "Epoch 180/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0256 - accuracy: 0.9875 - val_loss: 2.1737 - val_accuracy: 0.8000\n",
      "Epoch 181/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.2159 - val_accuracy: 0.8000\n",
      "Epoch 182/2000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.0263 - accuracy: 0.9875 - val_loss: 2.2100 - val_accuracy: 0.8000\n",
      "Epoch 183/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 0.0297 - accuracy: 0.9875 - val_loss: 2.2341 - val_accuracy: 0.8000\n",
      "Epoch 184/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.1724 - val_accuracy: 0.8000\n",
      "Epoch 185/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.0394 - accuracy: 0.9875 - val_loss: 2.1368 - val_accuracy: 0.8000\n",
      "Epoch 186/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0406 - accuracy: 0.9875 - val_loss: 2.0774 - val_accuracy: 0.8000\n",
      "Epoch 187/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.0212 - accuracy: 0.9875 - val_loss: 2.1296 - val_accuracy: 0.8000\n",
      "Epoch 188/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0204 - accuracy: 0.9875 - val_loss: 2.1784 - val_accuracy: 0.8000\n",
      "Epoch 189/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.0305 - accuracy: 0.9875 - val_loss: 2.2293 - val_accuracy: 0.8000\n",
      "Epoch 190/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.0199 - accuracy: 0.9875 - val_loss: 2.2648 - val_accuracy: 0.8000\n",
      "Epoch 191/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0268 - accuracy: 0.9875 - val_loss: 2.2133 - val_accuracy: 0.8000\n",
      "Epoch 192/2000\n",
      "80/80 [==============================] - 0s 74us/sample - loss: 0.0440 - accuracy: 0.9875 - val_loss: 2.1640 - val_accuracy: 0.8000\n",
      "Epoch 193/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0271 - accuracy: 0.9875 - val_loss: 2.1514 - val_accuracy: 0.8000\n",
      "Epoch 194/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.1809 - val_accuracy: 0.8500\n",
      "Epoch 195/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.0237 - accuracy: 0.9875 - val_loss: 2.2136 - val_accuracy: 0.8000\n",
      "Epoch 196/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0274 - accuracy: 0.9875 - val_loss: 2.2354 - val_accuracy: 0.8000\n",
      "Epoch 197/2000\n",
      "80/80 [==============================] - 0s 652us/sample - loss: 0.0171 - accuracy: 0.9875 - val_loss: 2.2350 - val_accuracy: 0.8000\n",
      "Epoch 198/2000\n",
      "80/80 [==============================] - 0s 16us/sample - loss: 0.0159 - accuracy: 0.9875 - val_loss: 2.2344 - val_accuracy: 0.8000\n",
      "Epoch 199/2000\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0207 - accuracy: 0.9875 - val_loss: 2.2352 - val_accuracy: 0.8000\n",
      "Epoch 200/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.0181 - accuracy: 0.9875 - val_loss: 2.2525 - val_accuracy: 0.8000\n",
      "Epoch 201/2000\n",
      "80/80 [==============================] - 0s 181us/sample - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.2546 - val_accuracy: 0.8000\n",
      "Epoch 202/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0230 - accuracy: 0.9875 - val_loss: 2.2412 - val_accuracy: 0.8000\n",
      "Epoch 203/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.1788 - val_accuracy: 0.8000\n",
      "Epoch 204/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0187 - accuracy: 0.9875 - val_loss: 2.1443 - val_accuracy: 0.8000\n",
      "Epoch 205/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.96 - 0s 127us/sample - loss: 0.0283 - accuracy: 0.9875 - val_loss: 2.1588 - val_accuracy: 0.8000\n",
      "Epoch 206/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.0252 - accuracy: 0.9875 - val_loss: 2.2014 - val_accuracy: 0.8000\n",
      "Epoch 207/2000\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.2122 - val_accuracy: 0.8000\n",
      "Epoch 208/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.0179 - accuracy: 0.9875 - val_loss: 2.2445 - val_accuracy: 0.8000\n",
      "Epoch 209/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.0151 - accuracy: 0.9875 - val_loss: 2.2548 - val_accuracy: 0.8000\n",
      "Epoch 210/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.0208 - accuracy: 0.9875 - val_loss: 2.2733 - val_accuracy: 0.8000\n",
      "Epoch 211/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0223 - accuracy: 0.9875 - val_loss: 2.2927 - val_accuracy: 0.8000\n",
      "Epoch 212/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.3024 - val_accuracy: 0.8000\n",
      "Epoch 213/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.0171 - accuracy: 0.9875 - val_loss: 2.2900 - val_accuracy: 0.8000\n",
      "Epoch 214/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.0149 - accuracy: 0.9875 - val_loss: 2.2962 - val_accuracy: 0.8000\n",
      "Epoch 215/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.0173 - accuracy: 0.9875 - val_loss: 2.2899 - val_accuracy: 0.8000\n",
      "Epoch 216/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0149 - accuracy: 0.9875 - val_loss: 2.2768 - val_accuracy: 0.8000\n",
      "Epoch 217/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0147 - accuracy: 0.9875 - val_loss: 2.2841 - val_accuracy: 0.8000\n",
      "Epoch 218/2000\n",
      "80/80 [==============================] - 0s 406us/sample - loss: 0.0168 - accuracy: 0.9875 - val_loss: 2.2821 - val_accuracy: 0.8000\n",
      "Epoch 219/2000\n",
      "80/80 [==============================] - 0s 172us/sample - loss: 0.0179 - accuracy: 0.9875 - val_loss: 2.2913 - val_accuracy: 0.8000\n",
      "Epoch 220/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 1.00 - 0s 97us/sample - loss: 0.0183 - accuracy: 0.9875 - val_loss: 2.2932 - val_accuracy: 0.8000\n",
      "Epoch 221/2000\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.0201 - accuracy: 0.9875 - val_loss: 2.2870 - val_accuracy: 0.8000\n",
      "Epoch 222/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.2301 - val_accuracy: 0.8000\n",
      "Epoch 223/2000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.0226 - accuracy: 0.9875 - val_loss: 2.2355 - val_accuracy: 0.8000\n",
      "Epoch 224/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0270 - accuracy: 0.9875 - val_loss: 2.2658 - val_accuracy: 0.8000\n",
      "Epoch 225/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0160 - accuracy: 0.9875 - val_loss: 2.3008 - val_accuracy: 0.8000\n",
      "Epoch 226/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0182 - accuracy: 0.9875 - val_loss: 2.3393 - val_accuracy: 0.8000\n",
      "Epoch 227/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0168 - accuracy: 0.9875 - val_loss: 2.3126 - val_accuracy: 0.8000\n",
      "Epoch 228/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0201 - accuracy: 0.9875 - val_loss: 2.2827 - val_accuracy: 0.8000\n",
      "Epoch 229/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.3050 - val_accuracy: 0.8000\n",
      "Epoch 230/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0231 - accuracy: 0.9875 - val_loss: 2.3015 - val_accuracy: 0.8000\n",
      "Epoch 231/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0198 - accuracy: 0.9875 - val_loss: 2.2375 - val_accuracy: 0.8000\n",
      "Epoch 232/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0172 - accuracy: 0.9875 - val_loss: 2.2480 - val_accuracy: 0.8000\n",
      "Epoch 233/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.2889 - val_accuracy: 0.8000\n",
      "Epoch 234/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0305 - accuracy: 0.9875 - val_loss: 2.2759 - val_accuracy: 0.8000\n",
      "Epoch 235/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0276 - accuracy: 0.9875 - val_loss: 2.2456 - val_accuracy: 0.8000\n",
      "Epoch 236/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0248 - accuracy: 0.9750 - val_loss: 2.2096 - val_accuracy: 0.8000\n",
      "Epoch 237/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.2608 - val_accuracy: 0.8000\n",
      "Epoch 238/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.2931 - val_accuracy: 0.8000\n",
      "Epoch 239/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0243 - accuracy: 0.9875 - val_loss: 2.2958 - val_accuracy: 0.8000\n",
      "Epoch 240/2000\n",
      "80/80 [==============================] - 0s 201us/sample - loss: 0.0182 - accuracy: 0.9875 - val_loss: 2.2600 - val_accuracy: 0.8000\n",
      "Epoch 241/2000\n",
      "80/80 [==============================] - 0s 199us/sample - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.2104 - val_accuracy: 0.8000\n",
      "Epoch 242/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0277 - accuracy: 0.9875 - val_loss: 2.2146 - val_accuracy: 0.8000\n",
      "Epoch 243/2000\n",
      "80/80 [==============================] - 0s 469us/sample - loss: 0.0269 - accuracy: 0.9875 - val_loss: 2.2493 - val_accuracy: 0.8000\n",
      "Epoch 244/2000\n",
      "80/80 [==============================] - 0s 14us/sample - loss: 0.0201 - accuracy: 0.9875 - val_loss: 2.3315 - val_accuracy: 0.8000\n",
      "Epoch 245/2000\n",
      "80/80 [==============================] - 0s 187us/sample - loss: 0.0164 - accuracy: 0.9875 - val_loss: 2.3537 - val_accuracy: 0.8000\n",
      "Epoch 246/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.0188 - accuracy: 0.9875 - val_loss: 2.3232 - val_accuracy: 0.8000\n",
      "Epoch 247/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0171 - accuracy: 0.9875 - val_loss: 2.2774 - val_accuracy: 0.8000\n",
      "Epoch 248/2000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0156 - accuracy: 0.9875 - val_loss: 2.2712 - val_accuracy: 0.8000\n",
      "Epoch 249/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.3053 - val_accuracy: 0.8000\n",
      "Epoch 250/2000\n",
      "80/80 [==============================] - 0s 168us/sample - loss: 0.0134 - accuracy: 0.9875 - val_loss: 2.3342 - val_accuracy: 0.8000\n",
      "Epoch 251/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0188 - accuracy: 0.9875 - val_loss: 2.3291 - val_accuracy: 0.8000\n",
      "Epoch 252/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 0.0180 - accuracy: 0.9875 - val_loss: 2.2980 - val_accuracy: 0.8000\n",
      "Epoch 253/2000\n",
      "80/80 [==============================] - 0s 160us/sample - loss: 0.0142 - accuracy: 0.9875 - val_loss: 2.2584 - val_accuracy: 0.8000\n",
      "Epoch 254/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.0189 - accuracy: 0.9875 - val_loss: 2.2618 - val_accuracy: 0.8000\n",
      "Epoch 255/2000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.3084 - val_accuracy: 0.8000\n",
      "Epoch 256/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.3063 - val_accuracy: 0.8000\n",
      "Epoch 257/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.2897 - val_accuracy: 0.8000\n",
      "Epoch 258/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0147 - accuracy: 0.9875 - val_loss: 2.2680 - val_accuracy: 0.8000\n",
      "Epoch 259/2000\n",
      "80/80 [==============================] - 0s 151us/sample - loss: 0.0170 - accuracy: 0.9875 - val_loss: 2.2913 - val_accuracy: 0.8000\n",
      "Epoch 260/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.3195 - val_accuracy: 0.8000\n",
      "Epoch 261/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.3248 - val_accuracy: 0.8000\n",
      "Epoch 262/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.3170 - val_accuracy: 0.8000\n",
      "Epoch 263/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.0215 - accuracy: 0.9875 - val_loss: 2.3376 - val_accuracy: 0.8000\n",
      "Epoch 264/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.2769 - val_accuracy: 0.8000\n",
      "Epoch 265/2000\n",
      "80/80 [==============================] - 0s 186us/sample - loss: 0.0168 - accuracy: 0.9875 - val_loss: 2.2507 - val_accuracy: 0.8000\n",
      "Epoch 266/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.0193 - accuracy: 0.9875 - val_loss: 2.2555 - val_accuracy: 0.8000\n",
      "Epoch 267/2000\n",
      "80/80 [==============================] - 0s 277us/sample - loss: 0.0139 - accuracy: 0.9875 - val_loss: 2.2922 - val_accuracy: 0.8000\n",
      "Epoch 268/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0169 - accuracy: 0.9875 - val_loss: 2.3250 - val_accuracy: 0.8000\n",
      "Epoch 269/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0157 - accuracy: 0.9875 - val_loss: 2.2955 - val_accuracy: 0.8000\n",
      "Epoch 270/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.2774 - val_accuracy: 0.8000\n",
      "Epoch 271/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.0152 - accuracy: 0.9875 - val_loss: 2.2480 - val_accuracy: 0.8000\n",
      "Epoch 272/2000\n",
      "80/80 [==============================] - 0s 24us/sample - loss: 0.0179 - accuracy: 0.9875 - val_loss: 2.2764 - val_accuracy: 0.8000\n",
      "Epoch 273/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.0191 - accuracy: 0.9875 - val_loss: 2.3173 - val_accuracy: 0.8000\n",
      "Epoch 274/2000\n",
      "80/80 [==============================] - 0s 573us/sample - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.3064 - val_accuracy: 0.8000\n",
      "Epoch 275/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.3041 - val_accuracy: 0.8000\n",
      "Epoch 276/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0139 - accuracy: 0.9875 - val_loss: 2.3271 - val_accuracy: 0.8000\n",
      "Epoch 277/2000\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.3418 - val_accuracy: 0.8000\n",
      "Epoch 278/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.3398 - val_accuracy: 0.8000\n",
      "Epoch 279/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.3204 - val_accuracy: 0.8000\n",
      "Epoch 280/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.3043 - val_accuracy: 0.8000\n",
      "Epoch 281/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0179 - accuracy: 0.9875 - val_loss: 2.2975 - val_accuracy: 0.8000\n",
      "Epoch 282/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0182 - accuracy: 0.9875 - val_loss: 2.3661 - val_accuracy: 0.8000\n",
      "Epoch 283/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0202 - accuracy: 0.9875 - val_loss: 2.3316 - val_accuracy: 0.8000\n",
      "Epoch 284/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.0172 - accuracy: 0.9875 - val_loss: 2.2741 - val_accuracy: 0.8000\n",
      "Epoch 285/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.2666 - val_accuracy: 0.8000\n",
      "Epoch 286/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0156 - accuracy: 0.9875 - val_loss: 2.2790 - val_accuracy: 0.8000\n",
      "Epoch 287/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.0204 - accuracy: 0.9875 - val_loss: 2.2784 - val_accuracy: 0.8000\n",
      "Epoch 288/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.3649 - val_accuracy: 0.8000\n",
      "Epoch 289/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0181 - accuracy: 0.9875 - val_loss: 2.3736 - val_accuracy: 0.8000\n",
      "Epoch 290/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0206 - accuracy: 0.9875 - val_loss: 2.3180 - val_accuracy: 0.8000\n",
      "Epoch 291/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.2821 - val_accuracy: 0.8000\n",
      "Epoch 292/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0135 - accuracy: 0.9875 - val_loss: 2.2798 - val_accuracy: 0.8000\n",
      "Epoch 293/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.0131 - accuracy: 0.9875 - val_loss: 2.2947 - val_accuracy: 0.8000\n",
      "Epoch 294/2000\n",
      "80/80 [==============================] - 0s 163us/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.3371 - val_accuracy: 0.8000\n",
      "Epoch 295/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.0260 - accuracy: 0.9875 - val_loss: 2.3143 - val_accuracy: 0.8000\n",
      "Epoch 296/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.2005 - val_accuracy: 0.8000\n",
      "Epoch 297/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0461 - accuracy: 0.9875 - val_loss: 2.2021 - val_accuracy: 0.8000\n",
      "Epoch 298/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0220 - accuracy: 0.9875 - val_loss: 2.3572 - val_accuracy: 0.8000\n",
      "Epoch 299/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0204 - accuracy: 0.9875 - val_loss: 2.4904 - val_accuracy: 0.7500\n",
      "Epoch 300/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0329 - accuracy: 0.9875 - val_loss: 2.2717 - val_accuracy: 0.8000\n",
      "Epoch 301/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0196 - accuracy: 0.9875 - val_loss: 2.1259 - val_accuracy: 0.8000\n",
      "Epoch 302/2000\n",
      "80/80 [==============================] - 0s 366us/sample - loss: 0.0168 - accuracy: 0.9875 - val_loss: 2.1074 - val_accuracy: 0.8000\n",
      "Epoch 303/2000\n",
      "80/80 [==============================] - 0s 241us/sample - loss: 0.0226 - accuracy: 0.9875 - val_loss: 2.1440 - val_accuracy: 0.8000\n",
      "Epoch 304/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.2397 - val_accuracy: 0.8000\n",
      "Epoch 305/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.0308 - accuracy: 0.9875 - val_loss: 2.2802 - val_accuracy: 0.8000\n",
      "Epoch 306/2000\n",
      "80/80 [==============================] - 0s 196us/sample - loss: 0.0264 - accuracy: 0.9875 - val_loss: 2.1900 - val_accuracy: 0.8000\n",
      "Epoch 307/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.1622 - val_accuracy: 0.8000\n",
      "Epoch 308/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0207 - accuracy: 0.9875 - val_loss: 2.1874 - val_accuracy: 0.8000\n",
      "Epoch 309/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.0183 - accuracy: 0.9875 - val_loss: 2.2393 - val_accuracy: 0.8000\n",
      "Epoch 310/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2.2924 - val_accuracy: 0.8000\n",
      "Epoch 311/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.0147 - accuracy: 0.9875 - val_loss: 2.3074 - val_accuracy: 0.8000\n",
      "Epoch 312/2000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.0154 - accuracy: 0.9875 - val_loss: 2.3136 - val_accuracy: 0.8000\n",
      "Epoch 313/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.0158 - accuracy: 0.9875 - val_loss: 2.3059 - val_accuracy: 0.8000\n",
      "Epoch 314/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0142 - accuracy: 0.9875 - val_loss: 2.2683 - val_accuracy: 0.8000\n",
      "Epoch 315/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.2493 - val_accuracy: 0.8000\n",
      "Epoch 316/2000\n",
      "80/80 [==============================] - 0s 249us/sample - loss: 0.0177 - accuracy: 0.9875 - val_loss: 2.2437 - val_accuracy: 0.8000\n",
      "Epoch 317/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0146 - accuracy: 0.9875 - val_loss: 2.3149 - val_accuracy: 0.8000\n",
      "Epoch 318/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.0168 - accuracy: 0.9875 - val_loss: 2.3457 - val_accuracy: 0.8000\n",
      "Epoch 319/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.0191 - accuracy: 0.9875 - val_loss: 2.3220 - val_accuracy: 0.8000\n",
      "Epoch 320/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.2460 - val_accuracy: 0.8000\n",
      "Epoch 321/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0233 - accuracy: 0.9875 - val_loss: 2.2221 - val_accuracy: 0.8000\n",
      "Epoch 322/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.0271 - accuracy: 0.9875 - val_loss: 2.2531 - val_accuracy: 0.8000\n",
      "Epoch 323/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0143 - accuracy: 0.9875 - val_loss: 2.3645 - val_accuracy: 0.8000\n",
      "Epoch 324/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0210 - accuracy: 0.9875 - val_loss: 2.4279 - val_accuracy: 0.8000\n",
      "Epoch 325/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 0.0274 - accuracy: 0.9875 - val_loss: 2.3873 - val_accuracy: 0.8000\n",
      "Epoch 326/2000\n",
      "80/80 [==============================] - 0s 216us/sample - loss: 0.0216 - accuracy: 0.9875 - val_loss: 2.2781 - val_accuracy: 0.8000\n",
      "Epoch 327/2000\n",
      "80/80 [==============================] - 0s 163us/sample - loss: 0.0133 - accuracy: 1.0000 - val_loss: 2.2195 - val_accuracy: 0.8000\n",
      "Epoch 328/2000\n",
      "80/80 [==============================] - 0s 67us/sample - loss: 0.0197 - accuracy: 0.9875 - val_loss: 2.2062 - val_accuracy: 0.8000\n",
      "Epoch 329/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0168 - accuracy: 0.9875 - val_loss: 2.2483 - val_accuracy: 0.8000\n",
      "Epoch 330/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0187 - accuracy: 0.9875 - val_loss: 2.2939 - val_accuracy: 0.8000\n",
      "Epoch 331/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0161 - accuracy: 0.9875 - val_loss: 2.2768 - val_accuracy: 0.8000\n",
      "Epoch 332/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.2932 - val_accuracy: 0.8000\n",
      "Epoch 333/2000\n",
      "80/80 [==============================] - 0s 212us/sample - loss: 0.0157 - accuracy: 0.9875 - val_loss: 2.3215 - val_accuracy: 0.8000\n",
      "Epoch 334/2000\n",
      "80/80 [==============================] - 0s 196us/sample - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.3377 - val_accuracy: 0.8000\n",
      "Epoch 335/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.0150 - accuracy: 0.9875 - val_loss: 2.3480 - val_accuracy: 0.8000\n",
      "Epoch 336/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0167 - accuracy: 0.9875 - val_loss: 2.3689 - val_accuracy: 0.8000\n",
      "Epoch 337/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.0130 - accuracy: 1.0000 - val_loss: 2.3459 - val_accuracy: 0.8000\n",
      "Epoch 338/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.3348 - val_accuracy: 0.8000\n",
      "Epoch 339/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.3259 - val_accuracy: 0.8000\n",
      "Epoch 340/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 0.0184 - accuracy: 0.9875 - val_loss: 2.3029 - val_accuracy: 0.8000\n",
      "Epoch 341/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.0125 - accuracy: 0.9875 - val_loss: 2.3488 - val_accuracy: 0.8000\n",
      "Epoch 342/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.0171 - accuracy: 0.9875 - val_loss: 2.3846 - val_accuracy: 0.8000\n",
      "Epoch 343/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0195 - accuracy: 0.9875 - val_loss: 2.3515 - val_accuracy: 0.8000\n",
      "Epoch 344/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.0241 - accuracy: 0.9750 - val_loss: 2.2590 - val_accuracy: 0.8000\n",
      "Epoch 345/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0162 - accuracy: 0.9875 - val_loss: 2.2783 - val_accuracy: 0.8000\n",
      "Epoch 346/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.0131 - accuracy: 0.9875 - val_loss: 2.3065 - val_accuracy: 0.8000\n",
      "Epoch 347/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.3595 - val_accuracy: 0.8000\n",
      "Epoch 348/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.0204 - accuracy: 0.9875 - val_loss: 2.3645 - val_accuracy: 0.8000\n",
      "Epoch 349/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0199 - accuracy: 0.9875 - val_loss: 2.2981 - val_accuracy: 0.8000\n",
      "Epoch 350/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.2479 - val_accuracy: 0.8000\n",
      "Epoch 351/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.0133 - accuracy: 0.9875 - val_loss: 2.2405 - val_accuracy: 0.8000\n",
      "Epoch 352/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0145 - accuracy: 0.9875 - val_loss: 2.2507 - val_accuracy: 0.8000\n",
      "Epoch 353/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0154 - accuracy: 0.9875 - val_loss: 2.2824 - val_accuracy: 0.8000\n",
      "Epoch 354/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.0132 - accuracy: 0.9875 - val_loss: 2.3134 - val_accuracy: 0.8000\n",
      "Epoch 355/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.3455 - val_accuracy: 0.8000\n",
      "Epoch 356/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.3698 - val_accuracy: 0.8000\n",
      "Epoch 357/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.3626 - val_accuracy: 0.8000\n",
      "Epoch 358/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.3411 - val_accuracy: 0.8000\n",
      "Epoch 359/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0120 - accuracy: 1.0000 - val_loss: 2.3393 - val_accuracy: 0.8000\n",
      "Epoch 360/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.0119 - accuracy: 1.0000 - val_loss: 2.3409 - val_accuracy: 0.8000\n",
      "Epoch 361/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.3409 - val_accuracy: 0.8000\n",
      "Epoch 362/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.3735 - val_accuracy: 0.8000\n",
      "Epoch 363/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.0155 - accuracy: 0.9875 - val_loss: 2.3769 - val_accuracy: 0.8000\n",
      "Epoch 364/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0161 - accuracy: 0.9875 - val_loss: 2.3518 - val_accuracy: 0.8000\n",
      "Epoch 365/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.3090 - val_accuracy: 0.8000\n",
      "Epoch 366/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.2420 - val_accuracy: 0.8000\n",
      "Epoch 367/2000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.0248 - accuracy: 0.9875 - val_loss: 2.2390 - val_accuracy: 0.8000\n",
      "Epoch 368/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0212 - accuracy: 0.9875 - val_loss: 2.2967 - val_accuracy: 0.8000\n",
      "Epoch 369/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.3671 - val_accuracy: 0.8000\n",
      "Epoch 370/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.4312 - val_accuracy: 0.8000\n",
      "Epoch 371/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0243 - accuracy: 0.9875 - val_loss: 2.4093 - val_accuracy: 0.8000\n",
      "Epoch 372/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0192 - accuracy: 0.9875 - val_loss: 2.3293 - val_accuracy: 0.8000\n",
      "Epoch 373/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.2176 - val_accuracy: 0.8000\n",
      "Epoch 374/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.96 - 0s 118us/sample - loss: 0.0190 - accuracy: 0.9875 - val_loss: 2.1954 - val_accuracy: 0.8000\n",
      "Epoch 375/2000\n",
      "80/80 [==============================] - 0s 812us/sample - loss: 0.0232 - accuracy: 0.9875 - val_loss: 2.2332 - val_accuracy: 0.8000\n",
      "Epoch 376/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0153 - accuracy: 0.9875 - val_loss: 2.2794 - val_accuracy: 0.8000\n",
      "Epoch 377/2000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.3018 - val_accuracy: 0.8000\n",
      "Epoch 378/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.3116 - val_accuracy: 0.8000\n",
      "Epoch 379/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.3137 - val_accuracy: 0.8000\n",
      "Epoch 380/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.2965 - val_accuracy: 0.8000\n",
      "Epoch 381/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.3018 - val_accuracy: 0.8000\n",
      "Epoch 382/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.3251 - val_accuracy: 0.8000\n",
      "Epoch 383/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.3392 - val_accuracy: 0.8000\n",
      "Epoch 384/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0188 - accuracy: 0.9875 - val_loss: 2.3647 - val_accuracy: 0.8000\n",
      "Epoch 385/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.0131 - accuracy: 0.9875 - val_loss: 2.2838 - val_accuracy: 0.8000\n",
      "Epoch 386/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.0186 - accuracy: 0.9875 - val_loss: 2.2619 - val_accuracy: 0.8000\n",
      "Epoch 387/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0193 - accuracy: 0.9875 - val_loss: 2.2905 - val_accuracy: 0.8000\n",
      "Epoch 388/2000\n",
      "80/80 [==============================] - 0s 210us/sample - loss: 0.0154 - accuracy: 0.9875 - val_loss: 2.3511 - val_accuracy: 0.8000\n",
      "Epoch 389/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.0145 - accuracy: 0.9875 - val_loss: 2.3764 - val_accuracy: 0.8000\n",
      "Epoch 390/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.0154 - accuracy: 0.9875 - val_loss: 2.3434 - val_accuracy: 0.8000\n",
      "Epoch 391/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0132 - accuracy: 0.9875 - val_loss: 2.3286 - val_accuracy: 0.8000\n",
      "Epoch 392/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.2794 - val_accuracy: 0.8000\n",
      "Epoch 393/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0154 - accuracy: 0.9875 - val_loss: 2.2604 - val_accuracy: 0.8000\n",
      "Epoch 394/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0172 - accuracy: 0.9875 - val_loss: 2.2809 - val_accuracy: 0.8000\n",
      "Epoch 395/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0133 - accuracy: 0.9875 - val_loss: 2.3237 - val_accuracy: 0.8000\n",
      "Epoch 396/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.3521 - val_accuracy: 0.8000\n",
      "Epoch 397/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.3259 - val_accuracy: 0.8000\n",
      "Epoch 398/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.2775 - val_accuracy: 0.8000\n",
      "Epoch 399/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0139 - accuracy: 0.9875 - val_loss: 2.2843 - val_accuracy: 0.8000\n",
      "Epoch 400/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0130 - accuracy: 0.9875 - val_loss: 2.3100 - val_accuracy: 0.8000\n",
      "Epoch 401/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.3453 - val_accuracy: 0.8000\n",
      "Epoch 402/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.3681 - val_accuracy: 0.8000\n",
      "Epoch 403/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0126 - accuracy: 0.9875 - val_loss: 2.3579 - val_accuracy: 0.8000\n",
      "Epoch 404/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.3172 - val_accuracy: 0.8000\n",
      "Epoch 405/2000\n",
      "80/80 [==============================] - 0s 497us/sample - loss: 0.0162 - accuracy: 0.9875 - val_loss: 2.3061 - val_accuracy: 0.8000\n",
      "Epoch 406/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.3752 - val_accuracy: 0.8000\n",
      "Epoch 407/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0127 - accuracy: 0.9875 - val_loss: 2.3846 - val_accuracy: 0.8000\n",
      "Epoch 408/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0165 - accuracy: 0.9875 - val_loss: 2.3398 - val_accuracy: 0.8000\n",
      "Epoch 409/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.2879 - val_accuracy: 0.8000\n",
      "Epoch 410/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.2825 - val_accuracy: 0.8000\n",
      "Epoch 411/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.3026 - val_accuracy: 0.8000\n",
      "Epoch 412/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0133 - accuracy: 1.0000 - val_loss: 2.3213 - val_accuracy: 0.8000\n",
      "Epoch 413/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0136 - accuracy: 1.0000 - val_loss: 2.2819 - val_accuracy: 0.8000\n",
      "Epoch 414/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.0194 - accuracy: 0.9875 - val_loss: 2.3085 - val_accuracy: 0.8000\n",
      "Epoch 415/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0165 - accuracy: 0.9875 - val_loss: 2.4497 - val_accuracy: 0.8000\n",
      "Epoch 416/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.0315 - accuracy: 0.9875 - val_loss: 2.4427 - val_accuracy: 0.8000\n",
      "Epoch 417/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.0152 - accuracy: 0.9875 - val_loss: 2.2337 - val_accuracy: 0.8000\n",
      "Epoch 418/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0317 - accuracy: 0.9875 - val_loss: 2.1482 - val_accuracy: 0.8000\n",
      "Epoch 419/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.0191 - accuracy: 0.9875 - val_loss: 2.2785 - val_accuracy: 0.8000\n",
      "Epoch 420/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0137 - accuracy: 0.9875 - val_loss: 2.4199 - val_accuracy: 0.8000\n",
      "Epoch 421/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.0121 - accuracy: 0.9875 - val_loss: 2.4255 - val_accuracy: 0.8000\n",
      "Epoch 422/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.4149 - val_accuracy: 0.8000\n",
      "Epoch 423/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.0193 - accuracy: 0.9875 - val_loss: 2.4296 - val_accuracy: 0.8000\n",
      "Epoch 424/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.5262 - val_accuracy: 0.8000\n",
      "Epoch 425/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0305 - accuracy: 0.9875 - val_loss: 2.5713 - val_accuracy: 0.7500\n",
      "Epoch 426/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.0189 - accuracy: 0.9875 - val_loss: 2.3273 - val_accuracy: 0.8000\n",
      "Epoch 427/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.0197 - accuracy: 0.9875 - val_loss: 2.2244 - val_accuracy: 0.8000\n",
      "Epoch 428/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0171 - accuracy: 0.9875 - val_loss: 2.3318 - val_accuracy: 0.8000\n",
      "Epoch 429/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.0143 - accuracy: 0.9875 - val_loss: 2.4322 - val_accuracy: 0.8000\n",
      "Epoch 430/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0150 - accuracy: 0.9875 - val_loss: 2.4505 - val_accuracy: 0.8000\n",
      "Epoch 431/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.4512 - val_accuracy: 0.8000\n",
      "Epoch 432/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.4698 - val_accuracy: 0.8000\n",
      "Epoch 433/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0138 - accuracy: 0.9875 - val_loss: 2.4812 - val_accuracy: 0.8000\n",
      "Epoch 434/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.4754 - val_accuracy: 0.8000\n",
      "Epoch 435/2000\n",
      "80/80 [==============================] - 0s 60us/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 2.4680 - val_accuracy: 0.8000\n",
      "Epoch 436/2000\n",
      "80/80 [==============================] - 0s 209us/sample - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.4838 - val_accuracy: 0.8000\n",
      "Epoch 437/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.4842 - val_accuracy: 0.8000\n",
      "Epoch 438/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.4754 - val_accuracy: 0.8000\n",
      "Epoch 439/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.5039 - val_accuracy: 0.8000\n",
      "Epoch 440/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.4954 - val_accuracy: 0.8000\n",
      "Epoch 441/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.0121 - accuracy: 1.0000 - val_loss: 2.4921 - val_accuracy: 0.8000\n",
      "Epoch 442/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.4704 - val_accuracy: 0.8000\n",
      "Epoch 443/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.4701 - val_accuracy: 0.8000\n",
      "Epoch 444/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.4830 - val_accuracy: 0.8000\n",
      "Epoch 445/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.5101 - val_accuracy: 0.8000\n",
      "Epoch 446/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 2.5120 - val_accuracy: 0.8000\n",
      "Epoch 447/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.5041 - val_accuracy: 0.8000\n",
      "Epoch 448/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.5032 - val_accuracy: 0.8000\n",
      "Epoch 449/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.4859 - val_accuracy: 0.8000\n",
      "Epoch 450/2000\n",
      "80/80 [==============================] - 0s 191us/sample - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.5011 - val_accuracy: 0.8000\n",
      "Epoch 451/2000\n",
      "80/80 [==============================] - 0s 262us/sample - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.5014 - val_accuracy: 0.8000\n",
      "Epoch 452/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.5135 - val_accuracy: 0.8000\n",
      "Epoch 453/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.5121 - val_accuracy: 0.8000\n",
      "Epoch 454/2000\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.5329 - val_accuracy: 0.8000\n",
      "Epoch 455/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.0119 - accuracy: 1.0000 - val_loss: 2.5239 - val_accuracy: 0.8000\n",
      "Epoch 456/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.4743 - val_accuracy: 0.8000\n",
      "Epoch 457/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.0166 - accuracy: 0.9875 - val_loss: 2.4610 - val_accuracy: 0.8000\n",
      "Epoch 458/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.0166 - accuracy: 0.9875 - val_loss: 2.5047 - val_accuracy: 0.8000\n",
      "Epoch 459/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.5178 - val_accuracy: 0.8000\n",
      "Epoch 460/2000\n",
      "80/80 [==============================] - 0s 74us/sample - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.5380 - val_accuracy: 0.8000\n",
      "Epoch 461/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.0130 - accuracy: 0.9875 - val_loss: 2.5407 - val_accuracy: 0.8000\n",
      "Epoch 462/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.4942 - val_accuracy: 0.8000\n",
      "Epoch 463/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.5313 - val_accuracy: 0.8000\n",
      "Epoch 464/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.5808 - val_accuracy: 0.8000\n",
      "Epoch 465/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0214 - accuracy: 0.9875 - val_loss: 2.5503 - val_accuracy: 0.8000\n",
      "Epoch 466/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0159 - accuracy: 0.9875 - val_loss: 2.4035 - val_accuracy: 0.8000\n",
      "Epoch 467/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.0294 - accuracy: 0.9875 - val_loss: 2.3734 - val_accuracy: 0.8000\n",
      "Epoch 468/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0282 - accuracy: 0.9875 - val_loss: 2.4175 - val_accuracy: 0.8000\n",
      "Epoch 469/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.0163 - accuracy: 0.9875 - val_loss: 2.5475 - val_accuracy: 0.8000\n",
      "Epoch 470/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0125 - accuracy: 0.9875 - val_loss: 2.5836 - val_accuracy: 0.8000\n",
      "Epoch 471/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0202 - accuracy: 0.9875 - val_loss: 2.5467 - val_accuracy: 0.8000\n",
      "Epoch 472/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.0136 - accuracy: 0.9875 - val_loss: 2.4455 - val_accuracy: 0.8000\n",
      "Epoch 473/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.4103 - val_accuracy: 0.8000\n",
      "Epoch 474/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0203 - accuracy: 0.9875 - val_loss: 2.4137 - val_accuracy: 0.8000\n",
      "Epoch 475/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.0125 - accuracy: 0.9875 - val_loss: 2.5578 - val_accuracy: 0.8000\n",
      "Epoch 476/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0281 - accuracy: 0.9875 - val_loss: 2.6181 - val_accuracy: 0.7500\n",
      "Epoch 477/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0295 - accuracy: 0.9875 - val_loss: 2.5053 - val_accuracy: 0.8000\n",
      "Epoch 478/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0125 - accuracy: 0.9875 - val_loss: 2.4048 - val_accuracy: 0.8000\n",
      "Epoch 479/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0221 - accuracy: 0.9875 - val_loss: 2.3494 - val_accuracy: 0.8000\n",
      "Epoch 480/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.0112 - accuracy: 0.9875 - val_loss: 2.4005 - val_accuracy: 0.8000\n",
      "Epoch 481/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0165 - accuracy: 0.9875 - val_loss: 2.4446 - val_accuracy: 0.8000\n",
      "Epoch 482/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.0173 - accuracy: 0.9875 - val_loss: 2.3980 - val_accuracy: 0.8000\n",
      "Epoch 483/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.4223 - val_accuracy: 0.8000\n",
      "Epoch 484/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.4518 - val_accuracy: 0.8000\n",
      "Epoch 485/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.4228 - val_accuracy: 0.8000\n",
      "Epoch 486/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.0122 - accuracy: 0.9875 - val_loss: 2.4516 - val_accuracy: 0.8000\n",
      "Epoch 487/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.4983 - val_accuracy: 0.8000\n",
      "Epoch 488/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.0133 - accuracy: 0.9875 - val_loss: 2.5204 - val_accuracy: 0.8000\n",
      "Epoch 489/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0147 - accuracy: 0.9875 - val_loss: 2.5060 - val_accuracy: 0.8000\n",
      "Epoch 490/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.4665 - val_accuracy: 0.8000\n",
      "Epoch 491/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0111 - accuracy: 0.9875 - val_loss: 2.4584 - val_accuracy: 0.8000\n",
      "Epoch 492/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0122 - accuracy: 0.9875 - val_loss: 2.4755 - val_accuracy: 0.8000\n",
      "Epoch 493/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.5005 - val_accuracy: 0.8000\n",
      "Epoch 494/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.0159 - accuracy: 0.9875 - val_loss: 2.5413 - val_accuracy: 0.8000\n",
      "Epoch 495/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.5076 - val_accuracy: 0.8000\n",
      "Epoch 496/2000\n",
      "80/80 [==============================] - 0s 173us/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.4753 - val_accuracy: 0.8000\n",
      "Epoch 497/2000\n",
      "80/80 [==============================] - 0s 584us/sample - loss: 0.0147 - accuracy: 0.9875 - val_loss: 2.4846 - val_accuracy: 0.8000\n",
      "Epoch 498/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.0128 - accuracy: 0.9875 - val_loss: 2.5103 - val_accuracy: 0.8000\n",
      "Epoch 499/2000\n",
      "80/80 [==============================] - 0s 204us/sample - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.5429 - val_accuracy: 0.8000\n",
      "Epoch 500/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.5612 - val_accuracy: 0.8000\n",
      "Epoch 501/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.0116 - accuracy: 0.9875 - val_loss: 2.5408 - val_accuracy: 0.8000\n",
      "Epoch 502/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0119 - accuracy: 1.0000 - val_loss: 2.4765 - val_accuracy: 0.8000\n",
      "Epoch 503/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.0136 - accuracy: 0.9875 - val_loss: 2.4642 - val_accuracy: 0.8000\n",
      "Epoch 504/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0140 - accuracy: 0.9875 - val_loss: 2.4902 - val_accuracy: 0.8000\n",
      "Epoch 505/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.5181 - val_accuracy: 0.8000\n",
      "Epoch 506/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.5606 - val_accuracy: 0.8000\n",
      "Epoch 507/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 1.8736e-05 - accuracy: 1.00 - 0s 108us/sample - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.5588 - val_accuracy: 0.8000\n",
      "Epoch 508/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.5372 - val_accuracy: 0.8000\n",
      "Epoch 509/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.4829 - val_accuracy: 0.8000\n",
      "Epoch 510/2000\n",
      "80/80 [==============================] - 0s 218us/sample - loss: 0.0114 - accuracy: 0.9875 - val_loss: 2.5037 - val_accuracy: 0.8000\n",
      "Epoch 511/2000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.0109 - accuracy: 0.9875 - val_loss: 2.5215 - val_accuracy: 0.8000\n",
      "Epoch 512/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.5791 - val_accuracy: 0.8000\n",
      "Epoch 513/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0134 - accuracy: 0.9875 - val_loss: 2.5749 - val_accuracy: 0.8000\n",
      "Epoch 514/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.5175 - val_accuracy: 0.8000\n",
      "Epoch 515/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.5139 - val_accuracy: 0.8000\n",
      "Epoch 516/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.5390 - val_accuracy: 0.8000\n",
      "Epoch 517/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.5464 - val_accuracy: 0.8000\n",
      "Epoch 518/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.5208 - val_accuracy: 0.8000\n",
      "Epoch 519/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.5195 - val_accuracy: 0.8000\n",
      "Epoch 520/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.5147 - val_accuracy: 0.8000\n",
      "Epoch 521/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.5264 - val_accuracy: 0.8000\n",
      "Epoch 522/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.5493 - val_accuracy: 0.8000\n",
      "Epoch 523/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.5726 - val_accuracy: 0.8000\n",
      "Epoch 524/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.5414 - val_accuracy: 0.8000\n",
      "Epoch 525/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.5329 - val_accuracy: 0.8000\n",
      "Epoch 526/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.5179 - val_accuracy: 0.8000\n",
      "Epoch 527/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.5439 - val_accuracy: 0.8000\n",
      "Epoch 528/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.6070 - val_accuracy: 0.8000\n",
      "Epoch 529/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0137 - accuracy: 0.9875 - val_loss: 2.6082 - val_accuracy: 0.8000\n",
      "Epoch 530/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.0130 - accuracy: 0.9875 - val_loss: 2.5393 - val_accuracy: 0.8000\n",
      "Epoch 531/2000\n",
      "80/80 [==============================] - 0s 212us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.5351 - val_accuracy: 0.8000\n",
      "Epoch 532/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.5390 - val_accuracy: 0.8000\n",
      "Epoch 533/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.5536 - val_accuracy: 0.8000\n",
      "Epoch 534/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.5555 - val_accuracy: 0.8000\n",
      "Epoch 535/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 1.8203e-04 - accuracy: 1.00 - 0s 61us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.5273 - val_accuracy: 0.8000\n",
      "Epoch 536/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.5299 - val_accuracy: 0.8000\n",
      "Epoch 537/2000\n",
      "80/80 [==============================] - 0s 199us/sample - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.5561 - val_accuracy: 0.8000\n",
      "Epoch 538/2000\n",
      "80/80 [==============================] - 0s 192us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.5573 - val_accuracy: 0.8000\n",
      "Epoch 539/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.5679 - val_accuracy: 0.8000\n",
      "Epoch 540/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.5906 - val_accuracy: 0.8000\n",
      "Epoch 541/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.5293 - val_accuracy: 0.8000\n",
      "Epoch 542/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.0101 - accuracy: 0.9875 - val_loss: 2.5316 - val_accuracy: 0.8000\n",
      "Epoch 543/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.5773 - val_accuracy: 0.8000\n",
      "Epoch 544/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.6052 - val_accuracy: 0.8000\n",
      "Epoch 545/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.6156 - val_accuracy: 0.8000\n",
      "Epoch 546/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.5584 - val_accuracy: 0.8000\n",
      "Epoch 547/2000\n",
      "80/80 [==============================] - 0s 284us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.5103 - val_accuracy: 0.8000\n",
      "Epoch 548/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0169 - accuracy: 0.9875 - val_loss: 2.5135 - val_accuracy: 0.8000\n",
      "Epoch 549/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.0110 - accuracy: 0.9875 - val_loss: 2.6146 - val_accuracy: 0.8000\n",
      "Epoch 550/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.0124 - accuracy: 0.9875 - val_loss: 2.6453 - val_accuracy: 0.8000\n",
      "Epoch 551/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.0123 - accuracy: 0.9875 - val_loss: 2.5645 - val_accuracy: 0.8000\n",
      "Epoch 552/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.5236 - val_accuracy: 0.8000\n",
      "Epoch 553/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0104 - accuracy: 0.9875 - val_loss: 2.5140 - val_accuracy: 0.8000\n",
      "Epoch 554/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.5640 - val_accuracy: 0.8000\n",
      "Epoch 555/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.7202 - val_accuracy: 0.7000\n",
      "Epoch 556/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.0186 - accuracy: 0.9875 - val_loss: 2.6785 - val_accuracy: 0.7000\n",
      "Epoch 557/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0131 - accuracy: 0.9875 - val_loss: 2.5534 - val_accuracy: 0.8000\n",
      "Epoch 558/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.5136 - val_accuracy: 0.8000\n",
      "Epoch 559/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0106 - accuracy: 0.9875 - val_loss: 2.5405 - val_accuracy: 0.8000\n",
      "Epoch 560/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.6055 - val_accuracy: 0.8000\n",
      "Epoch 561/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.6254 - val_accuracy: 0.8000\n",
      "Epoch 562/2000\n",
      "80/80 [==============================] - 0s 28us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.5782 - val_accuracy: 0.8000\n",
      "Epoch 563/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.5465 - val_accuracy: 0.8000\n",
      "Epoch 564/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.5451 - val_accuracy: 0.8000\n",
      "Epoch 565/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.5743 - val_accuracy: 0.8000\n",
      "Epoch 566/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.5654 - val_accuracy: 0.8000\n",
      "Epoch 567/2000\n",
      "80/80 [==============================] - 0s 207us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.5627 - val_accuracy: 0.8000\n",
      "Epoch 568/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.6051 - val_accuracy: 0.8000\n",
      "Epoch 569/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.5927 - val_accuracy: 0.8000\n",
      "Epoch 570/2000\n",
      "80/80 [==============================] - 0s 182us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.5531 - val_accuracy: 0.8000\n",
      "Epoch 571/2000\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.5664 - val_accuracy: 0.8000\n",
      "Epoch 572/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.5949 - val_accuracy: 0.8000\n",
      "Epoch 573/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.6306 - val_accuracy: 0.8000\n",
      "Epoch 574/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.6565 - val_accuracy: 0.7500\n",
      "Epoch 575/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.6297 - val_accuracy: 0.8000\n",
      "Epoch 576/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.5781 - val_accuracy: 0.8000\n",
      "Epoch 577/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0103 - accuracy: 0.9875 - val_loss: 2.5663 - val_accuracy: 0.8000\n",
      "Epoch 578/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.6829 - val_accuracy: 0.7500\n",
      "Epoch 579/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.6725 - val_accuracy: 0.7500\n",
      "Epoch 580/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.5955 - val_accuracy: 0.8000\n",
      "Epoch 581/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.5802 - val_accuracy: 0.8000\n",
      "Epoch 582/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.5780 - val_accuracy: 0.8000\n",
      "Epoch 583/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.5832 - val_accuracy: 0.8000\n",
      "Epoch 584/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.5892 - val_accuracy: 0.8000\n",
      "Epoch 585/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.6111 - val_accuracy: 0.8000\n",
      "Epoch 586/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.5817 - val_accuracy: 0.8000\n",
      "Epoch 587/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.6949 - val_accuracy: 0.7500\n",
      "Epoch 588/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0118 - accuracy: 0.9875 - val_loss: 2.6704 - val_accuracy: 0.7500\n",
      "Epoch 589/2000\n",
      "80/80 [==============================] - 0s 235us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.5828 - val_accuracy: 0.8000\n",
      "Epoch 590/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.5104 - val_accuracy: 0.8000\n",
      "Epoch 591/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.0136 - accuracy: 0.9875 - val_loss: 2.5518 - val_accuracy: 0.8000\n",
      "Epoch 592/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.6241 - val_accuracy: 0.8000\n",
      "Epoch 593/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.6751 - val_accuracy: 0.7500\n",
      "Epoch 594/2000\n",
      "80/80 [==============================] - 0s 16us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.6197 - val_accuracy: 0.8000\n",
      "Epoch 595/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.5986 - val_accuracy: 0.8000\n",
      "Epoch 596/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.5971 - val_accuracy: 0.8000\n",
      "Epoch 597/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.6214 - val_accuracy: 0.8000\n",
      "Epoch 598/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.6352 - val_accuracy: 0.7500\n",
      "Epoch 599/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.6530 - val_accuracy: 0.7500\n",
      "Epoch 600/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.5591 - val_accuracy: 0.8000\n",
      "Epoch 601/2000\n",
      "80/80 [==============================] - 0s 180us/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.5744 - val_accuracy: 0.8000\n",
      "Epoch 602/2000\n",
      "80/80 [==============================] - 0s 12us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.6356 - val_accuracy: 0.7500\n",
      "Epoch 603/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.6256 - val_accuracy: 0.8000\n",
      "Epoch 604/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.6010 - val_accuracy: 0.8000\n",
      "Epoch 605/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.6730 - val_accuracy: 0.7500\n",
      "Epoch 606/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.6800 - val_accuracy: 0.7500\n",
      "Epoch 607/2000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.6223 - val_accuracy: 0.7500\n",
      "Epoch 608/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.5783 - val_accuracy: 0.8000\n",
      "Epoch 609/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.6058 - val_accuracy: 0.8000\n",
      "Epoch 610/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.6656 - val_accuracy: 0.7500\n",
      "Epoch 611/2000\n",
      "80/80 [==============================] - 0s 305us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.6806 - val_accuracy: 0.7500\n",
      "Epoch 612/2000\n",
      "80/80 [==============================] - 0s 166us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.6636 - val_accuracy: 0.7500\n",
      "Epoch 613/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.6354 - val_accuracy: 0.7500\n",
      "Epoch 614/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.6796 - val_accuracy: 0.7500\n",
      "Epoch 615/2000\n",
      "80/80 [==============================] - 0s 155us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.7032 - val_accuracy: 0.7000\n",
      "Epoch 616/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.6751 - val_accuracy: 0.7500\n",
      "Epoch 617/2000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.6405 - val_accuracy: 0.7500\n",
      "Epoch 618/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.6747 - val_accuracy: 0.7500\n",
      "Epoch 619/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.7320 - val_accuracy: 0.7000\n",
      "Epoch 620/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.5869 - val_accuracy: 0.8000\n",
      "Epoch 621/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 0.0099 - accuracy: 0.9875 - val_loss: 2.6012 - val_accuracy: 0.7500\n",
      "Epoch 622/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.7502 - val_accuracy: 0.7000\n",
      "Epoch 623/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.7411 - val_accuracy: 0.7000\n",
      "Epoch 624/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.6452 - val_accuracy: 0.7500\n",
      "Epoch 625/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.0092 - accuracy: 0.9875 - val_loss: 2.6279 - val_accuracy: 0.7500\n",
      "Epoch 626/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.8145 - val_accuracy: 0.7000\n",
      "Epoch 627/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.0235 - accuracy: 0.9875 - val_loss: 2.6840 - val_accuracy: 0.7000\n",
      "Epoch 628/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.4041 - val_accuracy: 0.8000\n",
      "Epoch 629/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.0738 - accuracy: 0.9875 - val_loss: 2.3886 - val_accuracy: 0.8000\n",
      "Epoch 630/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.0755 - accuracy: 0.9875 - val_loss: 2.4903 - val_accuracy: 0.8000\n",
      "Epoch 631/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0207 - accuracy: 0.9875 - val_loss: 2.8482 - val_accuracy: 0.7000\n",
      "Epoch 632/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0506 - accuracy: 0.9875 - val_loss: 2.9735 - val_accuracy: 0.7000\n",
      "Epoch 633/2000\n",
      "80/80 [==============================] - 0s 189us/sample - loss: 0.0281 - accuracy: 0.9875 - val_loss: 2.5927 - val_accuracy: 0.7000\n",
      "Epoch 634/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.00 - 0s 228us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.2958 - val_accuracy: 0.8000\n",
      "Epoch 635/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0413 - accuracy: 0.9875 - val_loss: 2.3514 - val_accuracy: 0.8000\n",
      "Epoch 636/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.0424 - accuracy: 0.9875 - val_loss: 2.4167 - val_accuracy: 0.8000\n",
      "Epoch 637/2000\n",
      "80/80 [==============================] - 0s 179us/sample - loss: 0.0254 - accuracy: 0.9875 - val_loss: 2.5291 - val_accuracy: 0.7000\n",
      "Epoch 638/2000\n",
      "80/80 [==============================] - 0s 70us/sample - loss: 0.0153 - accuracy: 0.9875 - val_loss: 2.6083 - val_accuracy: 0.7000\n",
      "Epoch 639/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.0120 - accuracy: 1.0000 - val_loss: 2.6010 - val_accuracy: 0.7000\n",
      "Epoch 640/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.5575 - val_accuracy: 0.7000\n",
      "Epoch 641/2000\n",
      "80/80 [==============================] - 0s 45us/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.5268 - val_accuracy: 0.7000\n",
      "Epoch 642/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.4921 - val_accuracy: 0.7500\n",
      "Epoch 643/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.4662 - val_accuracy: 0.8000\n",
      "Epoch 644/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.4666 - val_accuracy: 0.8000\n",
      "Epoch 645/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.4898 - val_accuracy: 0.8000\n",
      "Epoch 646/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.4950 - val_accuracy: 0.8000\n",
      "Epoch 647/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.4920 - val_accuracy: 0.8000\n",
      "Epoch 648/2000\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.5007 - val_accuracy: 0.8000\n",
      "Epoch 649/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.5088 - val_accuracy: 0.8000\n",
      "Epoch 650/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.5138 - val_accuracy: 0.8000\n",
      "Epoch 651/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.5095 - val_accuracy: 0.8000\n",
      "Epoch 652/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.5110 - val_accuracy: 0.8000\n",
      "Epoch 653/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.5352 - val_accuracy: 0.8000\n",
      "Epoch 654/2000\n",
      "80/80 [==============================] - 0s 232us/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.5403 - val_accuracy: 0.8000\n",
      "Epoch 655/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.5269 - val_accuracy: 0.8000\n",
      "Epoch 656/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.4954 - val_accuracy: 0.8000\n",
      "Epoch 657/2000\n",
      "80/80 [==============================] - 0s 48us/sample - loss: 0.0146 - accuracy: 0.9875 - val_loss: 2.4979 - val_accuracy: 0.8000\n",
      "Epoch 658/2000\n",
      "80/80 [==============================] - 0s 18us/sample - loss: 0.0132 - accuracy: 0.9875 - val_loss: 2.5284 - val_accuracy: 0.8000\n",
      "Epoch 659/2000\n",
      "80/80 [==============================] - 0s 289us/sample - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.5599 - val_accuracy: 0.8000\n",
      "Epoch 660/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.5587 - val_accuracy: 0.8000\n",
      "Epoch 661/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.5673 - val_accuracy: 0.8000\n",
      "Epoch 662/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.5682 - val_accuracy: 0.8000\n",
      "Epoch 663/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.5739 - val_accuracy: 0.8000\n",
      "Epoch 664/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.5737 - val_accuracy: 0.8000\n",
      "Epoch 665/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.5404 - val_accuracy: 0.8000\n",
      "Epoch 666/2000\n",
      "80/80 [==============================] - 0s 53us/sample - loss: 0.0104 - accuracy: 0.9875 - val_loss: 2.5331 - val_accuracy: 0.8000\n",
      "Epoch 667/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.5515 - val_accuracy: 0.8000\n",
      "Epoch 668/2000\n",
      "80/80 [==============================] - 0s 159us/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.5729 - val_accuracy: 0.8000\n",
      "Epoch 669/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.6186 - val_accuracy: 0.8000\n",
      "Epoch 670/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.0118 - accuracy: 0.9875 - val_loss: 2.6268 - val_accuracy: 0.8000\n",
      "Epoch 671/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0114 - accuracy: 0.9875 - val_loss: 2.5998 - val_accuracy: 0.8000\n",
      "Epoch 672/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.5655 - val_accuracy: 0.8000\n",
      "Epoch 673/2000\n",
      "80/80 [==============================] - 0s 224us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.5573 - val_accuracy: 0.8000\n",
      "Epoch 674/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.5593 - val_accuracy: 0.8000\n",
      "Epoch 675/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.5718 - val_accuracy: 0.8000\n",
      "Epoch 676/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.5891 - val_accuracy: 0.8000\n",
      "Epoch 677/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.6057 - val_accuracy: 0.8000\n",
      "Epoch 678/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.6245 - val_accuracy: 0.8000\n",
      "Epoch 679/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0118 - accuracy: 0.9875 - val_loss: 2.6261 - val_accuracy: 0.8000\n",
      "Epoch 680/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.5557 - val_accuracy: 0.8000\n",
      "Epoch 681/2000\n",
      "80/80 [==============================] - 0s 62us/sample - loss: 0.0168 - accuracy: 0.9875 - val_loss: 2.5426 - val_accuracy: 0.8000\n",
      "Epoch 682/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0164 - accuracy: 0.9875 - val_loss: 2.6268 - val_accuracy: 0.8000\n",
      "Epoch 683/2000\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.0109 - accuracy: 0.9875 - val_loss: 2.6161 - val_accuracy: 0.8000\n",
      "Epoch 684/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.5768 - val_accuracy: 0.8000\n",
      "Epoch 685/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.5315 - val_accuracy: 0.8000\n",
      "Epoch 686/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0109 - accuracy: 0.9875 - val_loss: 2.5291 - val_accuracy: 0.8000\n",
      "Epoch 687/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0118 - accuracy: 0.9875 - val_loss: 2.5535 - val_accuracy: 0.8000\n",
      "Epoch 688/2000\n",
      "80/80 [==============================] - 0s 222us/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.6404 - val_accuracy: 0.7500\n",
      "Epoch 689/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.0114 - accuracy: 0.9875 - val_loss: 2.6548 - val_accuracy: 0.7500\n",
      "Epoch 690/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.0145 - accuracy: 0.9875 - val_loss: 2.6233 - val_accuracy: 0.7500\n",
      "Epoch 691/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.5785 - val_accuracy: 0.8000\n",
      "Epoch 692/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.5581 - val_accuracy: 0.8000\n",
      "Epoch 693/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.5571 - val_accuracy: 0.8000\n",
      "Epoch 694/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.5707 - val_accuracy: 0.8000\n",
      "Epoch 695/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.5915 - val_accuracy: 0.8000\n",
      "Epoch 696/2000\n",
      "80/80 [==============================] - 0s 49us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.6227 - val_accuracy: 0.8000\n",
      "Epoch 697/2000\n",
      "80/80 [==============================] - 0s 186us/sample - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.6121 - val_accuracy: 0.8000\n",
      "Epoch 698/2000\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.5810 - val_accuracy: 0.8000\n",
      "Epoch 699/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.0111 - accuracy: 0.9875 - val_loss: 2.5553 - val_accuracy: 0.8000\n",
      "Epoch 700/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.5894 - val_accuracy: 0.8000\n",
      "Epoch 701/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.6379 - val_accuracy: 0.7500\n",
      "Epoch 702/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.6171 - val_accuracy: 0.8000\n",
      "Epoch 703/2000\n",
      "80/80 [==============================] - 0s 163us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.5916 - val_accuracy: 0.8000\n",
      "Epoch 704/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.5538 - val_accuracy: 0.8000\n",
      "Epoch 705/2000\n",
      "80/80 [==============================] - 0s 155us/sample - loss: 0.0120 - accuracy: 0.9875 - val_loss: 2.5547 - val_accuracy: 0.8000\n",
      "Epoch 706/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.5987 - val_accuracy: 0.8000\n",
      "Epoch 707/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.6322 - val_accuracy: 0.8000\n",
      "Epoch 708/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.6093 - val_accuracy: 0.8000\n",
      "Epoch 709/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.5999 - val_accuracy: 0.8000\n",
      "Epoch 710/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.5878 - val_accuracy: 0.8000\n",
      "Epoch 711/2000\n",
      "80/80 [==============================] - 0s 69us/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.5818 - val_accuracy: 0.8000\n",
      "Epoch 712/2000\n",
      "80/80 [==============================] - 0s 194us/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.6267 - val_accuracy: 0.8000\n",
      "Epoch 713/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.6119 - val_accuracy: 0.8000\n",
      "Epoch 714/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.5448 - val_accuracy: 0.8000\n",
      "Epoch 715/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0134 - accuracy: 0.9875 - val_loss: 2.5473 - val_accuracy: 0.8000\n",
      "Epoch 716/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.0138 - accuracy: 0.9875 - val_loss: 2.5893 - val_accuracy: 0.8000\n",
      "Epoch 717/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.6279 - val_accuracy: 0.8000\n",
      "Epoch 718/2000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.6252 - val_accuracy: 0.8000\n",
      "Epoch 719/2000\n",
      "80/80 [==============================] - 0s 77us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.5711 - val_accuracy: 0.8000\n",
      "Epoch 720/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.0107 - accuracy: 0.9875 - val_loss: 2.5645 - val_accuracy: 0.8000\n",
      "Epoch 721/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0099 - accuracy: 0.9875 - val_loss: 2.6043 - val_accuracy: 0.8000\n",
      "Epoch 722/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.6346 - val_accuracy: 0.8000\n",
      "Epoch 723/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.6276 - val_accuracy: 0.8000\n",
      "Epoch 724/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.6066 - val_accuracy: 0.8000\n",
      "Epoch 725/2000\n",
      "80/80 [==============================] - 0s 550us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.5927 - val_accuracy: 0.8000\n",
      "Epoch 726/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.6005 - val_accuracy: 0.8000\n",
      "Epoch 727/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.6743 - val_accuracy: 0.7500\n",
      "Epoch 728/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0131 - accuracy: 0.9875 - val_loss: 2.6528 - val_accuracy: 0.8000\n",
      "Epoch 729/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.5495 - val_accuracy: 0.8000\n",
      "Epoch 730/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.0386 - accuracy: 0.9875 - val_loss: 2.5385 - val_accuracy: 0.8000\n",
      "Epoch 731/2000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.0301 - accuracy: 0.9875 - val_loss: 2.6142 - val_accuracy: 0.8000\n",
      "Epoch 732/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.7194 - val_accuracy: 0.7500\n",
      "Epoch 733/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.0166 - accuracy: 0.9875 - val_loss: 2.6817 - val_accuracy: 0.7500\n",
      "Epoch 734/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.6130 - val_accuracy: 0.8000\n",
      "Epoch 735/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.5737 - val_accuracy: 0.8000\n",
      "Epoch 736/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.5690 - val_accuracy: 0.8000\n",
      "Epoch 737/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.5818 - val_accuracy: 0.8000\n",
      "Epoch 738/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.6215 - val_accuracy: 0.8000\n",
      "Epoch 739/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.6267 - val_accuracy: 0.8000\n",
      "Epoch 740/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.5726 - val_accuracy: 0.8000\n",
      "Epoch 741/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.0153 - accuracy: 0.9875 - val_loss: 2.5775 - val_accuracy: 0.8000\n",
      "Epoch 742/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.7348 - val_accuracy: 0.7500\n",
      "Epoch 743/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.0200 - accuracy: 0.9875 - val_loss: 2.7461 - val_accuracy: 0.7500\n",
      "Epoch 744/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.0239 - accuracy: 0.9875 - val_loss: 2.6193 - val_accuracy: 0.8000\n",
      "Epoch 745/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.5706 - val_accuracy: 0.8000\n",
      "Epoch 746/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.5760 - val_accuracy: 0.8000\n",
      "Epoch 747/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.5858 - val_accuracy: 0.8000\n",
      "Epoch 748/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.5906 - val_accuracy: 0.8000\n",
      "Epoch 749/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.5950 - val_accuracy: 0.8000\n",
      "Epoch 750/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.5970 - val_accuracy: 0.8000\n",
      "Epoch 751/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.6019 - val_accuracy: 0.8000\n",
      "Epoch 752/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.6092 - val_accuracy: 0.8000\n",
      "Epoch 753/2000\n",
      "80/80 [==============================] - 0s 156us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6185 - val_accuracy: 0.8000\n",
      "Epoch 754/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6304 - val_accuracy: 0.8000\n",
      "Epoch 755/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.6346 - val_accuracy: 0.8000\n",
      "Epoch 756/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.6263 - val_accuracy: 0.8000\n",
      "Epoch 757/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.6241 - val_accuracy: 0.8000\n",
      "Epoch 758/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.6116 - val_accuracy: 0.8000\n",
      "Epoch 759/2000\n",
      "80/80 [==============================] - 0s 232us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.6117 - val_accuracy: 0.8000\n",
      "Epoch 760/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.6265 - val_accuracy: 0.8000\n",
      "Epoch 761/2000\n",
      "80/80 [==============================] - 0s 56us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.6378 - val_accuracy: 0.8000\n",
      "Epoch 762/2000\n",
      "80/80 [==============================] - 0s 164us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.6281 - val_accuracy: 0.8000\n",
      "Epoch 763/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.6294 - val_accuracy: 0.8000\n",
      "Epoch 764/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.6304 - val_accuracy: 0.8000\n",
      "Epoch 765/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6379 - val_accuracy: 0.8000\n",
      "Epoch 766/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.6548 - val_accuracy: 0.8000\n",
      "Epoch 767/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.6579 - val_accuracy: 0.8000\n",
      "Epoch 768/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.6492 - val_accuracy: 0.8000\n",
      "Epoch 769/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.6439 - val_accuracy: 0.8000\n",
      "Epoch 770/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6446 - val_accuracy: 0.8000\n",
      "Epoch 771/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6517 - val_accuracy: 0.8000\n",
      "Epoch 772/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.6688 - val_accuracy: 0.8000\n",
      "Epoch 773/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6795 - val_accuracy: 0.8000\n",
      "Epoch 774/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6600 - val_accuracy: 0.8000\n",
      "Epoch 775/2000\n",
      "80/80 [==============================] - 0s 74us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6499 - val_accuracy: 0.8000\n",
      "Epoch 776/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6477 - val_accuracy: 0.8000\n",
      "Epoch 777/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.6609 - val_accuracy: 0.8000\n",
      "Epoch 778/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6687 - val_accuracy: 0.8000\n",
      "Epoch 779/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6749 - val_accuracy: 0.8000\n",
      "Epoch 780/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6741 - val_accuracy: 0.8000\n",
      "Epoch 781/2000\n",
      "80/80 [==============================] - 0s 317us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.6514 - val_accuracy: 0.8000\n",
      "Epoch 782/2000\n",
      "80/80 [==============================] - 0s 156us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.6523 - val_accuracy: 0.8000\n",
      "Epoch 783/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.6662 - val_accuracy: 0.8000\n",
      "Epoch 784/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7073 - val_accuracy: 0.7500\n",
      "Epoch 785/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.6967 - val_accuracy: 0.8000\n",
      "Epoch 786/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.6277 - val_accuracy: 0.8000\n",
      "Epoch 787/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.0115 - accuracy: 0.9875 - val_loss: 2.6385 - val_accuracy: 0.8000\n",
      "Epoch 788/2000\n",
      "80/80 [==============================] - 0s 239us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.7230 - val_accuracy: 0.7500\n",
      "Epoch 789/2000\n",
      "80/80 [==============================] - 0s 155us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.7316 - val_accuracy: 0.7500\n",
      "Epoch 790/2000\n",
      "80/80 [==============================] - 0s 155us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.6509 - val_accuracy: 0.8000\n",
      "Epoch 791/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.6283 - val_accuracy: 0.8000\n",
      "Epoch 792/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.6554 - val_accuracy: 0.8000\n",
      "Epoch 793/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6831 - val_accuracy: 0.8000\n",
      "Epoch 794/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.6942 - val_accuracy: 0.7500\n",
      "Epoch 795/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6804 - val_accuracy: 0.8000\n",
      "Epoch 796/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6686 - val_accuracy: 0.8000\n",
      "Epoch 797/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6616 - val_accuracy: 0.8000\n",
      "Epoch 798/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.6650 - val_accuracy: 0.8000\n",
      "Epoch 799/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.6737 - val_accuracy: 0.8000\n",
      "Epoch 800/2000\n",
      "80/80 [==============================] - 0s 74us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6807 - val_accuracy: 0.8000\n",
      "Epoch 801/2000\n",
      "80/80 [==============================] - 0s 155us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6827 - val_accuracy: 0.8000\n",
      "Epoch 802/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6790 - val_accuracy: 0.8000\n",
      "Epoch 803/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6799 - val_accuracy: 0.8000\n",
      "Epoch 804/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6788 - val_accuracy: 0.8000\n",
      "Epoch 805/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6752 - val_accuracy: 0.8000\n",
      "Epoch 806/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.6813 - val_accuracy: 0.8000\n",
      "Epoch 807/2000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.7093 - val_accuracy: 0.8000\n",
      "Epoch 808/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7079 - val_accuracy: 0.8000\n",
      "Epoch 809/2000\n",
      "80/80 [==============================] - 0s 621us/sample - loss: 7.3012e-04 - accuracy: 1.0000 - val_loss: 2.6713 - val_accuracy: 0.8000\n",
      "Epoch 810/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.6577 - val_accuracy: 0.8000\n",
      "Epoch 811/2000\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.6704 - val_accuracy: 0.8000\n",
      "Epoch 812/2000\n",
      "80/80 [==============================] - 0s 174us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.6975 - val_accuracy: 0.8000\n",
      "Epoch 813/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7133 - val_accuracy: 0.8000\n",
      "Epoch 814/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7095 - val_accuracy: 0.8000\n",
      "Epoch 815/2000\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6905 - val_accuracy: 0.8000\n",
      "Epoch 816/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.6828 - val_accuracy: 0.8000\n",
      "Epoch 817/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.7014 - val_accuracy: 0.8000\n",
      "Epoch 818/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.7143 - val_accuracy: 0.8000\n",
      "Epoch 819/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.7096 - val_accuracy: 0.8000\n",
      "Epoch 820/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6981 - val_accuracy: 0.8000\n",
      "Epoch 821/2000\n",
      "80/80 [==============================] - 0s 154us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6999 - val_accuracy: 0.8000\n",
      "Epoch 822/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 9.7455e-04 - accuracy: 1.0000 - val_loss: 2.7068 - val_accuracy: 0.8000\n",
      "Epoch 823/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.7082 - val_accuracy: 0.8000\n",
      "Epoch 824/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6977 - val_accuracy: 0.8000\n",
      "Epoch 825/2000\n",
      "80/80 [==============================] - 0s 243us/sample - loss: 9.4274e-04 - accuracy: 1.0000 - val_loss: 2.6930 - val_accuracy: 0.8000\n",
      "Epoch 826/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 9.9426e-04 - accuracy: 1.0000 - val_loss: 2.6956 - val_accuracy: 0.8000\n",
      "Epoch 827/2000\n",
      "80/80 [==============================] - 0s 26us/sample - loss: 9.2968e-04 - accuracy: 1.0000 - val_loss: 2.6978 - val_accuracy: 0.8000\n",
      "Epoch 828/2000\n",
      "80/80 [==============================] - 0s 55us/sample - loss: 9.1468e-04 - accuracy: 1.0000 - val_loss: 2.7005 - val_accuracy: 0.8000\n",
      "Epoch 829/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 9.7754e-04 - accuracy: 1.0000 - val_loss: 2.7038 - val_accuracy: 0.8000\n",
      "Epoch 830/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 9.5822e-04 - accuracy: 1.0000 - val_loss: 2.7015 - val_accuracy: 0.8000\n",
      "Epoch 831/2000\n",
      "80/80 [==============================] - 0s 48us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6895 - val_accuracy: 0.8000\n",
      "Epoch 832/2000\n",
      "80/80 [==============================] - 0s 188us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6931 - val_accuracy: 0.8000\n",
      "Epoch 833/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 8.0349e-04 - accuracy: 1.0000 - val_loss: 2.7179 - val_accuracy: 0.8000\n",
      "Epoch 834/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7248 - val_accuracy: 0.8000\n",
      "Epoch 835/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6901 - val_accuracy: 0.8000\n",
      "Epoch 836/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.6837 - val_accuracy: 0.8000\n",
      "Epoch 837/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.6986 - val_accuracy: 0.8000\n",
      "Epoch 838/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 6.4042e-04 - accuracy: 1.0000 - val_loss: 2.7473 - val_accuracy: 0.7500\n",
      "Epoch 839/2000\n",
      "80/80 [==============================] - 0s 526us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.7562 - val_accuracy: 0.7500\n",
      "Epoch 840/2000\n",
      "80/80 [==============================] - 0s 220us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.7127 - val_accuracy: 0.8000\n",
      "Epoch 841/2000\n",
      "80/80 [==============================] - 0s 350us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.6944 - val_accuracy: 0.8000\n",
      "Epoch 842/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.7105 - val_accuracy: 0.8000\n",
      "Epoch 843/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 8.8752e-04 - accuracy: 1.0000 - val_loss: 2.7245 - val_accuracy: 0.8000\n",
      "Epoch 844/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 8.3520e-04 - accuracy: 1.0000 - val_loss: 2.7268 - val_accuracy: 0.8000\n",
      "Epoch 845/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 8.1505e-04 - accuracy: 1.0000 - val_loss: 2.7223 - val_accuracy: 0.8000\n",
      "Epoch 846/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 8.3686e-04 - accuracy: 1.0000 - val_loss: 2.7142 - val_accuracy: 0.8000\n",
      "Epoch 847/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 8.2643e-04 - accuracy: 1.0000 - val_loss: 2.7117 - val_accuracy: 0.8000\n",
      "Epoch 848/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 7.7188e-04 - accuracy: 1.0000 - val_loss: 2.7169 - val_accuracy: 0.8000\n",
      "Epoch 849/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 7.2817e-04 - accuracy: 1.0000 - val_loss: 2.7211 - val_accuracy: 0.8000\n",
      "Epoch 850/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 7.2456e-04 - accuracy: 1.0000 - val_loss: 2.7230 - val_accuracy: 0.8000\n",
      "Epoch 851/2000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 8.1543e-04 - accuracy: 1.0000 - val_loss: 2.7230 - val_accuracy: 0.8000\n",
      "Epoch 852/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 7.1570e-04 - accuracy: 1.0000 - val_loss: 2.7086 - val_accuracy: 0.8000\n",
      "Epoch 853/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 7.8505e-04 - accuracy: 1.0000 - val_loss: 2.7071 - val_accuracy: 0.8000\n",
      "Epoch 854/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 8.8595e-04 - accuracy: 1.0000 - val_loss: 2.7102 - val_accuracy: 0.8000\n",
      "Epoch 855/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 7.3884e-04 - accuracy: 1.0000 - val_loss: 2.7211 - val_accuracy: 0.8000\n",
      "Epoch 856/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 8.7604e-04 - accuracy: 1.0000 - val_loss: 2.7304 - val_accuracy: 0.8000\n",
      "Epoch 857/2000\n",
      "80/80 [==============================] - 0s 225us/sample - loss: 7.0853e-04 - accuracy: 1.0000 - val_loss: 2.7191 - val_accuracy: 0.8000\n",
      "Epoch 858/2000\n",
      "80/80 [==============================] - 0s 164us/sample - loss: 6.8109e-04 - accuracy: 1.0000 - val_loss: 2.7164 - val_accuracy: 0.8000\n",
      "Epoch 859/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 7.2129e-04 - accuracy: 1.0000 - val_loss: 2.7194 - val_accuracy: 0.8000\n",
      "Epoch 860/2000\n",
      "80/80 [==============================] - 0s 74us/sample - loss: 6.8882e-04 - accuracy: 1.0000 - val_loss: 2.7243 - val_accuracy: 0.8000\n",
      "Epoch 861/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 6.5837e-04 - accuracy: 1.0000 - val_loss: 2.7282 - val_accuracy: 0.8000\n",
      "Epoch 862/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 6.5041e-04 - accuracy: 1.0000 - val_loss: 2.7304 - val_accuracy: 0.8000\n",
      "Epoch 863/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 6.8185e-04 - accuracy: 1.0000 - val_loss: 2.7288 - val_accuracy: 0.8000\n",
      "Epoch 864/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 6.4088e-04 - accuracy: 1.0000 - val_loss: 2.7290 - val_accuracy: 0.8000\n",
      "Epoch 865/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 6.3406e-04 - accuracy: 1.0000 - val_loss: 2.7293 - val_accuracy: 0.8000\n",
      "Epoch 866/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 6.9859e-04 - accuracy: 1.0000 - val_loss: 2.7307 - val_accuracy: 0.8000\n",
      "Epoch 867/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 7.1651e-04 - accuracy: 1.0000 - val_loss: 2.7204 - val_accuracy: 0.8000\n",
      "Epoch 868/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 6.9290e-04 - accuracy: 1.0000 - val_loss: 2.7229 - val_accuracy: 0.8000\n",
      "Epoch 869/2000\n",
      "80/80 [==============================] - 0s 175us/sample - loss: 6.5975e-04 - accuracy: 1.0000 - val_loss: 2.7287 - val_accuracy: 0.8000\n",
      "Epoch 870/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 6.6851e-04 - accuracy: 1.0000 - val_loss: 2.7372 - val_accuracy: 0.8000\n",
      "Epoch 871/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 6.1034e-04 - accuracy: 1.0000 - val_loss: 2.7396 - val_accuracy: 0.8000\n",
      "Epoch 872/2000\n",
      "80/80 [==============================] - 0s 58us/sample - loss: 6.5049e-04 - accuracy: 1.0000 - val_loss: 2.7404 - val_accuracy: 0.8000\n",
      "Epoch 873/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 6.2869e-04 - accuracy: 1.0000 - val_loss: 2.7377 - val_accuracy: 0.8000\n",
      "Epoch 874/2000\n",
      "80/80 [==============================] - 0s 13us/sample - loss: 5.9747e-04 - accuracy: 1.0000 - val_loss: 2.7320 - val_accuracy: 0.8000\n",
      "Epoch 875/2000\n",
      "80/80 [==============================] - 0s 241us/sample - loss: 7.1340e-04 - accuracy: 1.0000 - val_loss: 2.7303 - val_accuracy: 0.8000\n",
      "Epoch 876/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 5.7133e-04 - accuracy: 1.0000 - val_loss: 2.7429 - val_accuracy: 0.8000\n",
      "Epoch 877/2000\n",
      "80/80 [==============================] - 0s 56us/sample - loss: 6.3456e-04 - accuracy: 1.0000 - val_loss: 2.7505 - val_accuracy: 0.8000\n",
      "Epoch 878/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 6.8845e-04 - accuracy: 1.0000 - val_loss: 2.7444 - val_accuracy: 0.8000\n",
      "Epoch 879/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 6.4744e-04 - accuracy: 1.0000 - val_loss: 2.7359 - val_accuracy: 0.8000\n",
      "Epoch 880/2000\n",
      "80/80 [==============================] - 0s 51us/sample - loss: 6.2172e-04 - accuracy: 1.0000 - val_loss: 2.7307 - val_accuracy: 0.8000\n",
      "Epoch 881/2000\n",
      "80/80 [==============================] - 0s 182us/sample - loss: 5.8164e-04 - accuracy: 1.0000 - val_loss: 2.7325 - val_accuracy: 0.8000\n",
      "Epoch 882/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 5.7002e-04 - accuracy: 1.0000 - val_loss: 2.7355 - val_accuracy: 0.8000\n",
      "Epoch 883/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 5.6208e-04 - accuracy: 1.0000 - val_loss: 2.7386 - val_accuracy: 0.8000\n",
      "Epoch 884/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 5.8121e-04 - accuracy: 1.0000 - val_loss: 2.7385 - val_accuracy: 0.8000\n",
      "Epoch 885/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 6.3138e-04 - accuracy: 1.0000 - val_loss: 2.7403 - val_accuracy: 0.8000\n",
      "Epoch 886/2000\n",
      "80/80 [==============================] - 0s 43us/sample - loss: 5.2400e-04 - accuracy: 1.0000 - val_loss: 2.7318 - val_accuracy: 0.8000\n",
      "Epoch 887/2000\n",
      "80/80 [==============================] - 0s 228us/sample - loss: 6.0513e-04 - accuracy: 1.0000 - val_loss: 2.7235 - val_accuracy: 0.8000\n",
      "Epoch 888/2000\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 7.2759e-04 - accuracy: 1.0000 - val_loss: 2.7242 - val_accuracy: 0.8000\n",
      "Epoch 889/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 6.3561e-04 - accuracy: 1.0000 - val_loss: 2.7341 - val_accuracy: 0.8000\n",
      "Epoch 890/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 6.4250e-04 - accuracy: 1.0000 - val_loss: 2.7513 - val_accuracy: 0.8000\n",
      "Epoch 891/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 6.0630e-04 - accuracy: 1.0000 - val_loss: 2.7511 - val_accuracy: 0.8000\n",
      "Epoch 892/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 5.5979e-04 - accuracy: 1.0000 - val_loss: 2.7461 - val_accuracy: 0.8000\n",
      "Epoch 893/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 5.7945e-04 - accuracy: 1.0000 - val_loss: 2.7402 - val_accuracy: 0.8000\n",
      "Epoch 894/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 1.0795e-05 - accuracy: 1.00 - 0s 91us/sample - loss: 5.6453e-04 - accuracy: 1.0000 - val_loss: 2.7434 - val_accuracy: 0.8000\n",
      "Epoch 895/2000\n",
      "80/80 [==============================] - 0s 64us/sample - loss: 5.6189e-04 - accuracy: 1.0000 - val_loss: 2.7381 - val_accuracy: 0.8000\n",
      "Epoch 896/2000\n",
      "80/80 [==============================] - 0s 193us/sample - loss: 5.2461e-04 - accuracy: 1.0000 - val_loss: 2.7395 - val_accuracy: 0.8000\n",
      "Epoch 897/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 5.4332e-04 - accuracy: 1.0000 - val_loss: 2.7406 - val_accuracy: 0.8000\n",
      "Epoch 898/2000\n",
      "80/80 [==============================] - 0s 304us/sample - loss: 5.6151e-04 - accuracy: 1.0000 - val_loss: 2.7389 - val_accuracy: 0.8000\n",
      "Epoch 899/2000\n",
      "80/80 [==============================] - 0s 324us/sample - loss: 5.0267e-04 - accuracy: 1.0000 - val_loss: 2.7483 - val_accuracy: 0.8000\n",
      "Epoch 900/2000\n",
      "80/80 [==============================] - 0s 51us/sample - loss: 5.6972e-04 - accuracy: 1.0000 - val_loss: 2.7545 - val_accuracy: 0.8000\n",
      "Epoch 901/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 6.0226e-04 - accuracy: 1.0000 - val_loss: 2.7498 - val_accuracy: 0.8000\n",
      "Epoch 902/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 5.1459e-04 - accuracy: 1.0000 - val_loss: 2.7285 - val_accuracy: 0.8000\n",
      "Epoch 903/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 6.4776e-04 - accuracy: 1.0000 - val_loss: 2.7227 - val_accuracy: 0.8000\n",
      "Epoch 904/2000\n",
      "80/80 [==============================] - 0s 49us/sample - loss: 7.6545e-04 - accuracy: 1.0000 - val_loss: 2.7298 - val_accuracy: 0.8000\n",
      "Epoch 905/2000\n",
      "80/80 [==============================] - 0s 192us/sample - loss: 4.8732e-04 - accuracy: 1.0000 - val_loss: 2.7607 - val_accuracy: 0.8000\n",
      "Epoch 906/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 7.5704e-04 - accuracy: 1.0000 - val_loss: 2.7779 - val_accuracy: 0.7500\n",
      "Epoch 907/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 8.2684e-04 - accuracy: 1.0000 - val_loss: 2.7621 - val_accuracy: 0.8000\n",
      "Epoch 908/2000\n",
      "80/80 [==============================] - 0s 169us/sample - loss: 5.4806e-04 - accuracy: 1.0000 - val_loss: 2.7441 - val_accuracy: 0.8000\n",
      "Epoch 909/2000\n",
      "80/80 [==============================] - 0s 72us/sample - loss: 5.7446e-04 - accuracy: 1.0000 - val_loss: 2.7368 - val_accuracy: 0.8000\n",
      "Epoch 910/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 5.0935e-04 - accuracy: 1.0000 - val_loss: 2.7500 - val_accuracy: 0.8000\n",
      "Epoch 911/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 5.2692e-04 - accuracy: 1.0000 - val_loss: 2.7608 - val_accuracy: 0.8000\n",
      "Epoch 912/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 5.2171e-04 - accuracy: 1.0000 - val_loss: 2.7582 - val_accuracy: 0.8000\n",
      "Epoch 913/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 4.8156e-04 - accuracy: 1.0000 - val_loss: 2.7532 - val_accuracy: 0.8000\n",
      "Epoch 914/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 4.6739e-04 - accuracy: 1.0000 - val_loss: 2.7488 - val_accuracy: 0.8000\n",
      "Epoch 915/2000\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 4.5053e-04 - accuracy: 1.0000 - val_loss: 2.7375 - val_accuracy: 0.8000\n",
      "Epoch 916/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 5.4971e-04 - accuracy: 1.0000 - val_loss: 2.7359 - val_accuracy: 0.8000\n",
      "Epoch 917/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 5.3511e-04 - accuracy: 1.0000 - val_loss: 2.7410 - val_accuracy: 0.8000\n",
      "Epoch 918/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 4.6638e-04 - accuracy: 1.0000 - val_loss: 2.7481 - val_accuracy: 0.8000\n",
      "Epoch 919/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 4.8091e-04 - accuracy: 1.0000 - val_loss: 2.7545 - val_accuracy: 0.8000\n",
      "Epoch 920/2000\n",
      "80/80 [==============================] - 0s 77us/sample - loss: 4.4583e-04 - accuracy: 1.0000 - val_loss: 2.7506 - val_accuracy: 0.8000\n",
      "Epoch 921/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 4.4360e-04 - accuracy: 1.0000 - val_loss: 2.7429 - val_accuracy: 0.8000\n",
      "Epoch 922/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 5.2887e-04 - accuracy: 1.0000 - val_loss: 2.7435 - val_accuracy: 0.8000\n",
      "Epoch 923/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 4.6009e-04 - accuracy: 1.0000 - val_loss: 2.7633 - val_accuracy: 0.8000\n",
      "Epoch 924/2000\n",
      "80/80 [==============================] - 0s 770us/sample - loss: 4.9814e-04 - accuracy: 1.0000 - val_loss: 2.7731 - val_accuracy: 0.7500\n",
      "Epoch 925/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 5.4683e-04 - accuracy: 1.0000 - val_loss: 2.7691 - val_accuracy: 0.7500\n",
      "Epoch 926/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 4.8193e-04 - accuracy: 1.0000 - val_loss: 2.7600 - val_accuracy: 0.8000\n",
      "Epoch 927/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 4.3491e-04 - accuracy: 1.0000 - val_loss: 2.7464 - val_accuracy: 0.8000\n",
      "Epoch 928/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 4.7132e-04 - accuracy: 1.0000 - val_loss: 2.7392 - val_accuracy: 0.8000\n",
      "Epoch 929/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 4.8525e-04 - accuracy: 1.0000 - val_loss: 2.7394 - val_accuracy: 0.8000\n",
      "Epoch 930/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 4.3433e-04 - accuracy: 1.0000 - val_loss: 2.7453 - val_accuracy: 0.8000\n",
      "Epoch 931/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 4.5043e-04 - accuracy: 1.0000 - val_loss: 2.7538 - val_accuracy: 0.8000\n",
      "Epoch 932/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 4.1624e-04 - accuracy: 1.0000 - val_loss: 2.7545 - val_accuracy: 0.8000\n",
      "Epoch 933/2000\n",
      "80/80 [==============================] - 0s 279us/sample - loss: 4.2218e-04 - accuracy: 1.0000 - val_loss: 2.7521 - val_accuracy: 0.8000\n",
      "Epoch 934/2000\n",
      "80/80 [==============================] - 0s 49us/sample - loss: 4.0003e-04 - accuracy: 1.0000 - val_loss: 2.7453 - val_accuracy: 0.8000\n",
      "Epoch 935/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 4.7602e-04 - accuracy: 1.0000 - val_loss: 2.7417 - val_accuracy: 0.8000\n",
      "Epoch 936/2000\n",
      "80/80 [==============================] - 0s 161us/sample - loss: 3.9787e-04 - accuracy: 1.0000 - val_loss: 2.7522 - val_accuracy: 0.8000\n",
      "Epoch 937/2000\n",
      "80/80 [==============================] - 0s 157us/sample - loss: 4.4070e-04 - accuracy: 1.0000 - val_loss: 2.7595 - val_accuracy: 0.8000\n",
      "Epoch 938/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 4.3015e-04 - accuracy: 1.0000 - val_loss: 2.7581 - val_accuracy: 0.8000\n",
      "Epoch 939/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 4.4736e-04 - accuracy: 1.0000 - val_loss: 2.7453 - val_accuracy: 0.8000\n",
      "Epoch 940/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 3.9203e-04 - accuracy: 1.0000 - val_loss: 2.7419 - val_accuracy: 0.8000\n",
      "Epoch 941/2000\n",
      "80/80 [==============================] - 0s 171us/sample - loss: 4.0906e-04 - accuracy: 1.0000 - val_loss: 2.7387 - val_accuracy: 0.8000\n",
      "Epoch 942/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 4.6178e-04 - accuracy: 1.0000 - val_loss: 2.7434 - val_accuracy: 0.8000\n",
      "Epoch 943/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 4.1664e-04 - accuracy: 1.0000 - val_loss: 2.7471 - val_accuracy: 0.8000\n",
      "Epoch 944/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 3.8385e-04 - accuracy: 1.0000 - val_loss: 2.7500 - val_accuracy: 0.8000\n",
      "Epoch 945/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 4.2714e-04 - accuracy: 1.0000 - val_loss: 2.7552 - val_accuracy: 0.8000\n",
      "Epoch 946/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 3.7066e-04 - accuracy: 1.0000 - val_loss: 2.7502 - val_accuracy: 0.8000\n",
      "Epoch 947/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 3.7187e-04 - accuracy: 1.0000 - val_loss: 2.7495 - val_accuracy: 0.8000\n",
      "Epoch 948/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 3.6917e-04 - accuracy: 1.0000 - val_loss: 2.7516 - val_accuracy: 0.8000\n",
      "Epoch 949/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 4.9640e-04 - accuracy: 1.00 - 0s 116us/sample - loss: 3.8591e-04 - accuracy: 1.0000 - val_loss: 2.7563 - val_accuracy: 0.8000\n",
      "Epoch 950/2000\n",
      "80/80 [==============================] - 0s 154us/sample - loss: 3.7526e-04 - accuracy: 1.0000 - val_loss: 2.7560 - val_accuracy: 0.8000\n",
      "Epoch 951/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 3.5876e-04 - accuracy: 1.0000 - val_loss: 2.7573 - val_accuracy: 0.8000\n",
      "Epoch 952/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 3.7234e-04 - accuracy: 1.0000 - val_loss: 2.7572 - val_accuracy: 0.8000\n",
      "Epoch 953/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 3.6893e-04 - accuracy: 1.0000 - val_loss: 2.7595 - val_accuracy: 0.8000\n",
      "Epoch 954/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 3.5059e-04 - accuracy: 1.0000 - val_loss: 2.7655 - val_accuracy: 0.8000\n",
      "Epoch 955/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 3.6267e-04 - accuracy: 1.0000 - val_loss: 2.7681 - val_accuracy: 0.8000\n",
      "Epoch 956/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 3.8294e-04 - accuracy: 1.0000 - val_loss: 2.7636 - val_accuracy: 0.8000\n",
      "Epoch 957/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 3.9266e-04 - accuracy: 1.0000 - val_loss: 2.7579 - val_accuracy: 0.8000\n",
      "Epoch 958/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 3.7603e-04 - accuracy: 1.0000 - val_loss: 2.7622 - val_accuracy: 0.8000\n",
      "Epoch 959/2000\n",
      "80/80 [==============================] - 0s 77us/sample - loss: 3.5653e-04 - accuracy: 1.0000 - val_loss: 2.7600 - val_accuracy: 0.8000\n",
      "Epoch 960/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 3.4660e-04 - accuracy: 1.0000 - val_loss: 2.7578 - val_accuracy: 0.8000\n",
      "Epoch 961/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 3.6378e-04 - accuracy: 1.0000 - val_loss: 2.7541 - val_accuracy: 0.8000\n",
      "Epoch 962/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 3.4160e-04 - accuracy: 1.0000 - val_loss: 2.7547 - val_accuracy: 0.8000\n",
      "Epoch 963/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 3.5435e-04 - accuracy: 1.0000 - val_loss: 2.7558 - val_accuracy: 0.8000\n",
      "Epoch 964/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 3.5650e-04 - accuracy: 1.0000 - val_loss: 2.7581 - val_accuracy: 0.8000\n",
      "Epoch 965/2000\n",
      "80/80 [==============================] - 0s 68us/sample - loss: 3.6069e-04 - accuracy: 1.0000 - val_loss: 2.7527 - val_accuracy: 0.8000\n",
      "Epoch 966/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 3.6012e-04 - accuracy: 1.0000 - val_loss: 2.7527 - val_accuracy: 0.8000\n",
      "Epoch 967/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 3.5527e-04 - accuracy: 1.0000 - val_loss: 2.7566 - val_accuracy: 0.8000\n",
      "Epoch 968/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 3.7954e-04 - accuracy: 1.0000 - val_loss: 2.7679 - val_accuracy: 0.8000\n",
      "Epoch 969/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 3.4105e-04 - accuracy: 1.0000 - val_loss: 2.7646 - val_accuracy: 0.8000\n",
      "Epoch 970/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 3.3283e-04 - accuracy: 1.0000 - val_loss: 2.7616 - val_accuracy: 0.8000\n",
      "Epoch 971/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 3.2716e-04 - accuracy: 1.0000 - val_loss: 2.7572 - val_accuracy: 0.8000\n",
      "Epoch 972/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 3.6835e-04 - accuracy: 1.0000 - val_loss: 2.7505 - val_accuracy: 0.8000\n",
      "Epoch 973/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 4.0709e-04 - accuracy: 1.0000 - val_loss: 2.7537 - val_accuracy: 0.8000\n",
      "Epoch 974/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 2.9799e-04 - accuracy: 1.0000 - val_loss: 2.7713 - val_accuracy: 0.8000\n",
      "Epoch 975/2000\n",
      "80/80 [==============================] - 0s 525us/sample - loss: 4.5293e-04 - accuracy: 1.0000 - val_loss: 2.7839 - val_accuracy: 0.7500\n",
      "Epoch 976/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 3.9678e-04 - accuracy: 1.0000 - val_loss: 2.7667 - val_accuracy: 0.8000\n",
      "Epoch 977/2000\n",
      "80/80 [==============================] - 0s 261us/sample - loss: 3.0762e-04 - accuracy: 1.0000 - val_loss: 2.7568 - val_accuracy: 0.8000\n",
      "Epoch 978/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 3.3542e-04 - accuracy: 1.0000 - val_loss: 2.7526 - val_accuracy: 0.8000\n",
      "Epoch 979/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 3.8089e-04 - accuracy: 1.0000 - val_loss: 2.7558 - val_accuracy: 0.8000\n",
      "Epoch 980/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 3.5875e-04 - accuracy: 1.0000 - val_loss: 2.7634 - val_accuracy: 0.8000\n",
      "Epoch 981/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 3.3180e-04 - accuracy: 1.0000 - val_loss: 2.7711 - val_accuracy: 0.8000\n",
      "Epoch 982/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 3.0874e-04 - accuracy: 1.0000 - val_loss: 2.7718 - val_accuracy: 0.8000\n",
      "Epoch 983/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 3.3230e-04 - accuracy: 1.0000 - val_loss: 2.7685 - val_accuracy: 0.8000\n",
      "Epoch 984/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 3.3117e-04 - accuracy: 1.0000 - val_loss: 2.7694 - val_accuracy: 0.8000\n",
      "Epoch 985/2000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 2.9771e-04 - accuracy: 1.0000 - val_loss: 2.7613 - val_accuracy: 0.8000\n",
      "Epoch 986/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 2.9784e-04 - accuracy: 1.0000 - val_loss: 2.7580 - val_accuracy: 0.8000\n",
      "Epoch 987/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 3.0372e-04 - accuracy: 1.0000 - val_loss: 2.7563 - val_accuracy: 0.8000\n",
      "Epoch 988/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 3.1739e-04 - accuracy: 1.0000 - val_loss: 2.7600 - val_accuracy: 0.8000\n",
      "Epoch 989/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 2.9605e-04 - accuracy: 1.0000 - val_loss: 2.7735 - val_accuracy: 0.8000\n",
      "Epoch 990/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 3.9419e-04 - accuracy: 1.0000 - val_loss: 2.7791 - val_accuracy: 0.8000\n",
      "Epoch 991/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 2.9419e-04 - accuracy: 1.0000 - val_loss: 2.7652 - val_accuracy: 0.8000\n",
      "Epoch 992/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 2.6069e-04 - accuracy: 1.0000 - val_loss: 2.7555 - val_accuracy: 0.8000\n",
      "Epoch 993/2000\n",
      "80/80 [==============================] - 0s 248us/sample - loss: 3.6710e-04 - accuracy: 1.0000 - val_loss: 2.7470 - val_accuracy: 0.8000\n",
      "Epoch 994/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 3.9717e-04 - accuracy: 1.0000 - val_loss: 2.7505 - val_accuracy: 0.8000\n",
      "Epoch 995/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 3.4223e-04 - accuracy: 1.0000 - val_loss: 2.7619 - val_accuracy: 0.8000\n",
      "Epoch 996/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 3.1187e-04 - accuracy: 1.0000 - val_loss: 2.7736 - val_accuracy: 0.8000\n",
      "Epoch 997/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 2.9638e-04 - accuracy: 1.0000 - val_loss: 2.7782 - val_accuracy: 0.8000\n",
      "Epoch 998/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 3.0245e-04 - accuracy: 1.0000 - val_loss: 2.7782 - val_accuracy: 0.8000\n",
      "Epoch 999/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 3.1140e-04 - accuracy: 1.0000 - val_loss: 2.7750 - val_accuracy: 0.8000\n",
      "Epoch 1000/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 2.8313e-04 - accuracy: 1.0000 - val_loss: 2.7591 - val_accuracy: 0.8000\n",
      "Epoch 1001/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 3.3355e-04 - accuracy: 1.0000 - val_loss: 2.7535 - val_accuracy: 0.8000\n",
      "Epoch 1002/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 2.9169e-04 - accuracy: 1.0000 - val_loss: 2.7629 - val_accuracy: 0.8000\n",
      "Epoch 1003/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 2.6898e-04 - accuracy: 1.0000 - val_loss: 2.7816 - val_accuracy: 0.7500\n",
      "Epoch 1004/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 3.3963e-04 - accuracy: 1.0000 - val_loss: 2.7890 - val_accuracy: 0.7500\n",
      "Epoch 1005/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 3.5907e-04 - accuracy: 1.0000 - val_loss: 2.7801 - val_accuracy: 0.8000\n",
      "Epoch 1006/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 2.8878e-04 - accuracy: 1.0000 - val_loss: 2.7689 - val_accuracy: 0.8000\n",
      "Epoch 1007/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 2.5343e-04 - accuracy: 1.0000 - val_loss: 2.7636 - val_accuracy: 0.8000\n",
      "Epoch 1008/2000\n",
      "80/80 [==============================] - 0s 496us/sample - loss: 2.6754e-04 - accuracy: 1.0000 - val_loss: 2.7560 - val_accuracy: 0.8000\n",
      "Epoch 1009/2000\n",
      "80/80 [==============================] - 0s 308us/sample - loss: 3.3486e-04 - accuracy: 1.0000 - val_loss: 2.7549 - val_accuracy: 0.8000\n",
      "Epoch 1010/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 3.1455e-04 - accuracy: 1.0000 - val_loss: 2.7629 - val_accuracy: 0.8000\n",
      "Epoch 1011/2000\n",
      "80/80 [==============================] - 0s 163us/sample - loss: 2.3534e-04 - accuracy: 1.0000 - val_loss: 2.7834 - val_accuracy: 0.8000\n",
      "Epoch 1012/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 2.6333e-04 - accuracy: 1.0000 - val_loss: 2.7987 - val_accuracy: 0.7500\n",
      "Epoch 1013/2000\n",
      "80/80 [==============================] - 0s 191us/sample - loss: 4.0742e-04 - accuracy: 1.0000 - val_loss: 2.7989 - val_accuracy: 0.7500\n",
      "Epoch 1014/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 3.6513e-04 - accuracy: 1.0000 - val_loss: 2.7827 - val_accuracy: 0.8000\n",
      "Epoch 1015/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 2.5216e-04 - accuracy: 1.0000 - val_loss: 2.7698 - val_accuracy: 0.8000\n",
      "Epoch 1016/2000\n",
      "80/80 [==============================] - 0s 74us/sample - loss: 2.8472e-04 - accuracy: 1.0000 - val_loss: 2.7593 - val_accuracy: 0.8000\n",
      "Epoch 1017/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 2.7927e-04 - accuracy: 1.0000 - val_loss: 2.7590 - val_accuracy: 0.8000\n",
      "Epoch 1018/2000\n",
      "80/80 [==============================] - 0s 55us/sample - loss: 2.7589e-04 - accuracy: 1.0000 - val_loss: 2.7635 - val_accuracy: 0.8000\n",
      "Epoch 1019/2000\n",
      "80/80 [==============================] - 0s 185us/sample - loss: 2.9355e-04 - accuracy: 1.0000 - val_loss: 2.7721 - val_accuracy: 0.8000\n",
      "Epoch 1020/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 2.5346e-04 - accuracy: 1.0000 - val_loss: 2.7761 - val_accuracy: 0.8000\n",
      "Epoch 1021/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 2.4403e-04 - accuracy: 1.0000 - val_loss: 2.7778 - val_accuracy: 0.8000\n",
      "Epoch 1022/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 2.5487e-04 - accuracy: 1.0000 - val_loss: 2.7784 - val_accuracy: 0.8000\n",
      "Epoch 1023/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 2.5226e-04 - accuracy: 1.0000 - val_loss: 2.7793 - val_accuracy: 0.8000\n",
      "Epoch 1024/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 2.5284e-04 - accuracy: 1.0000 - val_loss: 2.7809 - val_accuracy: 0.7500\n",
      "Epoch 1025/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 2.4048e-04 - accuracy: 1.0000 - val_loss: 2.7928 - val_accuracy: 0.7500\n",
      "Epoch 1026/2000\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 2.8528e-04 - accuracy: 1.0000 - val_loss: 2.7980 - val_accuracy: 0.7500\n",
      "Epoch 1027/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 2.7537e-04 - accuracy: 1.0000 - val_loss: 2.7926 - val_accuracy: 0.7500\n",
      "Epoch 1028/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 2.5175e-04 - accuracy: 1.0000 - val_loss: 2.7846 - val_accuracy: 0.7500\n",
      "Epoch 1029/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 2.5991e-04 - accuracy: 1.0000 - val_loss: 2.7742 - val_accuracy: 0.8000\n",
      "Epoch 1030/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 2.4205e-04 - accuracy: 1.0000 - val_loss: 2.7709 - val_accuracy: 0.8000\n",
      "Epoch 1031/2000\n",
      "80/80 [==============================] - 0s 73us/sample - loss: 2.4778e-04 - accuracy: 1.0000 - val_loss: 2.7724 - val_accuracy: 0.8000\n",
      "Epoch 1032/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 2.4099e-04 - accuracy: 1.0000 - val_loss: 2.7755 - val_accuracy: 0.8000\n",
      "Epoch 1033/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 2.3198e-04 - accuracy: 1.0000 - val_loss: 2.7795 - val_accuracy: 0.7500\n",
      "Epoch 1034/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 2.5947e-04 - accuracy: 1.0000 - val_loss: 2.7815 - val_accuracy: 0.7500\n",
      "Epoch 1035/2000\n",
      "80/80 [==============================] - 0s 534us/sample - loss: 2.2814e-04 - accuracy: 1.0000 - val_loss: 2.7739 - val_accuracy: 0.8000\n",
      "Epoch 1036/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 2.3339e-04 - accuracy: 1.0000 - val_loss: 2.7687 - val_accuracy: 0.8000\n",
      "Epoch 1037/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 2.5723e-04 - accuracy: 1.0000 - val_loss: 2.7692 - val_accuracy: 0.8000\n",
      "Epoch 1038/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 2.5961e-04 - accuracy: 1.0000 - val_loss: 2.7839 - val_accuracy: 0.7500\n",
      "Epoch 1039/2000\n",
      "80/80 [==============================] - 0s 217us/sample - loss: 2.8947e-04 - accuracy: 1.0000 - val_loss: 2.7902 - val_accuracy: 0.7500\n",
      "Epoch 1040/2000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 2.4711e-04 - accuracy: 1.0000 - val_loss: 2.7759 - val_accuracy: 0.8000\n",
      "Epoch 1041/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 2.2816e-04 - accuracy: 1.0000 - val_loss: 2.7678 - val_accuracy: 0.8000\n",
      "Epoch 1042/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 2.4624e-04 - accuracy: 1.0000 - val_loss: 2.7666 - val_accuracy: 0.8000\n",
      "Epoch 1043/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 2.4276e-04 - accuracy: 1.0000 - val_loss: 2.7703 - val_accuracy: 0.8000\n",
      "Epoch 1044/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 2.1585e-04 - accuracy: 1.0000 - val_loss: 2.7813 - val_accuracy: 0.8000\n",
      "Epoch 1045/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 2.2302e-04 - accuracy: 1.0000 - val_loss: 2.7938 - val_accuracy: 0.7500\n",
      "Epoch 1046/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 2.5175e-04 - accuracy: 1.0000 - val_loss: 2.7979 - val_accuracy: 0.7500\n",
      "Epoch 1047/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 2.9324e-04 - accuracy: 1.0000 - val_loss: 2.7917 - val_accuracy: 0.7500\n",
      "Epoch 1048/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 1.8762e-04 - accuracy: 1.0000 - val_loss: 2.7709 - val_accuracy: 0.8000\n",
      "Epoch 1049/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 2.4194e-04 - accuracy: 1.0000 - val_loss: 2.7534 - val_accuracy: 0.8000\n",
      "Epoch 1050/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 3.5214e-04 - accuracy: 1.0000 - val_loss: 2.7500 - val_accuracy: 0.8000\n",
      "Epoch 1051/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 3.0571e-04 - accuracy: 1.0000 - val_loss: 2.7593 - val_accuracy: 0.8000\n",
      "Epoch 1052/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 2.4041e-04 - accuracy: 1.0000 - val_loss: 2.7911 - val_accuracy: 0.7500\n",
      "Epoch 1053/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 3.1275e-04 - accuracy: 1.0000 - val_loss: 2.8074 - val_accuracy: 0.7500\n",
      "Epoch 1054/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 4.4709e-04 - accuracy: 1.0000 - val_loss: 2.7988 - val_accuracy: 0.7500\n",
      "Epoch 1055/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 2.7176e-04 - accuracy: 1.0000 - val_loss: 2.7636 - val_accuracy: 0.8000\n",
      "Epoch 1056/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 3.2161e-04 - accuracy: 1.0000 - val_loss: 2.7552 - val_accuracy: 0.8000\n",
      "Epoch 1057/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 2.5690e-04 - accuracy: 1.0000 - val_loss: 2.7706 - val_accuracy: 0.8000\n",
      "Epoch 1058/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 1.9367e-04 - accuracy: 1.0000 - val_loss: 2.7867 - val_accuracy: 0.7500\n",
      "Epoch 1059/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 2.0336e-04 - accuracy: 1.0000 - val_loss: 2.7965 - val_accuracy: 0.7500\n",
      "Epoch 1060/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 2.3331e-04 - accuracy: 1.0000 - val_loss: 2.7970 - val_accuracy: 0.7500\n",
      "Epoch 1061/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 2.3724e-04 - accuracy: 1.0000 - val_loss: 2.7939 - val_accuracy: 0.7500\n",
      "Epoch 1062/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 2.1073e-04 - accuracy: 1.0000 - val_loss: 2.7859 - val_accuracy: 0.7500\n",
      "Epoch 1063/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 1.9765e-04 - accuracy: 1.0000 - val_loss: 2.7790 - val_accuracy: 0.8000\n",
      "Epoch 1064/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 2.1490e-04 - accuracy: 1.0000 - val_loss: 2.7737 - val_accuracy: 0.8000\n",
      "Epoch 1065/2000\n",
      "80/80 [==============================] - 0s 659us/sample - loss: 2.1759e-04 - accuracy: 1.0000 - val_loss: 2.7761 - val_accuracy: 0.8000\n",
      "Epoch 1066/2000\n",
      "80/80 [==============================] - 0s 237us/sample - loss: 2.0349e-04 - accuracy: 1.0000 - val_loss: 2.7769 - val_accuracy: 0.8000\n",
      "Epoch 1067/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 2.0526e-04 - accuracy: 1.0000 - val_loss: 2.7796 - val_accuracy: 0.8000\n",
      "Epoch 1068/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 2.0282e-04 - accuracy: 1.0000 - val_loss: 2.7811 - val_accuracy: 0.8000\n",
      "Epoch 1069/2000\n",
      "80/80 [==============================] - 0s 159us/sample - loss: 1.9672e-04 - accuracy: 1.0000 - val_loss: 2.7801 - val_accuracy: 0.8000\n",
      "Epoch 1070/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 2.0520e-04 - accuracy: 1.0000 - val_loss: 2.7784 - val_accuracy: 0.8000\n",
      "Epoch 1071/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 1.9655e-04 - accuracy: 1.0000 - val_loss: 2.7820 - val_accuracy: 0.8000\n",
      "Epoch 1072/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 1.9489e-04 - accuracy: 1.0000 - val_loss: 2.7842 - val_accuracy: 0.8000\n",
      "Epoch 1073/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 2.0121e-04 - accuracy: 1.0000 - val_loss: 2.7892 - val_accuracy: 0.8000\n",
      "Epoch 1074/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 1.9542e-04 - accuracy: 1.0000 - val_loss: 2.7877 - val_accuracy: 0.8000\n",
      "Epoch 1075/2000\n",
      "80/80 [==============================] - 0s 72us/sample - loss: 1.9512e-04 - accuracy: 1.0000 - val_loss: 2.7882 - val_accuracy: 0.8000\n",
      "Epoch 1076/2000\n",
      "80/80 [==============================] - 0s 155us/sample - loss: 2.1786e-04 - accuracy: 1.0000 - val_loss: 2.7915 - val_accuracy: 0.7500\n",
      "Epoch 1077/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 2.0706e-04 - accuracy: 1.0000 - val_loss: 2.7808 - val_accuracy: 0.8000\n",
      "Epoch 1078/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 1.8652e-04 - accuracy: 1.0000 - val_loss: 2.7747 - val_accuracy: 0.8000\n",
      "Epoch 1079/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 2.1191e-04 - accuracy: 1.0000 - val_loss: 2.7667 - val_accuracy: 0.8000\n",
      "Epoch 1080/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 2.1214e-04 - accuracy: 1.0000 - val_loss: 2.7692 - val_accuracy: 0.8000\n",
      "Epoch 1081/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 1.9563e-04 - accuracy: 1.0000 - val_loss: 2.7741 - val_accuracy: 0.8000\n",
      "Epoch 1082/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 1.9407e-04 - accuracy: 1.0000 - val_loss: 2.7781 - val_accuracy: 0.8000\n",
      "Epoch 1083/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 1.8140e-04 - accuracy: 1.0000 - val_loss: 2.7777 - val_accuracy: 0.8000\n",
      "Epoch 1084/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 1.8119e-04 - accuracy: 1.0000 - val_loss: 2.7784 - val_accuracy: 0.8000\n",
      "Epoch 1085/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 1.8740e-04 - accuracy: 1.0000 - val_loss: 2.7785 - val_accuracy: 0.8000\n",
      "Epoch 1086/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 1.7992e-04 - accuracy: 1.0000 - val_loss: 2.7811 - val_accuracy: 0.8000\n",
      "Epoch 1087/2000\n",
      "80/80 [==============================] - 0s 160us/sample - loss: 1.7875e-04 - accuracy: 1.0000 - val_loss: 2.7831 - val_accuracy: 0.8000\n",
      "Epoch 1088/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 1.8698e-04 - accuracy: 1.0000 - val_loss: 2.7842 - val_accuracy: 0.8000\n",
      "Epoch 1089/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 1.9581e-04 - accuracy: 1.0000 - val_loss: 2.7936 - val_accuracy: 0.7500\n",
      "Epoch 1090/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 1.9007e-04 - accuracy: 1.0000 - val_loss: 2.7913 - val_accuracy: 0.7500\n",
      "Epoch 1091/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 1.7637e-04 - accuracy: 1.0000 - val_loss: 2.7939 - val_accuracy: 0.7500\n",
      "Epoch 1092/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 1.7579e-04 - accuracy: 1.0000 - val_loss: 2.7946 - val_accuracy: 0.7500\n",
      "Epoch 1093/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 1.7478e-04 - accuracy: 1.0000 - val_loss: 2.7945 - val_accuracy: 0.7500\n",
      "Epoch 1094/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 1.8167e-04 - accuracy: 1.0000 - val_loss: 2.7920 - val_accuracy: 0.7500\n",
      "Epoch 1095/2000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 1.7996e-04 - accuracy: 1.0000 - val_loss: 2.7930 - val_accuracy: 0.7500\n",
      "Epoch 1096/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 1.7060e-04 - accuracy: 1.0000 - val_loss: 2.7993 - val_accuracy: 0.7500\n",
      "Epoch 1097/2000\n",
      "80/80 [==============================] - 0s 77us/sample - loss: 1.9092e-04 - accuracy: 1.0000 - val_loss: 2.8038 - val_accuracy: 0.7500\n",
      "Epoch 1098/2000\n",
      "80/80 [==============================] - 0s 346us/sample - loss: 1.7433e-04 - accuracy: 1.0000 - val_loss: 2.7971 - val_accuracy: 0.7500\n",
      "Epoch 1099/2000\n",
      "80/80 [==============================] - 0s 271us/sample - loss: 1.7083e-04 - accuracy: 1.0000 - val_loss: 2.7903 - val_accuracy: 0.7500\n",
      "Epoch 1100/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 1.7889e-04 - accuracy: 1.0000 - val_loss: 2.7872 - val_accuracy: 0.7500\n",
      "Epoch 1101/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 1.8416e-04 - accuracy: 1.0000 - val_loss: 2.7838 - val_accuracy: 0.7500\n",
      "Epoch 1102/2000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 1.9547e-04 - accuracy: 1.0000 - val_loss: 2.7821 - val_accuracy: 0.7500\n",
      "Epoch 1103/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 1.8527e-04 - accuracy: 1.0000 - val_loss: 2.7850 - val_accuracy: 0.7500\n",
      "Epoch 1104/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 1.6851e-04 - accuracy: 1.0000 - val_loss: 2.7971 - val_accuracy: 0.7500\n",
      "Epoch 1105/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 1.6641e-04 - accuracy: 1.0000 - val_loss: 2.8020 - val_accuracy: 0.7500\n",
      "Epoch 1106/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 1.7738e-04 - accuracy: 1.0000 - val_loss: 2.7985 - val_accuracy: 0.7500\n",
      "Epoch 1107/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 1.6993e-04 - accuracy: 1.0000 - val_loss: 2.7998 - val_accuracy: 0.7500\n",
      "Epoch 1108/2000\n",
      "80/80 [==============================] - 0s 77us/sample - loss: 1.6943e-04 - accuracy: 1.0000 - val_loss: 2.7938 - val_accuracy: 0.7500\n",
      "Epoch 1109/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 1.6348e-04 - accuracy: 1.0000 - val_loss: 2.7874 - val_accuracy: 0.7500\n",
      "Epoch 1110/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 1.7199e-04 - accuracy: 1.0000 - val_loss: 2.7831 - val_accuracy: 0.7500\n",
      "Epoch 1111/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 1.6209e-04 - accuracy: 1.0000 - val_loss: 2.7874 - val_accuracy: 0.7500\n",
      "Epoch 1112/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 1.6376e-04 - accuracy: 1.0000 - val_loss: 2.7902 - val_accuracy: 0.7500\n",
      "Epoch 1113/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 1.6924e-04 - accuracy: 1.0000 - val_loss: 2.7881 - val_accuracy: 0.7500\n",
      "Epoch 1114/2000\n",
      "80/80 [==============================] - 0s 228us/sample - loss: 1.6206e-04 - accuracy: 1.0000 - val_loss: 2.7859 - val_accuracy: 0.7500\n",
      "Epoch 1115/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 1.6799e-04 - accuracy: 1.0000 - val_loss: 2.7842 - val_accuracy: 0.7500\n",
      "Epoch 1116/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 1.5678e-04 - accuracy: 1.0000 - val_loss: 2.7757 - val_accuracy: 0.7500\n",
      "Epoch 1117/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 2.0703e-04 - accuracy: 1.0000 - val_loss: 2.7693 - val_accuracy: 0.8000\n",
      "Epoch 1118/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 1.8898e-04 - accuracy: 1.0000 - val_loss: 2.7831 - val_accuracy: 0.7500\n",
      "Epoch 1119/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 3.4424e-06 - accuracy: 1.00 - 0s 97us/sample - loss: 1.5667e-04 - accuracy: 1.0000 - val_loss: 2.7927 - val_accuracy: 0.7500\n",
      "Epoch 1120/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 1.7393e-04 - accuracy: 1.0000 - val_loss: 2.7995 - val_accuracy: 0.7500\n",
      "Epoch 1121/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 1.7333e-04 - accuracy: 1.0000 - val_loss: 2.7988 - val_accuracy: 0.7500\n",
      "Epoch 1122/2000\n",
      "80/80 [==============================] - 0s 69us/sample - loss: 1.6818e-04 - accuracy: 1.0000 - val_loss: 2.7986 - val_accuracy: 0.7500\n",
      "Epoch 1123/2000\n",
      "80/80 [==============================] - 0s 196us/sample - loss: 1.6520e-04 - accuracy: 1.0000 - val_loss: 2.7987 - val_accuracy: 0.7500\n",
      "Epoch 1124/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 1.6095e-04 - accuracy: 1.0000 - val_loss: 2.7991 - val_accuracy: 0.7500\n",
      "Epoch 1125/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 1.6524e-04 - accuracy: 1.0000 - val_loss: 2.7932 - val_accuracy: 0.7500\n",
      "Epoch 1126/2000\n",
      "80/80 [==============================] - 0s 209us/sample - loss: 1.6794e-04 - accuracy: 1.0000 - val_loss: 2.7876 - val_accuracy: 0.7500\n",
      "Epoch 1127/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 1.5113e-04 - accuracy: 1.0000 - val_loss: 2.7898 - val_accuracy: 0.7500\n",
      "Epoch 1128/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 1.6791e-04 - accuracy: 1.0000 - val_loss: 2.7908 - val_accuracy: 0.7500\n",
      "Epoch 1129/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 1.4813e-04 - accuracy: 1.0000 - val_loss: 2.7826 - val_accuracy: 0.8000\n",
      "Epoch 1130/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 1.5379e-04 - accuracy: 1.0000 - val_loss: 2.7728 - val_accuracy: 0.8000\n",
      "Epoch 1131/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 1.7871e-04 - accuracy: 1.0000 - val_loss: 2.7653 - val_accuracy: 0.8000\n",
      "Epoch 1132/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 1.7152e-04 - accuracy: 1.0000 - val_loss: 2.7773 - val_accuracy: 0.8000\n",
      "Epoch 1133/2000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 1.5058e-04 - accuracy: 1.0000 - val_loss: 2.7828 - val_accuracy: 0.8000\n",
      "Epoch 1134/2000\n",
      "80/80 [==============================] - 0s 373us/sample - loss: 1.4735e-04 - accuracy: 1.0000 - val_loss: 2.7957 - val_accuracy: 0.7500\n",
      "Epoch 1135/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 6.8977e-06 - accuracy: 1.00 - 0s 98us/sample - loss: 1.7154e-04 - accuracy: 1.0000 - val_loss: 2.8009 - val_accuracy: 0.7500\n",
      "Epoch 1136/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 1.7885e-04 - accuracy: 1.0000 - val_loss: 2.7984 - val_accuracy: 0.7500\n",
      "Epoch 1137/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 1.6271e-04 - accuracy: 1.0000 - val_loss: 2.7921 - val_accuracy: 0.7500\n",
      "Epoch 1138/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 1.2873e-04 - accuracy: 1.0000 - val_loss: 2.7778 - val_accuracy: 0.8000\n",
      "Epoch 1139/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 1.3999e-04 - accuracy: 1.0000 - val_loss: 2.7652 - val_accuracy: 0.8000\n",
      "Epoch 1140/2000\n",
      "80/80 [==============================] - 0s 155us/sample - loss: 1.9500e-04 - accuracy: 1.0000 - val_loss: 2.7629 - val_accuracy: 0.8000\n",
      "Epoch 1141/2000\n",
      "80/80 [==============================] - 0s 273us/sample - loss: 1.9343e-04 - accuracy: 1.0000 - val_loss: 2.7729 - val_accuracy: 0.8000\n",
      "Epoch 1142/2000\n",
      "80/80 [==============================] - 0s 181us/sample - loss: 1.5151e-04 - accuracy: 1.0000 - val_loss: 2.7793 - val_accuracy: 0.7500\n",
      "Epoch 1143/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 1.4116e-04 - accuracy: 1.0000 - val_loss: 2.7923 - val_accuracy: 0.7500\n",
      "Epoch 1144/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 1.6796e-04 - accuracy: 1.0000 - val_loss: 2.7976 - val_accuracy: 0.7500\n",
      "Epoch 1145/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 1.4457e-04 - accuracy: 1.0000 - val_loss: 2.7844 - val_accuracy: 0.7500\n",
      "Epoch 1146/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 1.3978e-04 - accuracy: 1.0000 - val_loss: 2.7815 - val_accuracy: 0.8000\n",
      "Epoch 1147/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 1.5487e-04 - accuracy: 1.0000 - val_loss: 2.7772 - val_accuracy: 0.8000\n",
      "Epoch 1148/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 1.5777e-04 - accuracy: 1.0000 - val_loss: 2.7805 - val_accuracy: 0.8000\n",
      "Epoch 1149/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 1.5033e-04 - accuracy: 1.0000 - val_loss: 2.7781 - val_accuracy: 0.8000\n",
      "Epoch 1150/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 1.4867e-04 - accuracy: 1.0000 - val_loss: 2.7798 - val_accuracy: 0.8000\n",
      "Epoch 1151/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 1.4345e-04 - accuracy: 1.0000 - val_loss: 2.7811 - val_accuracy: 0.8000\n",
      "Epoch 1152/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 1.4226e-04 - accuracy: 1.0000 - val_loss: 2.7830 - val_accuracy: 0.7500\n",
      "Epoch 1153/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 1.4075e-04 - accuracy: 1.0000 - val_loss: 2.7850 - val_accuracy: 0.7500\n",
      "Epoch 1154/2000\n",
      "80/80 [==============================] - 0s 68us/sample - loss: 1.3970e-04 - accuracy: 1.0000 - val_loss: 2.7867 - val_accuracy: 0.7500\n",
      "Epoch 1155/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 1.4042e-04 - accuracy: 1.0000 - val_loss: 2.7854 - val_accuracy: 0.8000\n",
      "Epoch 1156/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 1.4423e-04 - accuracy: 1.0000 - val_loss: 2.7853 - val_accuracy: 0.8000\n",
      "Epoch 1157/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 1.4505e-04 - accuracy: 1.0000 - val_loss: 2.7935 - val_accuracy: 0.7500\n",
      "Epoch 1158/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 1.3899e-04 - accuracy: 1.0000 - val_loss: 2.7956 - val_accuracy: 0.7500\n",
      "Epoch 1159/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 1.4012e-04 - accuracy: 1.0000 - val_loss: 2.7942 - val_accuracy: 0.7500\n",
      "Epoch 1160/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 1.4934e-04 - accuracy: 1.0000 - val_loss: 2.7888 - val_accuracy: 0.7500\n",
      "Epoch 1161/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 1.3473e-04 - accuracy: 1.0000 - val_loss: 2.7894 - val_accuracy: 0.7500\n",
      "Epoch 1162/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 1.3777e-04 - accuracy: 1.0000 - val_loss: 2.7898 - val_accuracy: 0.7500\n",
      "Epoch 1163/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 1.4116e-04 - accuracy: 1.0000 - val_loss: 2.7824 - val_accuracy: 0.8000\n",
      "Epoch 1164/2000\n",
      "80/80 [==============================] - 0s 504us/sample - loss: 1.4133e-04 - accuracy: 1.0000 - val_loss: 2.7792 - val_accuracy: 0.8000\n",
      "Epoch 1165/2000\n",
      "80/80 [==============================] - 0s 252us/sample - loss: 1.4108e-04 - accuracy: 1.0000 - val_loss: 2.7800 - val_accuracy: 0.8000\n",
      "Epoch 1166/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 1.4074e-04 - accuracy: 1.0000 - val_loss: 2.7861 - val_accuracy: 0.8000\n",
      "Epoch 1167/2000\n",
      "80/80 [==============================] - 0s 176us/sample - loss: 1.4369e-04 - accuracy: 1.0000 - val_loss: 2.7903 - val_accuracy: 0.7500\n",
      "Epoch 1168/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 1.2914e-04 - accuracy: 1.0000 - val_loss: 2.7808 - val_accuracy: 0.8000\n",
      "Epoch 1169/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 1.2821e-04 - accuracy: 1.0000 - val_loss: 2.7784 - val_accuracy: 0.8000\n",
      "Epoch 1170/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 1.4427e-04 - accuracy: 1.0000 - val_loss: 2.7769 - val_accuracy: 0.8000\n",
      "Epoch 1171/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 1.3306e-04 - accuracy: 1.0000 - val_loss: 2.7841 - val_accuracy: 0.8000\n",
      "Epoch 1172/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 1.2071e-04 - accuracy: 1.0000 - val_loss: 2.7861 - val_accuracy: 0.7500\n",
      "Epoch 1173/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 1.2654e-04 - accuracy: 1.0000 - val_loss: 2.8063 - val_accuracy: 0.7500\n",
      "Epoch 1174/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 1.6772e-04 - accuracy: 1.0000 - val_loss: 2.8039 - val_accuracy: 0.7500\n",
      "Epoch 1175/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 1.7264e-04 - accuracy: 1.0000 - val_loss: 2.8012 - val_accuracy: 0.7500\n",
      "Epoch 1176/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 1.5032e-04 - accuracy: 1.0000 - val_loss: 2.7884 - val_accuracy: 0.7500\n",
      "Epoch 1177/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 1.2375e-04 - accuracy: 1.0000 - val_loss: 2.7796 - val_accuracy: 0.8000\n",
      "Epoch 1178/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 1.1899e-04 - accuracy: 1.0000 - val_loss: 2.7731 - val_accuracy: 0.8000\n",
      "Epoch 1179/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 1.2633e-04 - accuracy: 1.0000 - val_loss: 2.7666 - val_accuracy: 0.8000\n",
      "Epoch 1180/2000\n",
      "80/80 [==============================] - 0s 74us/sample - loss: 1.6150e-04 - accuracy: 1.0000 - val_loss: 2.7664 - val_accuracy: 0.8000\n",
      "Epoch 1181/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 1.4017e-04 - accuracy: 1.0000 - val_loss: 2.7842 - val_accuracy: 0.7500\n",
      "Epoch 1182/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 1.1644e-04 - accuracy: 1.0000 - val_loss: 2.7945 - val_accuracy: 0.7500\n",
      "Epoch 1183/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 1.3458e-04 - accuracy: 1.0000 - val_loss: 2.7984 - val_accuracy: 0.7500\n",
      "Epoch 1184/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 1.5756e-04 - accuracy: 1.0000 - val_loss: 2.7966 - val_accuracy: 0.7500\n",
      "Epoch 1185/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 1.1626e-04 - accuracy: 1.0000 - val_loss: 2.7811 - val_accuracy: 0.8000\n",
      "Epoch 1186/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 1.4155e-04 - accuracy: 1.0000 - val_loss: 2.7650 - val_accuracy: 0.8000\n",
      "Epoch 1187/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 1.8264e-04 - accuracy: 1.0000 - val_loss: 2.7590 - val_accuracy: 0.8000\n",
      "Epoch 1188/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 1.3147e-04 - accuracy: 1.0000 - val_loss: 2.7793 - val_accuracy: 0.8000\n",
      "Epoch 1189/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 1.0911e-04 - accuracy: 1.0000 - val_loss: 2.7983 - val_accuracy: 0.7500\n",
      "Epoch 1190/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 1.5349e-04 - accuracy: 1.0000 - val_loss: 2.8085 - val_accuracy: 0.7500\n",
      "Epoch 1191/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 1.9803e-04 - accuracy: 1.0000 - val_loss: 2.8109 - val_accuracy: 0.7500\n",
      "Epoch 1192/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 1.1399e-04 - accuracy: 1.0000 - val_loss: 2.7876 - val_accuracy: 0.8000\n",
      "Epoch 1193/2000\n",
      "80/80 [==============================] - 0s 245us/sample - loss: 1.7818e-04 - accuracy: 1.0000 - val_loss: 2.7685 - val_accuracy: 0.8000\n",
      "Epoch 1194/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 1.5678e-04 - accuracy: 1.0000 - val_loss: 2.7752 - val_accuracy: 0.8000\n",
      "Epoch 1195/2000\n",
      "80/80 [==============================] - 0s 505us/sample - loss: 1.2814e-04 - accuracy: 1.0000 - val_loss: 2.7825 - val_accuracy: 0.8000\n",
      "Epoch 1196/2000\n",
      "80/80 [==============================] - 0s 183us/sample - loss: 1.1063e-04 - accuracy: 1.0000 - val_loss: 2.7899 - val_accuracy: 0.8000\n",
      "Epoch 1197/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 1.0682e-04 - accuracy: 1.0000 - val_loss: 2.8022 - val_accuracy: 0.7500\n",
      "Epoch 1198/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 1.4342e-04 - accuracy: 1.0000 - val_loss: 2.8064 - val_accuracy: 0.7500\n",
      "Epoch 1199/2000\n",
      "80/80 [==============================] - 0s 154us/sample - loss: 1.1881e-04 - accuracy: 1.0000 - val_loss: 2.7950 - val_accuracy: 0.7500\n",
      "Epoch 1200/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 1.2754e-04 - accuracy: 1.0000 - val_loss: 2.7808 - val_accuracy: 0.8000\n",
      "Epoch 1201/2000\n",
      "80/80 [==============================] - 0s 73us/sample - loss: 1.2046e-04 - accuracy: 1.0000 - val_loss: 2.7811 - val_accuracy: 0.8000\n",
      "Epoch 1202/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 1.1799e-04 - accuracy: 1.0000 - val_loss: 2.7808 - val_accuracy: 0.8000\n",
      "Epoch 1203/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 1.2456e-04 - accuracy: 1.0000 - val_loss: 2.7819 - val_accuracy: 0.8000\n",
      "Epoch 1204/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 1.1027e-04 - accuracy: 1.0000 - val_loss: 2.7920 - val_accuracy: 0.8000\n",
      "Epoch 1205/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 1.1113e-04 - accuracy: 1.0000 - val_loss: 2.7950 - val_accuracy: 0.7500\n",
      "Epoch 1206/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 1.2638e-04 - accuracy: 1.0000 - val_loss: 2.8004 - val_accuracy: 0.7500\n",
      "Epoch 1207/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 1.2014e-04 - accuracy: 1.0000 - val_loss: 2.7888 - val_accuracy: 0.8000\n",
      "Epoch 1208/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 1.0772e-04 - accuracy: 1.0000 - val_loss: 2.7849 - val_accuracy: 0.8000\n",
      "Epoch 1209/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 1.0840e-04 - accuracy: 1.0000 - val_loss: 2.7814 - val_accuracy: 0.8000\n",
      "Epoch 1210/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 1.0951e-04 - accuracy: 1.0000 - val_loss: 2.7772 - val_accuracy: 0.8000\n",
      "Epoch 1211/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 1.2140e-04 - accuracy: 1.0000 - val_loss: 2.7735 - val_accuracy: 0.8000\n",
      "Epoch 1212/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 1.1825e-04 - accuracy: 1.0000 - val_loss: 2.7765 - val_accuracy: 0.8000\n",
      "Epoch 1213/2000\n",
      "80/80 [==============================] - 0s 60us/sample - loss: 1.1093e-04 - accuracy: 1.0000 - val_loss: 2.7812 - val_accuracy: 0.8000\n",
      "Epoch 1214/2000\n",
      "80/80 [==============================] - 0s 160us/sample - loss: 1.1509e-04 - accuracy: 1.0000 - val_loss: 2.7913 - val_accuracy: 0.7500\n",
      "Epoch 1215/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 1.0630e-04 - accuracy: 1.0000 - val_loss: 2.7911 - val_accuracy: 0.7500\n",
      "Epoch 1216/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 1.1196e-04 - accuracy: 1.0000 - val_loss: 2.7786 - val_accuracy: 0.7500\n",
      "Epoch 1217/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 1.0118e-04 - accuracy: 1.0000 - val_loss: 2.7817 - val_accuracy: 0.8000\n",
      "Epoch 1218/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 1.0370e-04 - accuracy: 1.0000 - val_loss: 2.7747 - val_accuracy: 0.8000\n",
      "Epoch 1219/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 1.0911e-04 - accuracy: 1.0000 - val_loss: 2.7723 - val_accuracy: 0.8000\n",
      "Epoch 1220/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 1.1452e-04 - accuracy: 1.0000 - val_loss: 2.7734 - val_accuracy: 0.8000\n",
      "Epoch 1221/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 1.1789e-04 - accuracy: 1.0000 - val_loss: 2.7795 - val_accuracy: 0.8000\n",
      "Epoch 1222/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 1.0551e-04 - accuracy: 1.0000 - val_loss: 2.7821 - val_accuracy: 0.8000\n",
      "Epoch 1223/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 1.0106e-04 - accuracy: 1.0000 - val_loss: 2.7896 - val_accuracy: 0.8000\n",
      "Epoch 1224/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 1.1583e-04 - accuracy: 1.0000 - val_loss: 2.7943 - val_accuracy: 0.7500\n",
      "Epoch 1225/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 1.0862e-04 - accuracy: 1.0000 - val_loss: 2.7886 - val_accuracy: 0.8000\n",
      "Epoch 1226/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 1.0355e-04 - accuracy: 1.0000 - val_loss: 2.7880 - val_accuracy: 0.8000\n",
      "Epoch 1227/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 1.0051e-04 - accuracy: 1.0000 - val_loss: 2.7913 - val_accuracy: 0.8000\n",
      "Epoch 1228/2000\n",
      "80/80 [==============================] - 0s 156us/sample - loss: 1.0193e-04 - accuracy: 1.0000 - val_loss: 2.7961 - val_accuracy: 0.7500\n",
      "Epoch 1229/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 1.1381e-04 - accuracy: 1.0000 - val_loss: 2.7999 - val_accuracy: 0.7500\n",
      "Epoch 1230/2000\n",
      "80/80 [==============================] - 0s 255us/sample - loss: 1.1469e-04 - accuracy: 1.0000 - val_loss: 2.7950 - val_accuracy: 0.7500\n",
      "Epoch 1231/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 1.2430e-04 - accuracy: 1.0000 - val_loss: 2.7790 - val_accuracy: 0.8000\n",
      "Epoch 1232/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 1.0624e-04 - accuracy: 1.0000 - val_loss: 2.7752 - val_accuracy: 0.8000\n",
      "Epoch 1233/2000\n",
      "80/80 [==============================] - 0s 297us/sample - loss: 1.0020e-04 - accuracy: 1.0000 - val_loss: 2.7838 - val_accuracy: 0.7500\n",
      "Epoch 1234/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 1.0351e-04 - accuracy: 1.0000 - val_loss: 2.7904 - val_accuracy: 0.7500\n",
      "Epoch 1235/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 9.7843e-05 - accuracy: 1.0000 - val_loss: 2.7886 - val_accuracy: 0.7500\n",
      "Epoch 1236/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 9.6812e-05 - accuracy: 1.0000 - val_loss: 2.7898 - val_accuracy: 0.7500\n",
      "Epoch 1237/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 1.0073e-04 - accuracy: 1.0000 - val_loss: 2.7887 - val_accuracy: 0.7500\n",
      "Epoch 1238/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 1.0039e-04 - accuracy: 1.0000 - val_loss: 2.7900 - val_accuracy: 0.7500\n",
      "Epoch 1239/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 9.8572e-05 - accuracy: 1.0000 - val_loss: 2.7941 - val_accuracy: 0.7500\n",
      "Epoch 1240/2000\n",
      "80/80 [==============================] - 0s 61us/sample - loss: 9.4637e-05 - accuracy: 1.0000 - val_loss: 2.8028 - val_accuracy: 0.7500\n",
      "Epoch 1241/2000\n",
      "80/80 [==============================] - 0s 165us/sample - loss: 9.5878e-05 - accuracy: 1.0000 - val_loss: 2.8044 - val_accuracy: 0.7500\n",
      "Epoch 1242/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 9.9479e-05 - accuracy: 1.0000 - val_loss: 2.8044 - val_accuracy: 0.7500\n",
      "Epoch 1243/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 1.0106e-04 - accuracy: 1.0000 - val_loss: 2.8007 - val_accuracy: 0.7500\n",
      "Epoch 1244/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 1.0179e-04 - accuracy: 1.0000 - val_loss: 2.7869 - val_accuracy: 0.7500\n",
      "Epoch 1245/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 9.5323e-05 - accuracy: 1.0000 - val_loss: 2.7915 - val_accuracy: 0.7500\n",
      "Epoch 1246/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 9.6987e-05 - accuracy: 1.0000 - val_loss: 2.7897 - val_accuracy: 0.7500\n",
      "Epoch 1247/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 9.6713e-05 - accuracy: 1.0000 - val_loss: 2.7924 - val_accuracy: 0.7500\n",
      "Epoch 1248/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 9.2209e-05 - accuracy: 1.0000 - val_loss: 2.7935 - val_accuracy: 0.7500\n",
      "Epoch 1249/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 9.3997e-05 - accuracy: 1.0000 - val_loss: 2.7936 - val_accuracy: 0.7500\n",
      "Epoch 1250/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 9.1547e-05 - accuracy: 1.0000 - val_loss: 2.7964 - val_accuracy: 0.7500\n",
      "Epoch 1251/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 9.4600e-05 - accuracy: 1.0000 - val_loss: 2.7985 - val_accuracy: 0.7500\n",
      "Epoch 1252/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 9.1044e-05 - accuracy: 1.0000 - val_loss: 2.7948 - val_accuracy: 0.7500\n",
      "Epoch 1253/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 9.6484e-05 - accuracy: 1.0000 - val_loss: 2.7916 - val_accuracy: 0.7500\n",
      "Epoch 1254/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 9.3360e-05 - accuracy: 1.0000 - val_loss: 2.7925 - val_accuracy: 0.7500\n",
      "Epoch 1255/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 9.2325e-05 - accuracy: 1.0000 - val_loss: 2.7962 - val_accuracy: 0.7500\n",
      "Epoch 1256/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 9.4360e-05 - accuracy: 1.0000 - val_loss: 2.8001 - val_accuracy: 0.7500\n",
      "Epoch 1257/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 8.9799e-05 - accuracy: 1.0000 - val_loss: 2.8005 - val_accuracy: 0.7500\n",
      "Epoch 1258/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 9.2071e-05 - accuracy: 1.0000 - val_loss: 2.7985 - val_accuracy: 0.7500\n",
      "Epoch 1259/2000\n",
      "80/80 [==============================] - 0s 291us/sample - loss: 8.9140e-05 - accuracy: 1.0000 - val_loss: 2.7975 - val_accuracy: 0.7500\n",
      "Epoch 1260/2000\n",
      "80/80 [==============================] - 0s 450us/sample - loss: 9.1510e-05 - accuracy: 1.0000 - val_loss: 2.7961 - val_accuracy: 0.7500\n",
      "Epoch 1261/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 8.8670e-05 - accuracy: 1.0000 - val_loss: 2.7939 - val_accuracy: 0.7500\n",
      "Epoch 1262/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 8.8343e-05 - accuracy: 1.0000 - val_loss: 2.7915 - val_accuracy: 0.7500\n",
      "Epoch 1263/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 9.1231e-05 - accuracy: 1.0000 - val_loss: 2.7912 - val_accuracy: 0.7500\n",
      "Epoch 1264/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 8.7910e-05 - accuracy: 1.0000 - val_loss: 2.7948 - val_accuracy: 0.7500\n",
      "Epoch 1265/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 8.9081e-05 - accuracy: 1.0000 - val_loss: 2.7956 - val_accuracy: 0.7500\n",
      "Epoch 1266/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 8.9341e-05 - accuracy: 1.0000 - val_loss: 2.7958 - val_accuracy: 0.7500\n",
      "Epoch 1267/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 9.4238e-05 - accuracy: 1.0000 - val_loss: 2.7926 - val_accuracy: 0.7500\n",
      "Epoch 1268/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 9.2298e-05 - accuracy: 1.0000 - val_loss: 2.7963 - val_accuracy: 0.7500\n",
      "Epoch 1269/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 8.9161e-05 - accuracy: 1.0000 - val_loss: 2.7953 - val_accuracy: 0.7500\n",
      "Epoch 1270/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 8.7710e-05 - accuracy: 1.0000 - val_loss: 2.7923 - val_accuracy: 0.7500\n",
      "Epoch 1271/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 8.8265e-05 - accuracy: 1.0000 - val_loss: 2.7901 - val_accuracy: 0.7500\n",
      "Epoch 1272/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 8.5720e-05 - accuracy: 1.0000 - val_loss: 2.7826 - val_accuracy: 0.8000\n",
      "Epoch 1273/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 1.0319e-04 - accuracy: 1.0000 - val_loss: 2.7794 - val_accuracy: 0.8000\n",
      "Epoch 1274/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 8.9596e-05 - accuracy: 1.0000 - val_loss: 2.7879 - val_accuracy: 0.7500\n",
      "Epoch 1275/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 9.2270e-05 - accuracy: 1.0000 - val_loss: 2.7974 - val_accuracy: 0.7500\n",
      "Epoch 1276/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 4.0215e-06 - accuracy: 1.00 - 0s 106us/sample - loss: 8.8183e-05 - accuracy: 1.0000 - val_loss: 2.8009 - val_accuracy: 0.7500\n",
      "Epoch 1277/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 9.1278e-05 - accuracy: 1.0000 - val_loss: 2.7977 - val_accuracy: 0.7500\n",
      "Epoch 1278/2000\n",
      "80/80 [==============================] - 0s 72us/sample - loss: 8.7081e-05 - accuracy: 1.0000 - val_loss: 2.7889 - val_accuracy: 0.7500\n",
      "Epoch 1279/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 8.5611e-05 - accuracy: 1.0000 - val_loss: 2.7889 - val_accuracy: 0.7500\n",
      "Epoch 1280/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 8.4456e-05 - accuracy: 1.0000 - val_loss: 2.7835 - val_accuracy: 0.7500\n",
      "Epoch 1281/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 9.0590e-05 - accuracy: 1.0000 - val_loss: 2.7741 - val_accuracy: 0.8000\n",
      "Epoch 1282/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 8.8172e-05 - accuracy: 1.0000 - val_loss: 2.7726 - val_accuracy: 0.8000\n",
      "Epoch 1283/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 9.1794e-05 - accuracy: 1.0000 - val_loss: 2.7740 - val_accuracy: 0.8000\n",
      "Epoch 1284/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 8.5746e-05 - accuracy: 1.0000 - val_loss: 2.7742 - val_accuracy: 0.8000\n",
      "Epoch 1285/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 8.5468e-05 - accuracy: 1.0000 - val_loss: 2.7767 - val_accuracy: 0.8000\n",
      "Epoch 1286/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 8.3427e-05 - accuracy: 1.0000 - val_loss: 2.7821 - val_accuracy: 0.8000\n",
      "Epoch 1287/2000\n",
      "80/80 [==============================] - 0s 70us/sample - loss: 8.3118e-05 - accuracy: 1.0000 - val_loss: 2.7859 - val_accuracy: 0.8000\n",
      "Epoch 1288/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 7.9334e-05 - accuracy: 1.0000 - val_loss: 2.7927 - val_accuracy: 0.7500\n",
      "Epoch 1289/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 8.3459e-05 - accuracy: 1.0000 - val_loss: 2.7970 - val_accuracy: 0.7500\n",
      "Epoch 1290/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 9.0925e-05 - accuracy: 1.0000 - val_loss: 2.7966 - val_accuracy: 0.7500\n",
      "Epoch 1291/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 8.9607e-05 - accuracy: 1.0000 - val_loss: 2.7857 - val_accuracy: 0.7500\n",
      "Epoch 1292/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 8.4691e-05 - accuracy: 1.0000 - val_loss: 2.7875 - val_accuracy: 0.7500\n",
      "Epoch 1293/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 8.3171e-05 - accuracy: 1.0000 - val_loss: 2.7899 - val_accuracy: 0.7500\n",
      "Epoch 1294/2000\n",
      "80/80 [==============================] - 0s 601us/sample - loss: 8.2562e-05 - accuracy: 1.0000 - val_loss: 2.7859 - val_accuracy: 0.7500\n",
      "Epoch 1295/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 8.1021e-05 - accuracy: 1.0000 - val_loss: 2.7933 - val_accuracy: 0.7500\n",
      "Epoch 1296/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 9.3757e-05 - accuracy: 1.0000 - val_loss: 2.7999 - val_accuracy: 0.7500\n",
      "Epoch 1297/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 8.8041e-05 - accuracy: 1.0000 - val_loss: 2.7918 - val_accuracy: 0.7500\n",
      "Epoch 1298/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 7.8350e-05 - accuracy: 1.0000 - val_loss: 2.7827 - val_accuracy: 0.8000\n",
      "Epoch 1299/2000\n",
      "80/80 [==============================] - 0s 73us/sample - loss: 8.0123e-05 - accuracy: 1.0000 - val_loss: 2.7848 - val_accuracy: 0.8000\n",
      "Epoch 1300/2000\n",
      "80/80 [==============================] - 0s 254us/sample - loss: 8.2217e-05 - accuracy: 1.0000 - val_loss: 2.7876 - val_accuracy: 0.8000\n",
      "Epoch 1301/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 8.1485e-05 - accuracy: 1.0000 - val_loss: 2.7883 - val_accuracy: 0.8000\n",
      "Epoch 1302/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 7.7492e-05 - accuracy: 1.0000 - val_loss: 2.7950 - val_accuracy: 0.7500\n",
      "Epoch 1303/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 7.8729e-05 - accuracy: 1.0000 - val_loss: 2.7993 - val_accuracy: 0.7500\n",
      "Epoch 1304/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 8.0827e-05 - accuracy: 1.0000 - val_loss: 2.7980 - val_accuracy: 0.7500\n",
      "Epoch 1305/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 8.4790e-05 - accuracy: 1.0000 - val_loss: 2.7945 - val_accuracy: 0.7500\n",
      "Epoch 1306/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 7.8161e-05 - accuracy: 1.0000 - val_loss: 2.7956 - val_accuracy: 0.7500\n",
      "Epoch 1307/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 8.0260e-05 - accuracy: 1.0000 - val_loss: 2.7929 - val_accuracy: 0.7500\n",
      "Epoch 1308/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 8.2534e-05 - accuracy: 1.0000 - val_loss: 2.7832 - val_accuracy: 0.8000\n",
      "Epoch 1309/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 7.6930e-05 - accuracy: 1.0000 - val_loss: 2.7786 - val_accuracy: 0.8000\n",
      "Epoch 1310/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 8.4251e-05 - accuracy: 1.0000 - val_loss: 2.7783 - val_accuracy: 0.8000\n",
      "Epoch 1311/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 7.5977e-05 - accuracy: 1.0000 - val_loss: 2.7866 - val_accuracy: 0.8000\n",
      "Epoch 1312/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 7.5112e-05 - accuracy: 1.0000 - val_loss: 2.7957 - val_accuracy: 0.7500\n",
      "Epoch 1313/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 9.0220e-05 - accuracy: 1.0000 - val_loss: 2.8006 - val_accuracy: 0.7500\n",
      "Epoch 1314/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 7.5876e-05 - accuracy: 1.0000 - val_loss: 2.7923 - val_accuracy: 0.7500\n",
      "Epoch 1315/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 9.3783e-05 - accuracy: 1.0000 - val_loss: 2.7739 - val_accuracy: 0.8000\n",
      "Epoch 1316/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 7.9665e-05 - accuracy: 1.0000 - val_loss: 2.7793 - val_accuracy: 0.8000\n",
      "Epoch 1317/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 8.0460e-05 - accuracy: 1.0000 - val_loss: 2.7848 - val_accuracy: 0.8000\n",
      "Epoch 1318/2000\n",
      "80/80 [==============================] - 0s 72us/sample - loss: 7.7678e-05 - accuracy: 1.0000 - val_loss: 2.7907 - val_accuracy: 0.7500\n",
      "Epoch 1319/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 7.6323e-05 - accuracy: 1.0000 - val_loss: 2.7947 - val_accuracy: 0.7500\n",
      "Epoch 1320/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 7.3438e-05 - accuracy: 1.0000 - val_loss: 2.7953 - val_accuracy: 0.7500\n",
      "Epoch 1321/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 7.5252e-05 - accuracy: 1.0000 - val_loss: 2.7967 - val_accuracy: 0.7500\n",
      "Epoch 1322/2000\n",
      "80/80 [==============================] - 0s 177us/sample - loss: 7.5480e-05 - accuracy: 1.0000 - val_loss: 2.7954 - val_accuracy: 0.7500\n",
      "Epoch 1323/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 7.2617e-05 - accuracy: 1.0000 - val_loss: 2.7989 - val_accuracy: 0.7500\n",
      "Epoch 1324/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 7.8122e-05 - accuracy: 1.0000 - val_loss: 2.8015 - val_accuracy: 0.7500\n",
      "Epoch 1325/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 7.2055e-05 - accuracy: 1.0000 - val_loss: 2.7940 - val_accuracy: 0.7500\n",
      "Epoch 1326/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 7.2399e-05 - accuracy: 1.0000 - val_loss: 2.7881 - val_accuracy: 0.8000\n",
      "Epoch 1327/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 7.5244e-05 - accuracy: 1.0000 - val_loss: 2.7875 - val_accuracy: 0.7500\n",
      "Epoch 1328/2000\n",
      "80/80 [==============================] - 0s 381us/sample - loss: 7.3225e-05 - accuracy: 1.0000 - val_loss: 2.7850 - val_accuracy: 0.8000\n",
      "Epoch 1329/2000\n",
      "80/80 [==============================] - 0s 174us/sample - loss: 7.6132e-05 - accuracy: 1.0000 - val_loss: 2.7862 - val_accuracy: 0.7500\n",
      "Epoch 1330/2000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 7.3201e-05 - accuracy: 1.0000 - val_loss: 2.7717 - val_accuracy: 0.7500\n",
      "Epoch 1331/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 7.1551e-05 - accuracy: 1.0000 - val_loss: 2.7922 - val_accuracy: 0.7500\n",
      "Epoch 1332/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 7.3301e-05 - accuracy: 1.0000 - val_loss: 2.7953 - val_accuracy: 0.7500\n",
      "Epoch 1333/2000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 7.3588e-05 - accuracy: 1.0000 - val_loss: 2.7922 - val_accuracy: 0.7500\n",
      "Epoch 1334/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 7.0461e-05 - accuracy: 1.0000 - val_loss: 2.7924 - val_accuracy: 0.7500\n",
      "Epoch 1335/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 7.2640e-05 - accuracy: 1.0000 - val_loss: 2.7927 - val_accuracy: 0.7500\n",
      "Epoch 1336/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 7.2922e-05 - accuracy: 1.0000 - val_loss: 2.7965 - val_accuracy: 0.7500\n",
      "Epoch 1337/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 6.9396e-05 - accuracy: 1.0000 - val_loss: 2.7971 - val_accuracy: 0.7500\n",
      "Epoch 1338/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 7.1700e-05 - accuracy: 1.0000 - val_loss: 2.7989 - val_accuracy: 0.7500\n",
      "Epoch 1339/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 6.9277e-05 - accuracy: 1.0000 - val_loss: 2.7973 - val_accuracy: 0.7500\n",
      "Epoch 1340/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 7.1033e-05 - accuracy: 1.0000 - val_loss: 2.7953 - val_accuracy: 0.7500\n",
      "Epoch 1341/2000\n",
      "80/80 [==============================] - 0s 252us/sample - loss: 7.0331e-05 - accuracy: 1.0000 - val_loss: 2.7959 - val_accuracy: 0.7500\n",
      "Epoch 1342/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 6.8343e-05 - accuracy: 1.0000 - val_loss: 2.7951 - val_accuracy: 0.7500\n",
      "Epoch 1343/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 7.0372e-05 - accuracy: 1.0000 - val_loss: 2.7946 - val_accuracy: 0.7500\n",
      "Epoch 1344/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 7.6016e-05 - accuracy: 1.0000 - val_loss: 2.7999 - val_accuracy: 0.7500\n",
      "Epoch 1345/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 6.8664e-05 - accuracy: 1.0000 - val_loss: 2.7946 - val_accuracy: 0.7500\n",
      "Epoch 1346/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 6.7609e-05 - accuracy: 1.0000 - val_loss: 2.7903 - val_accuracy: 0.7500\n",
      "Epoch 1347/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 7.0881e-05 - accuracy: 1.0000 - val_loss: 2.7873 - val_accuracy: 0.8000\n",
      "Epoch 1348/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 7.0333e-05 - accuracy: 1.0000 - val_loss: 2.7888 - val_accuracy: 0.7500\n",
      "Epoch 1349/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 7.0451e-05 - accuracy: 1.0000 - val_loss: 2.7897 - val_accuracy: 0.7500\n",
      "Epoch 1350/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 7.2125e-05 - accuracy: 1.0000 - val_loss: 2.7984 - val_accuracy: 0.7500\n",
      "Epoch 1351/2000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 6.8199e-05 - accuracy: 1.0000 - val_loss: 2.7999 - val_accuracy: 0.7500\n",
      "Epoch 1352/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 6.9056e-05 - accuracy: 1.0000 - val_loss: 2.8001 - val_accuracy: 0.7500\n",
      "Epoch 1353/2000\n",
      "80/80 [==============================] - 0s 68us/sample - loss: 7.0674e-05 - accuracy: 1.0000 - val_loss: 2.7974 - val_accuracy: 0.7500\n",
      "Epoch 1354/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 6.7793e-05 - accuracy: 1.0000 - val_loss: 2.7947 - val_accuracy: 0.7500\n",
      "Epoch 1355/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 6.5767e-05 - accuracy: 1.0000 - val_loss: 2.7878 - val_accuracy: 0.8000\n",
      "Epoch 1356/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 6.6666e-05 - accuracy: 1.0000 - val_loss: 2.7833 - val_accuracy: 0.8000\n",
      "Epoch 1357/2000\n",
      "80/80 [==============================] - 0s 74us/sample - loss: 7.2283e-05 - accuracy: 1.0000 - val_loss: 2.7828 - val_accuracy: 0.8000\n",
      "Epoch 1358/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 7.0870e-05 - accuracy: 1.0000 - val_loss: 2.7907 - val_accuracy: 0.7500\n",
      "Epoch 1359/2000\n",
      "80/80 [==============================] - 0s 444us/sample - loss: 6.5869e-05 - accuracy: 1.0000 - val_loss: 2.7927 - val_accuracy: 0.7500\n",
      "Epoch 1360/2000\n",
      "80/80 [==============================] - 0s 268us/sample - loss: 6.5017e-05 - accuracy: 1.0000 - val_loss: 2.7978 - val_accuracy: 0.7500\n",
      "Epoch 1361/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 6.8205e-05 - accuracy: 1.0000 - val_loss: 2.8001 - val_accuracy: 0.7500\n",
      "Epoch 1362/2000\n",
      "80/80 [==============================] - 0s 69us/sample - loss: 6.9062e-05 - accuracy: 1.0000 - val_loss: 2.7983 - val_accuracy: 0.7500\n",
      "Epoch 1363/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 6.4999e-05 - accuracy: 1.0000 - val_loss: 2.7943 - val_accuracy: 0.7500\n",
      "Epoch 1364/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 7.1932e-05 - accuracy: 1.0000 - val_loss: 2.7888 - val_accuracy: 0.7500\n",
      "Epoch 1365/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 6.4221e-05 - accuracy: 1.0000 - val_loss: 2.7921 - val_accuracy: 0.7500\n",
      "Epoch 1366/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 6.6198e-05 - accuracy: 1.0000 - val_loss: 2.7967 - val_accuracy: 0.7500\n",
      "Epoch 1367/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 6.5817e-05 - accuracy: 1.0000 - val_loss: 2.7938 - val_accuracy: 0.7500\n",
      "Epoch 1368/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 6.3089e-05 - accuracy: 1.0000 - val_loss: 2.7950 - val_accuracy: 0.7500\n",
      "Epoch 1369/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 6.3148e-05 - accuracy: 1.0000 - val_loss: 2.7940 - val_accuracy: 0.7500\n",
      "Epoch 1370/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 6.6254e-05 - accuracy: 1.0000 - val_loss: 2.7921 - val_accuracy: 0.8000\n",
      "Epoch 1371/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 6.4161e-05 - accuracy: 1.0000 - val_loss: 2.7940 - val_accuracy: 0.7500\n",
      "Epoch 1372/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 6.2921e-05 - accuracy: 1.0000 - val_loss: 2.7961 - val_accuracy: 0.7500\n",
      "Epoch 1373/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 6.3478e-05 - accuracy: 1.0000 - val_loss: 2.7972 - val_accuracy: 0.7500\n",
      "Epoch 1374/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 6.2153e-05 - accuracy: 1.0000 - val_loss: 2.8021 - val_accuracy: 0.7500\n",
      "Epoch 1375/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 7.1327e-05 - accuracy: 1.0000 - val_loss: 2.8043 - val_accuracy: 0.7500\n",
      "Epoch 1376/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 6.3201e-05 - accuracy: 1.0000 - val_loss: 2.7969 - val_accuracy: 0.7500\n",
      "Epoch 1377/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 6.0207e-05 - accuracy: 1.0000 - val_loss: 2.7910 - val_accuracy: 0.7500\n",
      "Epoch 1378/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 6.0969e-05 - accuracy: 1.0000 - val_loss: 2.7869 - val_accuracy: 0.8000\n",
      "Epoch 1379/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 6.8562e-05 - accuracy: 1.0000 - val_loss: 2.7817 - val_accuracy: 0.8000\n",
      "Epoch 1380/2000\n",
      "80/80 [==============================] - 0s 222us/sample - loss: 7.1609e-05 - accuracy: 1.0000 - val_loss: 2.7831 - val_accuracy: 0.8000\n",
      "Epoch 1381/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 7.0475e-05 - accuracy: 1.0000 - val_loss: 2.7965 - val_accuracy: 0.7500\n",
      "Epoch 1382/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 6.6352e-05 - accuracy: 1.0000 - val_loss: 2.8051 - val_accuracy: 0.7500\n",
      "Epoch 1383/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 7.4087e-05 - accuracy: 1.0000 - val_loss: 2.8064 - val_accuracy: 0.7500\n",
      "Epoch 1384/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 6.3429e-05 - accuracy: 1.0000 - val_loss: 2.7967 - val_accuracy: 0.7500\n",
      "Epoch 1385/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 5.9648e-05 - accuracy: 1.0000 - val_loss: 2.7883 - val_accuracy: 0.8000\n",
      "Epoch 1386/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 5.9768e-05 - accuracy: 1.0000 - val_loss: 2.7678 - val_accuracy: 0.8000\n",
      "Epoch 1387/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 6.2891e-05 - accuracy: 1.0000 - val_loss: 2.7719 - val_accuracy: 0.8000\n",
      "Epoch 1388/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 6.9695e-05 - accuracy: 1.0000 - val_loss: 2.7858 - val_accuracy: 0.8000\n",
      "Epoch 1389/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 6.6269e-05 - accuracy: 1.0000 - val_loss: 2.7761 - val_accuracy: 0.7500\n",
      "Epoch 1390/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 6.1669e-05 - accuracy: 1.0000 - val_loss: 2.8091 - val_accuracy: 0.7500\n",
      "Epoch 1391/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 6.9652e-05 - accuracy: 1.0000 - val_loss: 2.8182 - val_accuracy: 0.7500\n",
      "Epoch 1392/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 7.0073e-05 - accuracy: 1.0000 - val_loss: 2.8119 - val_accuracy: 0.7500\n",
      "Epoch 1393/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 6.1124e-05 - accuracy: 1.0000 - val_loss: 2.8108 - val_accuracy: 0.7500\n",
      "Epoch 1394/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 6.1612e-05 - accuracy: 1.0000 - val_loss: 2.8058 - val_accuracy: 0.7500\n",
      "Epoch 1395/2000\n",
      "80/80 [==============================] - 0s 470us/sample - loss: 5.7919e-05 - accuracy: 1.0000 - val_loss: 2.8022 - val_accuracy: 0.7500\n",
      "Epoch 1396/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 5.8922e-05 - accuracy: 1.0000 - val_loss: 2.8016 - val_accuracy: 0.7500\n",
      "Epoch 1397/2000\n",
      "80/80 [==============================] - 0s 246us/sample - loss: 5.7777e-05 - accuracy: 1.0000 - val_loss: 2.7998 - val_accuracy: 0.7500\n",
      "Epoch 1398/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 5.9333e-05 - accuracy: 1.0000 - val_loss: 2.7992 - val_accuracy: 0.7500\n",
      "Epoch 1399/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 6.0979e-05 - accuracy: 1.0000 - val_loss: 2.8058 - val_accuracy: 0.7500\n",
      "Epoch 1400/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 6.1139e-05 - accuracy: 1.0000 - val_loss: 2.8090 - val_accuracy: 0.7500\n",
      "Epoch 1401/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 6.0561e-05 - accuracy: 1.0000 - val_loss: 2.8072 - val_accuracy: 0.7500\n",
      "Epoch 1402/2000\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 5.7766e-05 - accuracy: 1.0000 - val_loss: 2.8050 - val_accuracy: 0.7500\n",
      "Epoch 1403/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 5.6916e-05 - accuracy: 1.0000 - val_loss: 2.8023 - val_accuracy: 0.7500\n",
      "Epoch 1404/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 5.6502e-05 - accuracy: 1.0000 - val_loss: 2.7992 - val_accuracy: 0.7500\n",
      "Epoch 1405/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 5.6343e-05 - accuracy: 1.0000 - val_loss: 2.7963 - val_accuracy: 0.7500\n",
      "Epoch 1406/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 5.8591e-05 - accuracy: 1.0000 - val_loss: 2.7959 - val_accuracy: 0.7500\n",
      "Epoch 1407/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 6.3306e-05 - accuracy: 1.0000 - val_loss: 2.7911 - val_accuracy: 0.7500\n",
      "Epoch 1408/2000\n",
      "80/80 [==============================] - 0s 74us/sample - loss: 5.7199e-05 - accuracy: 1.0000 - val_loss: 2.7964 - val_accuracy: 0.7500\n",
      "Epoch 1409/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 5.5905e-05 - accuracy: 1.0000 - val_loss: 2.8035 - val_accuracy: 0.7500\n",
      "Epoch 1410/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 5.6450e-05 - accuracy: 1.0000 - val_loss: 2.8082 - val_accuracy: 0.7500\n",
      "Epoch 1411/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 5.6416e-05 - accuracy: 1.0000 - val_loss: 2.8079 - val_accuracy: 0.7500\n",
      "Epoch 1412/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 5.5681e-05 - accuracy: 1.0000 - val_loss: 2.8043 - val_accuracy: 0.7500\n",
      "Epoch 1413/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 5.6472e-05 - accuracy: 1.0000 - val_loss: 2.8026 - val_accuracy: 0.7500\n",
      "Epoch 1414/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 5.3114e-05 - accuracy: 1.0000 - val_loss: 2.7839 - val_accuracy: 0.7500\n",
      "Epoch 1415/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 5.3562e-05 - accuracy: 1.0000 - val_loss: 2.7881 - val_accuracy: 0.8000\n",
      "Epoch 1416/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 6.7718e-05 - accuracy: 1.0000 - val_loss: 2.7850 - val_accuracy: 0.8000\n",
      "Epoch 1417/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 6.2822e-05 - accuracy: 1.0000 - val_loss: 2.7963 - val_accuracy: 0.7500\n",
      "Epoch 1418/2000\n",
      "80/80 [==============================] - 0s 72us/sample - loss: 5.2852e-05 - accuracy: 1.0000 - val_loss: 2.8049 - val_accuracy: 0.7500\n",
      "Epoch 1419/2000\n",
      "80/80 [==============================] - 0s 211us/sample - loss: 5.6202e-05 - accuracy: 1.0000 - val_loss: 2.8128 - val_accuracy: 0.7500\n",
      "Epoch 1420/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 5.9874e-05 - accuracy: 1.0000 - val_loss: 2.8134 - val_accuracy: 0.7500\n",
      "Epoch 1421/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 6.0563e-05 - accuracy: 1.0000 - val_loss: 2.8104 - val_accuracy: 0.7500\n",
      "Epoch 1422/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 5.4781e-05 - accuracy: 1.0000 - val_loss: 2.8015 - val_accuracy: 0.7500\n",
      "Epoch 1423/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 5.7671e-05 - accuracy: 1.0000 - val_loss: 2.7820 - val_accuracy: 0.7500\n",
      "Epoch 1424/2000\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 6.0302e-05 - accuracy: 1.0000 - val_loss: 2.7904 - val_accuracy: 0.7500\n",
      "Epoch 1425/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 5.4533e-05 - accuracy: 1.0000 - val_loss: 2.7973 - val_accuracy: 0.7500\n",
      "Epoch 1426/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 5.8214e-05 - accuracy: 1.0000 - val_loss: 2.8092 - val_accuracy: 0.7500\n",
      "Epoch 1427/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 5.4835e-05 - accuracy: 1.0000 - val_loss: 2.8137 - val_accuracy: 0.7500\n",
      "Epoch 1428/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 6.2125e-05 - accuracy: 1.0000 - val_loss: 2.8094 - val_accuracy: 0.7500\n",
      "Epoch 1429/2000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 6.0489e-05 - accuracy: 1.0000 - val_loss: 2.8092 - val_accuracy: 0.7500\n",
      "Epoch 1430/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 4.7956e-05 - accuracy: 1.0000 - val_loss: 2.7962 - val_accuracy: 0.7500\n",
      "Epoch 1431/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 5.7373e-05 - accuracy: 1.0000 - val_loss: 2.7854 - val_accuracy: 0.8000\n",
      "Epoch 1432/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 5.8662e-05 - accuracy: 1.0000 - val_loss: 2.7875 - val_accuracy: 0.8000\n",
      "Epoch 1433/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 5.7728e-05 - accuracy: 1.0000 - val_loss: 2.7928 - val_accuracy: 0.7500\n",
      "Epoch 1434/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 5.8264e-05 - accuracy: 1.0000 - val_loss: 2.8066 - val_accuracy: 0.7500\n",
      "Epoch 1435/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 5.1733e-05 - accuracy: 1.0000 - val_loss: 2.8147 - val_accuracy: 0.7500\n",
      "Epoch 1436/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 5.5616e-05 - accuracy: 1.0000 - val_loss: 2.8163 - val_accuracy: 0.7500\n",
      "Epoch 1437/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 5.8454e-05 - accuracy: 1.0000 - val_loss: 2.8158 - val_accuracy: 0.7500\n",
      "Epoch 1438/2000\n",
      "80/80 [==============================] - 0s 74us/sample - loss: 5.9450e-05 - accuracy: 1.0000 - val_loss: 2.8072 - val_accuracy: 0.7500\n",
      "Epoch 1439/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 5.2509e-05 - accuracy: 1.0000 - val_loss: 2.8044 - val_accuracy: 0.7500\n",
      "Epoch 1440/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 5.0750e-05 - accuracy: 1.0000 - val_loss: 2.7954 - val_accuracy: 0.7500\n",
      "Epoch 1441/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 5.4480e-05 - accuracy: 1.0000 - val_loss: 2.7900 - val_accuracy: 0.7500\n",
      "Epoch 1442/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 5.3786e-05 - accuracy: 1.0000 - val_loss: 2.7896 - val_accuracy: 0.8000\n",
      "Epoch 1443/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 5.4684e-05 - accuracy: 1.0000 - val_loss: 2.7938 - val_accuracy: 0.7500\n",
      "Epoch 1444/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 5.0794e-05 - accuracy: 1.0000 - val_loss: 2.7991 - val_accuracy: 0.7500\n",
      "Epoch 1445/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 5.1864e-05 - accuracy: 1.0000 - val_loss: 2.8049 - val_accuracy: 0.7500\n",
      "Epoch 1446/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 5.0332e-05 - accuracy: 1.0000 - val_loss: 2.8063 - val_accuracy: 0.7500\n",
      "Epoch 1447/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 4.9648e-05 - accuracy: 1.0000 - val_loss: 2.8078 - val_accuracy: 0.7500\n",
      "Epoch 1448/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 4.9503e-05 - accuracy: 1.0000 - val_loss: 2.8058 - val_accuracy: 0.7500\n",
      "Epoch 1449/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 5.0825e-05 - accuracy: 1.0000 - val_loss: 2.7915 - val_accuracy: 0.7500\n",
      "Epoch 1450/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 5.0435e-05 - accuracy: 1.0000 - val_loss: 2.8021 - val_accuracy: 0.7500\n",
      "Epoch 1451/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 4.8548e-05 - accuracy: 1.0000 - val_loss: 2.8054 - val_accuracy: 0.7500\n",
      "Epoch 1452/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 4.8939e-05 - accuracy: 1.0000 - val_loss: 2.8084 - val_accuracy: 0.7500\n",
      "Epoch 1453/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 4.9573e-05 - accuracy: 1.0000 - val_loss: 2.7980 - val_accuracy: 0.7500\n",
      "Epoch 1454/2000\n",
      "80/80 [==============================] - 0s 64us/sample - loss: 5.0728e-05 - accuracy: 1.0000 - val_loss: 2.8083 - val_accuracy: 0.7500\n",
      "Epoch 1455/2000\n",
      "80/80 [==============================] - 0s 210us/sample - loss: 4.9185e-05 - accuracy: 1.0000 - val_loss: 2.8037 - val_accuracy: 0.7500\n",
      "Epoch 1456/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 4.8088e-05 - accuracy: 1.0000 - val_loss: 2.8003 - val_accuracy: 0.7500\n",
      "Epoch 1457/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 4.8007e-05 - accuracy: 1.0000 - val_loss: 2.7977 - val_accuracy: 0.7500\n",
      "Epoch 1458/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 4.9027e-05 - accuracy: 1.0000 - val_loss: 2.7951 - val_accuracy: 0.7500\n",
      "Epoch 1459/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 4.8726e-05 - accuracy: 1.0000 - val_loss: 2.7806 - val_accuracy: 0.8000\n",
      "Epoch 1460/2000\n",
      "80/80 [==============================] - 0s 71us/sample - loss: 4.8933e-05 - accuracy: 1.0000 - val_loss: 2.7892 - val_accuracy: 0.8000\n",
      "Epoch 1461/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 5.1349e-05 - accuracy: 1.0000 - val_loss: 2.7902 - val_accuracy: 0.8000\n",
      "Epoch 1462/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 4.8529e-05 - accuracy: 1.0000 - val_loss: 2.7964 - val_accuracy: 0.7500\n",
      "Epoch 1463/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 4.6499e-05 - accuracy: 1.0000 - val_loss: 2.8030 - val_accuracy: 0.7500\n",
      "Epoch 1464/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 4.7528e-05 - accuracy: 1.0000 - val_loss: 2.8082 - val_accuracy: 0.7500\n",
      "Epoch 1465/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 4.8867e-05 - accuracy: 1.0000 - val_loss: 2.8086 - val_accuracy: 0.7500\n",
      "Epoch 1466/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 4.8555e-05 - accuracy: 1.0000 - val_loss: 2.7962 - val_accuracy: 0.7500\n",
      "Epoch 1467/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 4.8034e-05 - accuracy: 1.0000 - val_loss: 2.8037 - val_accuracy: 0.7500\n",
      "Epoch 1468/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 4.8490e-05 - accuracy: 1.0000 - val_loss: 2.8000 - val_accuracy: 0.7500\n",
      "Epoch 1469/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 4.6427e-05 - accuracy: 1.0000 - val_loss: 2.8005 - val_accuracy: 0.7500\n",
      "Epoch 1470/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 4.6372e-05 - accuracy: 1.0000 - val_loss: 2.7997 - val_accuracy: 0.7500\n",
      "Epoch 1471/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 4.8732e-05 - accuracy: 1.0000 - val_loss: 2.7986 - val_accuracy: 0.7500\n",
      "Epoch 1472/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 4.5788e-05 - accuracy: 1.0000 - val_loss: 2.8026 - val_accuracy: 0.7500\n",
      "Epoch 1473/2000\n",
      "80/80 [==============================] - 0s 187us/sample - loss: 5.0253e-05 - accuracy: 1.0000 - val_loss: 2.8087 - val_accuracy: 0.7500\n",
      "Epoch 1474/2000\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 4.7900e-05 - accuracy: 1.0000 - val_loss: 2.8061 - val_accuracy: 0.7500\n",
      "Epoch 1475/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 4.6293e-05 - accuracy: 1.0000 - val_loss: 2.8000 - val_accuracy: 0.7500\n",
      "Epoch 1476/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 4.5284e-05 - accuracy: 1.0000 - val_loss: 2.7862 - val_accuracy: 0.7500\n",
      "Epoch 1477/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 4.5629e-05 - accuracy: 1.0000 - val_loss: 2.7960 - val_accuracy: 0.7500\n",
      "Epoch 1478/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 4.5465e-05 - accuracy: 1.0000 - val_loss: 2.7941 - val_accuracy: 0.8000\n",
      "Epoch 1479/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 4.6975e-05 - accuracy: 1.0000 - val_loss: 2.7933 - val_accuracy: 0.8000\n",
      "Epoch 1480/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 4.8398e-05 - accuracy: 1.0000 - val_loss: 2.7965 - val_accuracy: 0.7500\n",
      "Epoch 1481/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 4.4837e-05 - accuracy: 1.0000 - val_loss: 2.7954 - val_accuracy: 0.7500\n",
      "Epoch 1482/2000\n",
      "80/80 [==============================] - 0s 531us/sample - loss: 4.6581e-05 - accuracy: 1.0000 - val_loss: 2.7951 - val_accuracy: 0.8000\n",
      "Epoch 1483/2000\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 4.7022e-05 - accuracy: 1.0000 - val_loss: 2.7958 - val_accuracy: 0.8000\n",
      "Epoch 1484/2000\n",
      "80/80 [==============================] - 0s 199us/sample - loss: 4.4853e-05 - accuracy: 1.0000 - val_loss: 2.8032 - val_accuracy: 0.7500\n",
      "Epoch 1485/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 4.7996e-05 - accuracy: 1.0000 - val_loss: 2.8090 - val_accuracy: 0.7500\n",
      "Epoch 1486/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 4.9581e-05 - accuracy: 1.0000 - val_loss: 2.8081 - val_accuracy: 0.7500\n",
      "Epoch 1487/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 4.5391e-05 - accuracy: 1.0000 - val_loss: 2.7983 - val_accuracy: 0.7500\n",
      "Epoch 1488/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 4.7031e-05 - accuracy: 1.0000 - val_loss: 2.7680 - val_accuracy: 0.8000\n",
      "Epoch 1489/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 4.7766e-05 - accuracy: 1.0000 - val_loss: 2.7854 - val_accuracy: 0.8000\n",
      "Epoch 1490/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 4.7065e-05 - accuracy: 1.0000 - val_loss: 2.7887 - val_accuracy: 0.8000\n",
      "Epoch 1491/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 4.4141e-05 - accuracy: 1.0000 - val_loss: 2.7879 - val_accuracy: 0.7500\n",
      "Epoch 1492/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 4.1573e-05 - accuracy: 1.0000 - val_loss: 2.8125 - val_accuracy: 0.7500\n",
      "Epoch 1493/2000\n",
      "80/80 [==============================] - 0s 177us/sample - loss: 4.3587e-05 - accuracy: 1.0000 - val_loss: 2.8211 - val_accuracy: 0.7500\n",
      "Epoch 1494/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 4.9570e-05 - accuracy: 1.0000 - val_loss: 2.8282 - val_accuracy: 0.7500\n",
      "Epoch 1495/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 5.0484e-05 - accuracy: 1.0000 - val_loss: 2.8286 - val_accuracy: 0.7500\n",
      "Epoch 1496/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 4.8900e-05 - accuracy: 1.0000 - val_loss: 2.8263 - val_accuracy: 0.7500\n",
      "Epoch 1497/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 4.5497e-05 - accuracy: 1.0000 - val_loss: 2.8236 - val_accuracy: 0.7500\n",
      "Epoch 1498/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 4.3684e-05 - accuracy: 1.0000 - val_loss: 2.8131 - val_accuracy: 0.7500\n",
      "Epoch 1499/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 4.5137e-05 - accuracy: 1.0000 - val_loss: 2.8083 - val_accuracy: 0.7500\n",
      "Epoch 1500/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 4.7537e-05 - accuracy: 1.0000 - val_loss: 2.8094 - val_accuracy: 0.7500\n",
      "Epoch 1501/2000\n",
      "80/80 [==============================] - 0s 70us/sample - loss: 4.3129e-05 - accuracy: 1.0000 - val_loss: 2.8198 - val_accuracy: 0.7500\n",
      "Epoch 1502/2000\n",
      "80/80 [==============================] - 0s 172us/sample - loss: 4.1335e-05 - accuracy: 1.0000 - val_loss: 2.8268 - val_accuracy: 0.7500\n",
      "Epoch 1503/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 4.6453e-05 - accuracy: 1.0000 - val_loss: 2.8317 - val_accuracy: 0.7500\n",
      "Epoch 1504/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 4.7436e-05 - accuracy: 1.0000 - val_loss: 2.8281 - val_accuracy: 0.7500\n",
      "Epoch 1505/2000\n",
      "80/80 [==============================] - 0s 160us/sample - loss: 4.7276e-05 - accuracy: 1.0000 - val_loss: 2.8033 - val_accuracy: 0.7500\n",
      "Epoch 1506/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 4.5057e-05 - accuracy: 1.0000 - val_loss: 2.7891 - val_accuracy: 0.7500\n",
      "Epoch 1507/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 4.3760e-05 - accuracy: 1.0000 - val_loss: 2.8037 - val_accuracy: 0.7500\n",
      "Epoch 1508/2000\n",
      "80/80 [==============================] - 0s 172us/sample - loss: 4.6212e-05 - accuracy: 1.0000 - val_loss: 2.8058 - val_accuracy: 0.7500\n",
      "Epoch 1509/2000\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 4.0960e-05 - accuracy: 1.0000 - val_loss: 2.8164 - val_accuracy: 0.7500\n",
      "Epoch 1510/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 4.5594e-05 - accuracy: 1.0000 - val_loss: 2.8307 - val_accuracy: 0.7500\n",
      "Epoch 1511/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 5.3648e-05 - accuracy: 1.0000 - val_loss: 2.8364 - val_accuracy: 0.7500\n",
      "Epoch 1512/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 4.4501e-05 - accuracy: 1.0000 - val_loss: 2.8254 - val_accuracy: 0.7500\n",
      "Epoch 1513/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 4.5581e-05 - accuracy: 1.0000 - val_loss: 2.8115 - val_accuracy: 0.7500\n",
      "Epoch 1514/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 4.0727e-05 - accuracy: 1.0000 - val_loss: 2.8050 - val_accuracy: 0.7500\n",
      "Epoch 1515/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 4.4136e-05 - accuracy: 1.0000 - val_loss: 2.8031 - val_accuracy: 0.7500\n",
      "Epoch 1516/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 4.6435e-05 - accuracy: 1.0000 - val_loss: 2.8047 - val_accuracy: 0.7500\n",
      "Epoch 1517/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 4.5512e-05 - accuracy: 1.0000 - val_loss: 2.8125 - val_accuracy: 0.7500\n",
      "Epoch 1518/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 4.0457e-05 - accuracy: 1.0000 - val_loss: 2.8163 - val_accuracy: 0.7500\n",
      "Epoch 1519/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 4.0033e-05 - accuracy: 1.0000 - val_loss: 2.8203 - val_accuracy: 0.7500\n",
      "Epoch 1520/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 4.1774e-05 - accuracy: 1.0000 - val_loss: 2.8102 - val_accuracy: 0.7500\n",
      "Epoch 1521/2000\n",
      "80/80 [==============================] - 0s 214us/sample - loss: 4.1811e-05 - accuracy: 1.0000 - val_loss: 2.8168 - val_accuracy: 0.7500\n",
      "Epoch 1522/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 4.0425e-05 - accuracy: 1.0000 - val_loss: 2.8165 - val_accuracy: 0.7500\n",
      "Epoch 1523/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 4.0704e-05 - accuracy: 1.0000 - val_loss: 2.8189 - val_accuracy: 0.7500\n",
      "Epoch 1524/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 3.9395e-05 - accuracy: 1.0000 - val_loss: 2.8084 - val_accuracy: 0.7500\n",
      "Epoch 1525/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 4.0222e-05 - accuracy: 1.0000 - val_loss: 2.8198 - val_accuracy: 0.7500\n",
      "Epoch 1526/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 3.9872e-05 - accuracy: 1.0000 - val_loss: 2.8072 - val_accuracy: 0.7500\n",
      "Epoch 1527/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 3.8630e-05 - accuracy: 1.0000 - val_loss: 2.8030 - val_accuracy: 0.7500\n",
      "Epoch 1528/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 4.1481e-05 - accuracy: 1.0000 - val_loss: 2.8101 - val_accuracy: 0.7500\n",
      "Epoch 1529/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 4.0315e-05 - accuracy: 1.0000 - val_loss: 2.7993 - val_accuracy: 0.7500\n",
      "Epoch 1530/2000\n",
      "80/80 [==============================] - 0s 77us/sample - loss: 3.9852e-05 - accuracy: 1.0000 - val_loss: 2.8110 - val_accuracy: 0.7500\n",
      "Epoch 1531/2000\n",
      "80/80 [==============================] - 0s 169us/sample - loss: 4.0674e-05 - accuracy: 1.0000 - val_loss: 2.8150 - val_accuracy: 0.7500\n",
      "Epoch 1532/2000\n",
      "80/80 [==============================] - 0s 68us/sample - loss: 3.8441e-05 - accuracy: 1.0000 - val_loss: 2.8167 - val_accuracy: 0.7500\n",
      "Epoch 1533/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 3.8401e-05 - accuracy: 1.0000 - val_loss: 2.8184 - val_accuracy: 0.7500\n",
      "Epoch 1534/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 3.9587e-05 - accuracy: 1.0000 - val_loss: 2.8200 - val_accuracy: 0.7500\n",
      "Epoch 1535/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 3.8431e-05 - accuracy: 1.0000 - val_loss: 2.8190 - val_accuracy: 0.7500\n",
      "Epoch 1536/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 3.8875e-05 - accuracy: 1.0000 - val_loss: 2.8180 - val_accuracy: 0.7500\n",
      "Epoch 1537/2000\n",
      "80/80 [==============================] - 0s 502us/sample - loss: 3.8046e-05 - accuracy: 1.0000 - val_loss: 2.8149 - val_accuracy: 0.7500\n",
      "Epoch 1538/2000\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 3.9278e-05 - accuracy: 1.0000 - val_loss: 2.8000 - val_accuracy: 0.7500\n",
      "Epoch 1539/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 3.7975e-05 - accuracy: 1.0000 - val_loss: 2.8108 - val_accuracy: 0.7500\n",
      "Epoch 1540/2000\n",
      "80/80 [==============================] - 0s 214us/sample - loss: 3.9782e-05 - accuracy: 1.0000 - val_loss: 2.8127 - val_accuracy: 0.7500\n",
      "Epoch 1541/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 3.9546e-05 - accuracy: 1.0000 - val_loss: 2.8090 - val_accuracy: 0.7500\n",
      "Epoch 1542/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 3.8760e-05 - accuracy: 1.0000 - val_loss: 2.8101 - val_accuracy: 0.7500\n",
      "Epoch 1543/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 3.7964e-05 - accuracy: 1.0000 - val_loss: 2.8112 - val_accuracy: 0.7500\n",
      "Epoch 1544/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 3.7992e-05 - accuracy: 1.0000 - val_loss: 2.8124 - val_accuracy: 0.7500\n",
      "Epoch 1545/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 3.7408e-05 - accuracy: 1.0000 - val_loss: 2.8153 - val_accuracy: 0.7500\n",
      "Epoch 1546/2000\n",
      "80/80 [==============================] - 0s 67us/sample - loss: 3.7441e-05 - accuracy: 1.0000 - val_loss: 2.8176 - val_accuracy: 0.7500\n",
      "Epoch 1547/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 3.6574e-05 - accuracy: 1.0000 - val_loss: 2.8121 - val_accuracy: 0.7500\n",
      "Epoch 1548/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 3.7971e-05 - accuracy: 1.0000 - val_loss: 2.8124 - val_accuracy: 0.7500\n",
      "Epoch 1549/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 3.8883e-05 - accuracy: 1.0000 - val_loss: 2.8204 - val_accuracy: 0.7500\n",
      "Epoch 1550/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 3.9630e-05 - accuracy: 1.0000 - val_loss: 2.8069 - val_accuracy: 0.7500\n",
      "Epoch 1551/2000\n",
      "80/80 [==============================] - 0s 64us/sample - loss: 3.9880e-05 - accuracy: 1.0000 - val_loss: 2.8063 - val_accuracy: 0.7500\n",
      "Epoch 1552/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 3.7064e-05 - accuracy: 1.0000 - val_loss: 2.8006 - val_accuracy: 0.7500\n",
      "Epoch 1553/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 3.8278e-05 - accuracy: 1.0000 - val_loss: 2.7865 - val_accuracy: 0.7500\n",
      "Epoch 1554/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 3.8275e-05 - accuracy: 1.0000 - val_loss: 2.7980 - val_accuracy: 0.7500\n",
      "Epoch 1555/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 3.7754e-05 - accuracy: 1.0000 - val_loss: 2.8010 - val_accuracy: 0.7500\n",
      "Epoch 1556/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 3.6527e-05 - accuracy: 1.0000 - val_loss: 2.7830 - val_accuracy: 0.7500\n",
      "Epoch 1557/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 3.5928e-05 - accuracy: 1.0000 - val_loss: 2.7981 - val_accuracy: 0.7500\n",
      "Epoch 1558/2000\n",
      "80/80 [==============================] - 0s 17us/sample - loss: 3.5968e-05 - accuracy: 1.0000 - val_loss: 2.8109 - val_accuracy: 0.7500\n",
      "Epoch 1559/2000\n",
      "80/80 [==============================] - 0s 237us/sample - loss: 3.6851e-05 - accuracy: 1.0000 - val_loss: 2.8121 - val_accuracy: 0.7500\n",
      "Epoch 1560/2000\n",
      "80/80 [==============================] - 0s 50us/sample - loss: 3.8342e-05 - accuracy: 1.0000 - val_loss: 2.8129 - val_accuracy: 0.7500\n",
      "Epoch 1561/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 3.5781e-05 - accuracy: 1.0000 - val_loss: 2.8027 - val_accuracy: 0.7500\n",
      "Epoch 1562/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 3.4129e-05 - accuracy: 1.0000 - val_loss: 2.7994 - val_accuracy: 0.7500\n",
      "Epoch 1563/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 3.5814e-05 - accuracy: 1.0000 - val_loss: 2.7912 - val_accuracy: 0.7500\n",
      "Epoch 1564/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 3.9238e-05 - accuracy: 1.0000 - val_loss: 2.7845 - val_accuracy: 0.7500\n",
      "Epoch 1565/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 4.1732e-05 - accuracy: 1.0000 - val_loss: 2.7917 - val_accuracy: 0.7500\n",
      "Epoch 1566/2000\n",
      "80/80 [==============================] - 0s 73us/sample - loss: 4.0549e-05 - accuracy: 1.0000 - val_loss: 2.8097 - val_accuracy: 0.7500\n",
      "Epoch 1567/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 3.7873e-05 - accuracy: 1.0000 - val_loss: 2.8192 - val_accuracy: 0.7500\n",
      "Epoch 1568/2000\n",
      "80/80 [==============================] - 0s 558us/sample - loss: 3.7648e-05 - accuracy: 1.0000 - val_loss: 2.8220 - val_accuracy: 0.7500\n",
      "Epoch 1569/2000\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 3.9020e-05 - accuracy: 1.0000 - val_loss: 2.8204 - val_accuracy: 0.7500\n",
      "Epoch 1570/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 3.7198e-05 - accuracy: 1.0000 - val_loss: 2.8146 - val_accuracy: 0.7500\n",
      "Epoch 1571/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 3.6775e-05 - accuracy: 1.0000 - val_loss: 2.8080 - val_accuracy: 0.7500\n",
      "Epoch 1572/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 3.4510e-05 - accuracy: 1.0000 - val_loss: 2.7994 - val_accuracy: 0.7500\n",
      "Epoch 1573/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 3.5498e-05 - accuracy: 1.0000 - val_loss: 2.8026 - val_accuracy: 0.7500\n",
      "Epoch 1574/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 3.6950e-05 - accuracy: 1.0000 - val_loss: 2.7774 - val_accuracy: 0.7500\n",
      "Epoch 1575/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 3.4863e-05 - accuracy: 1.0000 - val_loss: 2.8031 - val_accuracy: 0.7500\n",
      "Epoch 1576/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 3.2881e-05 - accuracy: 1.0000 - val_loss: 2.8120 - val_accuracy: 0.7500\n",
      "Epoch 1577/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 3.3648e-05 - accuracy: 1.0000 - val_loss: 2.8179 - val_accuracy: 0.7500\n",
      "Epoch 1578/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 3.6115e-05 - accuracy: 1.0000 - val_loss: 2.8109 - val_accuracy: 0.7500\n",
      "Epoch 1579/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 3.9237e-05 - accuracy: 1.0000 - val_loss: 2.8211 - val_accuracy: 0.7500\n",
      "Epoch 1580/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 3.8556e-05 - accuracy: 1.0000 - val_loss: 2.8052 - val_accuracy: 0.7500\n",
      "Epoch 1581/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 3.5916e-05 - accuracy: 1.0000 - val_loss: 2.8123 - val_accuracy: 0.7500\n",
      "Epoch 1582/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 3.5992e-05 - accuracy: 1.0000 - val_loss: 2.7943 - val_accuracy: 0.7500\n",
      "Epoch 1583/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 3.4954e-05 - accuracy: 1.0000 - val_loss: 2.7793 - val_accuracy: 0.7500\n",
      "Epoch 1584/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 3.4086e-05 - accuracy: 1.0000 - val_loss: 2.7890 - val_accuracy: 0.7500\n",
      "Epoch 1585/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 1.3635e-06 - accuracy: 1.00 - 0s 95us/sample - loss: 3.5846e-05 - accuracy: 1.0000 - val_loss: 2.7942 - val_accuracy: 0.7500\n",
      "Epoch 1586/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 3.3824e-05 - accuracy: 1.0000 - val_loss: 2.8034 - val_accuracy: 0.7500\n",
      "Epoch 1587/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 3.2948e-05 - accuracy: 1.0000 - val_loss: 2.7981 - val_accuracy: 0.7500\n",
      "Epoch 1588/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 3.2968e-05 - accuracy: 1.0000 - val_loss: 2.8126 - val_accuracy: 0.7500\n",
      "Epoch 1589/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 3.3661e-05 - accuracy: 1.0000 - val_loss: 2.8021 - val_accuracy: 0.7500\n",
      "Epoch 1590/2000\n",
      "80/80 [==============================] - 0s 14us/sample - loss: 3.3746e-05 - accuracy: 1.0000 - val_loss: 2.8100 - val_accuracy: 0.7500\n",
      "Epoch 1591/2000\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 3.5551e-05 - accuracy: 1.0000 - val_loss: 2.8005 - val_accuracy: 0.7500\n",
      "Epoch 1592/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 3.3271e-05 - accuracy: 1.0000 - val_loss: 2.8056 - val_accuracy: 0.7500\n",
      "Epoch 1593/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 3.2000e-05 - accuracy: 1.0000 - val_loss: 2.8057 - val_accuracy: 0.7500\n",
      "Epoch 1594/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 3.4595e-05 - accuracy: 1.0000 - val_loss: 2.8032 - val_accuracy: 0.7500\n",
      "Epoch 1595/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 3.4463e-05 - accuracy: 1.0000 - val_loss: 2.8083 - val_accuracy: 0.7500\n",
      "Epoch 1596/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 3.5993e-05 - accuracy: 1.0000 - val_loss: 2.8008 - val_accuracy: 0.7500\n",
      "Epoch 1597/2000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 3.1947e-05 - accuracy: 1.0000 - val_loss: 2.7915 - val_accuracy: 0.7500\n",
      "Epoch 1598/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 3.1909e-05 - accuracy: 1.0000 - val_loss: 2.7896 - val_accuracy: 0.7500\n",
      "Epoch 1599/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 3.3113e-05 - accuracy: 1.0000 - val_loss: 2.7888 - val_accuracy: 0.8000\n",
      "Epoch 1600/2000\n",
      "80/80 [==============================] - 0s 59us/sample - loss: 3.7242e-05 - accuracy: 1.0000 - val_loss: 2.7869 - val_accuracy: 0.8000\n",
      "Epoch 1601/2000\n",
      "80/80 [==============================] - 0s 545us/sample - loss: 3.7987e-05 - accuracy: 1.0000 - val_loss: 2.7882 - val_accuracy: 0.8000\n",
      "Epoch 1602/2000\n",
      "80/80 [==============================] - 0s 219us/sample - loss: 3.7058e-05 - accuracy: 1.0000 - val_loss: 2.8036 - val_accuracy: 0.7500\n",
      "Epoch 1603/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 2.9483e-05 - accuracy: 1.0000 - val_loss: 2.8185 - val_accuracy: 0.7500\n",
      "Epoch 1604/2000\n",
      "80/80 [==============================] - 0s 164us/sample - loss: 3.3286e-05 - accuracy: 1.0000 - val_loss: 2.8269 - val_accuracy: 0.7500\n",
      "Epoch 1605/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 3.7159e-05 - accuracy: 1.0000 - val_loss: 2.8248 - val_accuracy: 0.7500\n",
      "Epoch 1606/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 3.6239e-05 - accuracy: 1.0000 - val_loss: 2.8198 - val_accuracy: 0.7500\n",
      "Epoch 1607/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 3.2909e-05 - accuracy: 1.0000 - val_loss: 2.8108 - val_accuracy: 0.7500\n",
      "Epoch 1608/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 3.1640e-05 - accuracy: 1.0000 - val_loss: 2.7918 - val_accuracy: 0.7500\n",
      "Epoch 1609/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 3.3894e-05 - accuracy: 1.0000 - val_loss: 2.7717 - val_accuracy: 0.7500\n",
      "Epoch 1610/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 3.4587e-05 - accuracy: 1.0000 - val_loss: 2.7695 - val_accuracy: 0.7500\n",
      "Epoch 1611/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 3.3161e-05 - accuracy: 1.0000 - val_loss: 2.7915 - val_accuracy: 0.7500\n",
      "Epoch 1612/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 3.3125e-05 - accuracy: 1.0000 - val_loss: 2.8011 - val_accuracy: 0.7500\n",
      "Epoch 1613/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 3.1228e-05 - accuracy: 1.0000 - val_loss: 2.7955 - val_accuracy: 0.7500\n",
      "Epoch 1614/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 3.0830e-05 - accuracy: 1.0000 - val_loss: 2.8025 - val_accuracy: 0.7500\n",
      "Epoch 1615/2000\n",
      "80/80 [==============================] - 0s 251us/sample - loss: 3.0058e-05 - accuracy: 1.0000 - val_loss: 2.7992 - val_accuracy: 0.7500\n",
      "Epoch 1616/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 2.9951e-05 - accuracy: 1.0000 - val_loss: 2.8010 - val_accuracy: 0.7500\n",
      "Epoch 1617/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 2.9895e-05 - accuracy: 1.0000 - val_loss: 2.8082 - val_accuracy: 0.7500\n",
      "Epoch 1618/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 3.0609e-05 - accuracy: 1.0000 - val_loss: 2.8060 - val_accuracy: 0.7500\n",
      "Epoch 1619/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 3.0443e-05 - accuracy: 1.0000 - val_loss: 2.8116 - val_accuracy: 0.7500\n",
      "Epoch 1620/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 3.0254e-05 - accuracy: 1.0000 - val_loss: 2.8009 - val_accuracy: 0.7500\n",
      "Epoch 1621/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 2.9611e-05 - accuracy: 1.0000 - val_loss: 2.7991 - val_accuracy: 0.7500\n",
      "Epoch 1622/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 3.1364e-05 - accuracy: 1.0000 - val_loss: 2.7972 - val_accuracy: 0.7500\n",
      "Epoch 1623/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 3.0799e-05 - accuracy: 1.0000 - val_loss: 2.8127 - val_accuracy: 0.7500\n",
      "Epoch 1624/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 3.9818e-05 - accuracy: 1.00 - 0s 79us/sample - loss: 2.9721e-05 - accuracy: 1.0000 - val_loss: 2.8137 - val_accuracy: 0.7500\n",
      "Epoch 1625/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 3.0517e-05 - accuracy: 1.0000 - val_loss: 2.8159 - val_accuracy: 0.7500\n",
      "Epoch 1626/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 3.0378e-05 - accuracy: 1.0000 - val_loss: 2.8154 - val_accuracy: 0.7500\n",
      "Epoch 1627/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 2.9937e-05 - accuracy: 1.0000 - val_loss: 2.8164 - val_accuracy: 0.7500\n",
      "Epoch 1628/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 2.9864e-05 - accuracy: 1.0000 - val_loss: 2.8065 - val_accuracy: 0.7500\n",
      "Epoch 1629/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 3.0572e-05 - accuracy: 1.0000 - val_loss: 2.8042 - val_accuracy: 0.7500\n",
      "Epoch 1630/2000\n",
      "80/80 [==============================] - 0s 74us/sample - loss: 3.0975e-05 - accuracy: 1.0000 - val_loss: 2.8069 - val_accuracy: 0.7500\n",
      "Epoch 1631/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 2.9417e-05 - accuracy: 1.0000 - val_loss: 2.8073 - val_accuracy: 0.7500\n",
      "Epoch 1632/2000\n",
      "80/80 [==============================] - 0s 526us/sample - loss: 2.9260e-05 - accuracy: 1.0000 - val_loss: 2.8134 - val_accuracy: 0.7500\n",
      "Epoch 1633/2000\n",
      "80/80 [==============================] - 0s 57us/sample - loss: 3.1903e-05 - accuracy: 1.0000 - val_loss: 2.7945 - val_accuracy: 0.7500\n",
      "Epoch 1634/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 3.0994e-05 - accuracy: 1.0000 - val_loss: 2.8107 - val_accuracy: 0.7500\n",
      "Epoch 1635/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 3.0607e-05 - accuracy: 1.0000 - val_loss: 2.8031 - val_accuracy: 0.7500\n",
      "Epoch 1636/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 2.8369e-05 - accuracy: 1.0000 - val_loss: 2.7875 - val_accuracy: 0.7500\n",
      "Epoch 1637/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 2.9236e-05 - accuracy: 1.0000 - val_loss: 2.8092 - val_accuracy: 0.7500\n",
      "Epoch 1638/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 2.9851e-05 - accuracy: 1.0000 - val_loss: 2.8090 - val_accuracy: 0.7500\n",
      "Epoch 1639/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 3.0047e-05 - accuracy: 1.0000 - val_loss: 2.8091 - val_accuracy: 0.7500\n",
      "Epoch 1640/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 2.9958e-05 - accuracy: 1.0000 - val_loss: 2.8038 - val_accuracy: 0.7500\n",
      "Epoch 1641/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 2.8529e-05 - accuracy: 1.0000 - val_loss: 2.8011 - val_accuracy: 0.7500\n",
      "Epoch 1642/2000\n",
      "80/80 [==============================] - 0s 70us/sample - loss: 2.8067e-05 - accuracy: 1.0000 - val_loss: 2.8025 - val_accuracy: 0.7500\n",
      "Epoch 1643/2000\n",
      "80/80 [==============================] - 0s 71us/sample - loss: 2.7848e-05 - accuracy: 1.0000 - val_loss: 2.7910 - val_accuracy: 0.7500\n",
      "Epoch 1644/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 2.8762e-05 - accuracy: 1.0000 - val_loss: 2.7928 - val_accuracy: 0.8000\n",
      "Epoch 1645/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 2.9402e-05 - accuracy: 1.0000 - val_loss: 2.7871 - val_accuracy: 0.8000\n",
      "Epoch 1646/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 3.0151e-05 - accuracy: 1.0000 - val_loss: 2.7782 - val_accuracy: 0.7500\n",
      "Epoch 1647/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 2.9399e-05 - accuracy: 1.0000 - val_loss: 2.7960 - val_accuracy: 0.7500\n",
      "Epoch 1648/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 2.7563e-05 - accuracy: 1.0000 - val_loss: 2.7859 - val_accuracy: 0.7500\n",
      "Epoch 1649/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 2.8347e-05 - accuracy: 1.0000 - val_loss: 2.7905 - val_accuracy: 0.7500\n",
      "Epoch 1650/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 2.7736e-05 - accuracy: 1.0000 - val_loss: 2.8054 - val_accuracy: 0.7500\n",
      "Epoch 1651/2000\n",
      "80/80 [==============================] - 0s 159us/sample - loss: 2.7585e-05 - accuracy: 1.0000 - val_loss: 2.8110 - val_accuracy: 0.7500\n",
      "Epoch 1652/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 2.7783e-05 - accuracy: 1.0000 - val_loss: 2.8137 - val_accuracy: 0.7500\n",
      "Epoch 1653/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 2.9830e-05 - accuracy: 1.0000 - val_loss: 2.8115 - val_accuracy: 0.7500\n",
      "Epoch 1654/2000\n",
      "80/80 [==============================] - 0s 51us/sample - loss: 2.9265e-05 - accuracy: 1.0000 - val_loss: 2.8107 - val_accuracy: 0.7500\n",
      "Epoch 1655/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 2.7702e-05 - accuracy: 1.0000 - val_loss: 2.8044 - val_accuracy: 0.7500\n",
      "Epoch 1656/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 2.9103e-05 - accuracy: 1.0000 - val_loss: 2.7924 - val_accuracy: 0.7500\n",
      "Epoch 1657/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 2.7169e-05 - accuracy: 1.0000 - val_loss: 2.7770 - val_accuracy: 0.8000\n",
      "Epoch 1658/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 2.8309e-05 - accuracy: 1.0000 - val_loss: 2.7883 - val_accuracy: 0.8000\n",
      "Epoch 1659/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 2.9304e-05 - accuracy: 1.0000 - val_loss: 2.7937 - val_accuracy: 0.8000\n",
      "Epoch 1660/2000\n",
      "80/80 [==============================] - 0s 182us/sample - loss: 2.7896e-05 - accuracy: 1.0000 - val_loss: 2.7944 - val_accuracy: 0.7500\n",
      "Epoch 1661/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 2.6813e-05 - accuracy: 1.0000 - val_loss: 2.8002 - val_accuracy: 0.7500\n",
      "Epoch 1662/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 2.7577e-05 - accuracy: 1.0000 - val_loss: 2.8048 - val_accuracy: 0.7500\n",
      "Epoch 1663/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 2.6704e-05 - accuracy: 1.0000 - val_loss: 2.8068 - val_accuracy: 0.7500\n",
      "Epoch 1664/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 2.6542e-05 - accuracy: 1.0000 - val_loss: 2.8015 - val_accuracy: 0.7500\n",
      "Epoch 1665/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 2.5969e-05 - accuracy: 1.0000 - val_loss: 2.7986 - val_accuracy: 0.7500\n",
      "Epoch 1666/2000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 2.8056e-05 - accuracy: 1.0000 - val_loss: 2.7938 - val_accuracy: 0.7500\n",
      "Epoch 1667/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 2.9057e-05 - accuracy: 1.0000 - val_loss: 2.7764 - val_accuracy: 0.7500\n",
      "Epoch 1668/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 2.6571e-05 - accuracy: 1.0000 - val_loss: 2.7972 - val_accuracy: 0.7500\n",
      "Epoch 1669/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 2.5934e-05 - accuracy: 1.0000 - val_loss: 2.7997 - val_accuracy: 0.7500\n",
      "Epoch 1670/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 2.6530e-05 - accuracy: 1.0000 - val_loss: 2.8010 - val_accuracy: 0.7500\n",
      "Epoch 1671/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 2.5720e-05 - accuracy: 1.0000 - val_loss: 2.7900 - val_accuracy: 0.7500\n",
      "Epoch 1672/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 2.6310e-05 - accuracy: 1.0000 - val_loss: 2.7903 - val_accuracy: 0.7500\n",
      "Epoch 1673/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 2.6183e-05 - accuracy: 1.0000 - val_loss: 2.8036 - val_accuracy: 0.7500\n",
      "Epoch 1674/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 2.6040e-05 - accuracy: 1.0000 - val_loss: 2.8017 - val_accuracy: 0.7500\n",
      "Epoch 1675/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 2.5114e-05 - accuracy: 1.0000 - val_loss: 2.7918 - val_accuracy: 0.7500\n",
      "Epoch 1676/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 2.5096e-05 - accuracy: 1.0000 - val_loss: 2.8134 - val_accuracy: 0.7500\n",
      "Epoch 1677/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 2.7438e-05 - accuracy: 1.0000 - val_loss: 2.8164 - val_accuracy: 0.7500\n",
      "Epoch 1678/2000\n",
      "80/80 [==============================] - 0s 38us/sample - loss: 2.7646e-05 - accuracy: 1.0000 - val_loss: 2.8083 - val_accuracy: 0.7500\n",
      "Epoch 1679/2000\n",
      "80/80 [==============================] - 0s 177us/sample - loss: 2.5870e-05 - accuracy: 1.0000 - val_loss: 2.8095 - val_accuracy: 0.7500\n",
      "Epoch 1680/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 2.5652e-05 - accuracy: 1.0000 - val_loss: 2.8069 - val_accuracy: 0.7500\n",
      "Epoch 1681/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 2.5214e-05 - accuracy: 1.0000 - val_loss: 2.7913 - val_accuracy: 0.7500\n",
      "Epoch 1682/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 2.5176e-05 - accuracy: 1.0000 - val_loss: 2.8018 - val_accuracy: 0.7500\n",
      "Epoch 1683/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 2.6522e-05 - accuracy: 1.0000 - val_loss: 2.7993 - val_accuracy: 0.8000\n",
      "Epoch 1684/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 2.6336e-05 - accuracy: 1.0000 - val_loss: 2.7800 - val_accuracy: 0.7500\n",
      "Epoch 1685/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 2.5170e-05 - accuracy: 1.0000 - val_loss: 2.8037 - val_accuracy: 0.7500\n",
      "Epoch 1686/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 2.4794e-05 - accuracy: 1.0000 - val_loss: 2.8013 - val_accuracy: 0.7500\n",
      "Epoch 1687/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 2.4555e-05 - accuracy: 1.0000 - val_loss: 2.8053 - val_accuracy: 0.7500\n",
      "Epoch 1688/2000\n",
      "80/80 [==============================] - 0s 325us/sample - loss: 2.5318e-05 - accuracy: 1.0000 - val_loss: 2.8066 - val_accuracy: 0.7500\n",
      "Epoch 1689/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 2.4426e-05 - accuracy: 1.0000 - val_loss: 2.7887 - val_accuracy: 0.7500\n",
      "Epoch 1690/2000\n",
      "80/80 [==============================] - 0s 184us/sample - loss: 2.4784e-05 - accuracy: 1.0000 - val_loss: 2.7872 - val_accuracy: 0.7500\n",
      "Epoch 1691/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 2.5903e-05 - accuracy: 1.0000 - val_loss: 2.7942 - val_accuracy: 0.8000\n",
      "Epoch 1692/2000\n",
      "80/80 [==============================] - 0s 172us/sample - loss: 2.7414e-05 - accuracy: 1.0000 - val_loss: 2.7794 - val_accuracy: 0.8000\n",
      "Epoch 1693/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 2.4940e-05 - accuracy: 1.0000 - val_loss: 2.7852 - val_accuracy: 0.7500\n",
      "Epoch 1694/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 2.5585e-05 - accuracy: 1.0000 - val_loss: 2.8046 - val_accuracy: 0.7500\n",
      "Epoch 1695/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 2.5708e-05 - accuracy: 1.0000 - val_loss: 2.8097 - val_accuracy: 0.7500\n",
      "Epoch 1696/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 2.5804e-05 - accuracy: 1.0000 - val_loss: 2.7960 - val_accuracy: 0.7500\n",
      "Epoch 1697/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 2.5750e-05 - accuracy: 1.0000 - val_loss: 2.8138 - val_accuracy: 0.7500\n",
      "Epoch 1698/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 2.6031e-05 - accuracy: 1.0000 - val_loss: 2.8072 - val_accuracy: 0.7500\n",
      "Epoch 1699/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 2.7743e-05 - accuracy: 1.0000 - val_loss: 2.7746 - val_accuracy: 0.7500\n",
      "Epoch 1700/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 2.3794e-05 - accuracy: 1.0000 - val_loss: 2.7812 - val_accuracy: 0.7500\n",
      "Epoch 1701/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 2.3911e-05 - accuracy: 1.0000 - val_loss: 2.7884 - val_accuracy: 0.7500\n",
      "Epoch 1702/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 2.4399e-05 - accuracy: 1.0000 - val_loss: 2.7934 - val_accuracy: 0.7500\n",
      "Epoch 1703/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 2.3699e-05 - accuracy: 1.0000 - val_loss: 2.8000 - val_accuracy: 0.7500\n",
      "Epoch 1704/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 2.3909e-05 - accuracy: 1.0000 - val_loss: 2.8043 - val_accuracy: 0.7500\n",
      "Epoch 1705/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 2.4572e-05 - accuracy: 1.0000 - val_loss: 2.7936 - val_accuracy: 0.7500\n",
      "Epoch 1706/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 2.4422e-05 - accuracy: 1.0000 - val_loss: 2.8026 - val_accuracy: 0.7500\n",
      "Epoch 1707/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 2.2838e-05 - accuracy: 1.0000 - val_loss: 2.7955 - val_accuracy: 0.7500\n",
      "Epoch 1708/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 2.4857e-05 - accuracy: 1.0000 - val_loss: 2.7892 - val_accuracy: 0.8000\n",
      "Epoch 1709/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 2.5416e-05 - accuracy: 1.0000 - val_loss: 2.7943 - val_accuracy: 0.8000\n",
      "Epoch 1710/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 2.5250e-05 - accuracy: 1.0000 - val_loss: 2.8054 - val_accuracy: 0.7500\n",
      "Epoch 1711/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 2.3755e-05 - accuracy: 1.0000 - val_loss: 2.8070 - val_accuracy: 0.7500\n",
      "Epoch 1712/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 2.3156e-05 - accuracy: 1.0000 - val_loss: 2.8171 - val_accuracy: 0.7500\n",
      "Epoch 1713/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 2.3039e-05 - accuracy: 1.0000 - val_loss: 2.8017 - val_accuracy: 0.7500\n",
      "Epoch 1714/2000\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 2.3172e-05 - accuracy: 1.0000 - val_loss: 2.8031 - val_accuracy: 0.7500\n",
      "Epoch 1715/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 2.2916e-05 - accuracy: 1.0000 - val_loss: 2.8166 - val_accuracy: 0.7500\n",
      "Epoch 1716/2000\n",
      "80/80 [==============================] - 0s 344us/sample - loss: 2.4304e-05 - accuracy: 1.0000 - val_loss: 2.8061 - val_accuracy: 0.7500\n",
      "Epoch 1717/2000\n",
      "80/80 [==============================] - 0s 23us/sample - loss: 2.3737e-05 - accuracy: 1.0000 - val_loss: 2.8024 - val_accuracy: 0.7500\n",
      "Epoch 1718/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 2.2868e-05 - accuracy: 1.0000 - val_loss: 2.8081 - val_accuracy: 0.7500\n",
      "Epoch 1719/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 2.2614e-05 - accuracy: 1.0000 - val_loss: 2.7981 - val_accuracy: 0.7500\n",
      "Epoch 1720/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 2.2942e-05 - accuracy: 1.0000 - val_loss: 2.7967 - val_accuracy: 0.7500\n",
      "Epoch 1721/2000\n",
      "80/80 [==============================] - 0s 155us/sample - loss: 2.4073e-05 - accuracy: 1.0000 - val_loss: 2.8016 - val_accuracy: 0.7500\n",
      "Epoch 1722/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 2.3724e-05 - accuracy: 1.0000 - val_loss: 2.7855 - val_accuracy: 0.7500\n",
      "Epoch 1723/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 2.3972e-05 - accuracy: 1.0000 - val_loss: 2.7893 - val_accuracy: 0.7500\n",
      "Epoch 1724/2000\n",
      "80/80 [==============================] - 0s 53us/sample - loss: 2.3353e-05 - accuracy: 1.0000 - val_loss: 2.8101 - val_accuracy: 0.7500\n",
      "Epoch 1725/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 2.4799e-05 - accuracy: 1.0000 - val_loss: 2.8203 - val_accuracy: 0.7500\n",
      "Epoch 1726/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 2.2421e-05 - accuracy: 1.0000 - val_loss: 2.8199 - val_accuracy: 0.7500\n",
      "Epoch 1727/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 2.2444e-05 - accuracy: 1.0000 - val_loss: 2.8038 - val_accuracy: 0.7500\n",
      "Epoch 1728/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 2.1765e-05 - accuracy: 1.0000 - val_loss: 2.8124 - val_accuracy: 0.7500\n",
      "Epoch 1729/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 2.2227e-05 - accuracy: 1.0000 - val_loss: 2.8106 - val_accuracy: 0.7500\n",
      "Epoch 1730/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 2.3113e-05 - accuracy: 1.0000 - val_loss: 2.7919 - val_accuracy: 0.7500\n",
      "Epoch 1731/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 2.4086e-05 - accuracy: 1.0000 - val_loss: 2.8074 - val_accuracy: 0.7500\n",
      "Epoch 1732/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 2.2505e-05 - accuracy: 1.0000 - val_loss: 2.7869 - val_accuracy: 0.7500\n",
      "Epoch 1733/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 2.1889e-05 - accuracy: 1.0000 - val_loss: 2.8146 - val_accuracy: 0.7500\n",
      "Epoch 1734/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 2.2096e-05 - accuracy: 1.0000 - val_loss: 2.8227 - val_accuracy: 0.7500\n",
      "Epoch 1735/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 2.2506e-05 - accuracy: 1.0000 - val_loss: 2.8188 - val_accuracy: 0.7500\n",
      "Epoch 1736/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 2.2920e-05 - accuracy: 1.0000 - val_loss: 2.8223 - val_accuracy: 0.7500\n",
      "Epoch 1737/2000\n",
      "80/80 [==============================] - 0s 74us/sample - loss: 2.2445e-05 - accuracy: 1.0000 - val_loss: 2.8144 - val_accuracy: 0.7500\n",
      "Epoch 1738/2000\n",
      "80/80 [==============================] - 0s 650us/sample - loss: 2.1554e-05 - accuracy: 1.0000 - val_loss: 2.7950 - val_accuracy: 0.7500\n",
      "Epoch 1739/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 2.3122e-05 - accuracy: 1.0000 - val_loss: 2.8013 - val_accuracy: 0.7500\n",
      "Epoch 1740/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 2.3694e-05 - accuracy: 1.0000 - val_loss: 2.7873 - val_accuracy: 0.7500\n",
      "Epoch 1741/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 2.3434e-05 - accuracy: 1.0000 - val_loss: 2.7899 - val_accuracy: 0.7500\n",
      "Epoch 1742/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 2.2220e-05 - accuracy: 1.0000 - val_loss: 2.8054 - val_accuracy: 0.7500\n",
      "Epoch 1743/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 2.1351e-05 - accuracy: 1.0000 - val_loss: 2.8094 - val_accuracy: 0.7500\n",
      "Epoch 1744/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 2.2266e-05 - accuracy: 1.0000 - val_loss: 2.8177 - val_accuracy: 0.7500\n",
      "Epoch 1745/2000\n",
      "80/80 [==============================] - 0s 180us/sample - loss: 2.1419e-05 - accuracy: 1.0000 - val_loss: 2.7919 - val_accuracy: 0.7500\n",
      "Epoch 1746/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 2.1872e-05 - accuracy: 1.0000 - val_loss: 2.7909 - val_accuracy: 0.7500\n",
      "Epoch 1747/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 2.1789e-05 - accuracy: 1.0000 - val_loss: 2.8168 - val_accuracy: 0.7500\n",
      "Epoch 1748/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 2.1518e-05 - accuracy: 1.0000 - val_loss: 2.8106 - val_accuracy: 0.7500\n",
      "Epoch 1749/2000\n",
      "80/80 [==============================] - 0s 77us/sample - loss: 2.1008e-05 - accuracy: 1.0000 - val_loss: 2.7794 - val_accuracy: 0.7500\n",
      "Epoch 1750/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 2.1139e-05 - accuracy: 1.0000 - val_loss: 2.7965 - val_accuracy: 0.7500\n",
      "Epoch 1751/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 2.1517e-05 - accuracy: 1.0000 - val_loss: 2.7962 - val_accuracy: 0.7500\n",
      "Epoch 1752/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 2.1585e-05 - accuracy: 1.0000 - val_loss: 2.8053 - val_accuracy: 0.7500\n",
      "Epoch 1753/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 2.1563e-05 - accuracy: 1.0000 - val_loss: 2.8075 - val_accuracy: 0.7500\n",
      "Epoch 1754/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 2.0966e-05 - accuracy: 1.0000 - val_loss: 2.8081 - val_accuracy: 0.7500\n",
      "Epoch 1755/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 2.0885e-05 - accuracy: 1.0000 - val_loss: 2.8186 - val_accuracy: 0.7500\n",
      "Epoch 1756/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 2.0652e-05 - accuracy: 1.0000 - val_loss: 2.7966 - val_accuracy: 0.7500\n",
      "Epoch 1757/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 2.1173e-05 - accuracy: 1.0000 - val_loss: 2.8190 - val_accuracy: 0.7500\n",
      "Epoch 1758/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 2.3209e-05 - accuracy: 1.0000 - val_loss: 2.8271 - val_accuracy: 0.7500\n",
      "Epoch 1759/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 2.2934e-05 - accuracy: 1.0000 - val_loss: 2.8117 - val_accuracy: 0.7500\n",
      "Epoch 1760/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 2.2006e-05 - accuracy: 1.0000 - val_loss: 2.8169 - val_accuracy: 0.7500\n",
      "Epoch 1761/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 2.1375e-05 - accuracy: 1.0000 - val_loss: 2.8007 - val_accuracy: 0.7500\n",
      "Epoch 1762/2000\n",
      "80/80 [==============================] - 0s 67us/sample - loss: 2.0815e-05 - accuracy: 1.0000 - val_loss: 2.8109 - val_accuracy: 0.7500\n",
      "Epoch 1763/2000\n",
      "80/80 [==============================] - 0s 155us/sample - loss: 2.1650e-05 - accuracy: 1.0000 - val_loss: 2.7949 - val_accuracy: 0.7500\n",
      "Epoch 1764/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 2.2092e-05 - accuracy: 1.0000 - val_loss: 2.8055 - val_accuracy: 0.7500\n",
      "Epoch 1765/2000\n",
      "80/80 [==============================] - 0s 195us/sample - loss: 2.3143e-05 - accuracy: 1.0000 - val_loss: 2.8026 - val_accuracy: 0.7500\n",
      "Epoch 1766/2000\n",
      "80/80 [==============================] - 0s 28us/sample - loss: 2.0546e-05 - accuracy: 1.0000 - val_loss: 2.8084 - val_accuracy: 0.7500\n",
      "Epoch 1767/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 2.0165e-05 - accuracy: 1.0000 - val_loss: 2.7978 - val_accuracy: 0.7500\n",
      "Epoch 1768/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 2.0463e-05 - accuracy: 1.0000 - val_loss: 2.8105 - val_accuracy: 0.7500\n",
      "Epoch 1769/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 2.0093e-05 - accuracy: 1.0000 - val_loss: 2.8132 - val_accuracy: 0.7500\n",
      "Epoch 1770/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 2.0067e-05 - accuracy: 1.0000 - val_loss: 2.8081 - val_accuracy: 0.7500\n",
      "Epoch 1771/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 2.0486e-05 - accuracy: 1.0000 - val_loss: 2.8081 - val_accuracy: 0.7500\n",
      "Epoch 1772/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 2.0358e-05 - accuracy: 1.0000 - val_loss: 2.8064 - val_accuracy: 0.7500\n",
      "Epoch 1773/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 1.9925e-05 - accuracy: 1.0000 - val_loss: 2.8079 - val_accuracy: 0.7500\n",
      "Epoch 1774/2000\n",
      "80/80 [==============================] - 0s 161us/sample - loss: 2.0072e-05 - accuracy: 1.0000 - val_loss: 2.8112 - val_accuracy: 0.7500\n",
      "Epoch 1775/2000\n",
      "80/80 [==============================] - 0s 74us/sample - loss: 2.1053e-05 - accuracy: 1.0000 - val_loss: 2.8102 - val_accuracy: 0.7500\n",
      "Epoch 1776/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 2.0944e-05 - accuracy: 1.0000 - val_loss: 2.7952 - val_accuracy: 0.7500\n",
      "Epoch 1777/2000\n",
      "80/80 [==============================] - 0s 70us/sample - loss: 2.0106e-05 - accuracy: 1.0000 - val_loss: 2.8039 - val_accuracy: 0.7500\n",
      "Epoch 1778/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 2.0817e-05 - accuracy: 1.0000 - val_loss: 2.8158 - val_accuracy: 0.7500\n",
      "Epoch 1779/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 2.1425e-05 - accuracy: 1.0000 - val_loss: 2.8190 - val_accuracy: 0.7500\n",
      "Epoch 1780/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 1.9900e-05 - accuracy: 1.0000 - val_loss: 2.8176 - val_accuracy: 0.7500\n",
      "Epoch 1781/2000\n",
      "80/80 [==============================] - 0s 214us/sample - loss: 1.9581e-05 - accuracy: 1.0000 - val_loss: 2.8032 - val_accuracy: 0.7500\n",
      "Epoch 1782/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 1.9546e-05 - accuracy: 1.0000 - val_loss: 2.8067 - val_accuracy: 0.7500\n",
      "Epoch 1783/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 2.0138e-05 - accuracy: 1.0000 - val_loss: 2.7988 - val_accuracy: 0.7500\n",
      "Epoch 1784/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 2.0631e-05 - accuracy: 1.0000 - val_loss: 2.7916 - val_accuracy: 0.7500\n",
      "Epoch 1785/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 2.0344e-05 - accuracy: 1.0000 - val_loss: 2.8014 - val_accuracy: 0.7500\n",
      "Epoch 1786/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 2.0533e-05 - accuracy: 1.0000 - val_loss: 2.7989 - val_accuracy: 0.7500\n",
      "Epoch 1787/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 1.9915e-05 - accuracy: 1.0000 - val_loss: 2.8032 - val_accuracy: 0.7500\n",
      "Epoch 1788/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 2.0213e-05 - accuracy: 1.0000 - val_loss: 2.8132 - val_accuracy: 0.7500\n",
      "Epoch 1789/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 1.9176e-05 - accuracy: 1.0000 - val_loss: 2.8002 - val_accuracy: 0.7500\n",
      "Epoch 1790/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 1.9312e-05 - accuracy: 1.0000 - val_loss: 2.7996 - val_accuracy: 0.7500\n",
      "Epoch 1791/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 1.9702e-05 - accuracy: 1.0000 - val_loss: 2.8049 - val_accuracy: 0.7500\n",
      "Epoch 1792/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 1.9622e-05 - accuracy: 1.0000 - val_loss: 2.7989 - val_accuracy: 0.7500\n",
      "Epoch 1793/2000\n",
      "80/80 [==============================] - 0s 599us/sample - loss: 1.9495e-05 - accuracy: 1.0000 - val_loss: 2.7960 - val_accuracy: 0.7500\n",
      "Epoch 1794/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 1.9378e-05 - accuracy: 1.0000 - val_loss: 2.7968 - val_accuracy: 0.7500\n",
      "Epoch 1795/2000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 1.9777e-05 - accuracy: 1.0000 - val_loss: 2.7871 - val_accuracy: 0.7500\n",
      "Epoch 1796/2000\n",
      "80/80 [==============================] - 0s 163us/sample - loss: 1.9426e-05 - accuracy: 1.0000 - val_loss: 2.7981 - val_accuracy: 0.7500\n",
      "Epoch 1797/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 2.0245e-05 - accuracy: 1.0000 - val_loss: 2.7988 - val_accuracy: 0.7500\n",
      "Epoch 1798/2000\n",
      "80/80 [==============================] - 0s 152us/sample - loss: 1.9989e-05 - accuracy: 1.0000 - val_loss: 2.8035 - val_accuracy: 0.7500\n",
      "Epoch 1799/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 1.9301e-05 - accuracy: 1.0000 - val_loss: 2.8066 - val_accuracy: 0.7500\n",
      "Epoch 1800/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 1.8671e-05 - accuracy: 1.0000 - val_loss: 2.8056 - val_accuracy: 0.7500\n",
      "Epoch 1801/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 1.9315e-05 - accuracy: 1.0000 - val_loss: 2.8071 - val_accuracy: 0.7500\n",
      "Epoch 1802/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 1.9580e-05 - accuracy: 1.0000 - val_loss: 2.8110 - val_accuracy: 0.7500\n",
      "Epoch 1803/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 1.8860e-05 - accuracy: 1.0000 - val_loss: 2.8123 - val_accuracy: 0.7500\n",
      "Epoch 1804/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 1.9061e-05 - accuracy: 1.0000 - val_loss: 2.8171 - val_accuracy: 0.7500\n",
      "Epoch 1805/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 1.9390e-05 - accuracy: 1.0000 - val_loss: 2.8071 - val_accuracy: 0.7500\n",
      "Epoch 1806/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 1.8519e-05 - accuracy: 1.0000 - val_loss: 2.8043 - val_accuracy: 0.7500\n",
      "Epoch 1807/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 1.8783e-05 - accuracy: 1.0000 - val_loss: 2.7981 - val_accuracy: 0.7500\n",
      "Epoch 1808/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 1.8004e-05 - accuracy: 1.0000 - val_loss: 2.8065 - val_accuracy: 0.7500\n",
      "Epoch 1809/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 1.9735e-05 - accuracy: 1.0000 - val_loss: 2.7904 - val_accuracy: 0.7500\n",
      "Epoch 1810/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 1.9404e-05 - accuracy: 1.0000 - val_loss: 2.7916 - val_accuracy: 0.7500\n",
      "Epoch 1811/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 2.0027e-05 - accuracy: 1.0000 - val_loss: 2.7957 - val_accuracy: 0.7500\n",
      "Epoch 1812/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 1.9305e-05 - accuracy: 1.0000 - val_loss: 2.7899 - val_accuracy: 0.7500\n",
      "Epoch 1813/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 1.7582e-05 - accuracy: 1.0000 - val_loss: 2.8218 - val_accuracy: 0.7500\n",
      "Epoch 1814/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 1.9998e-05 - accuracy: 1.0000 - val_loss: 2.8327 - val_accuracy: 0.7500\n",
      "Epoch 1815/2000\n",
      "80/80 [==============================] - 0s 560us/sample - loss: 2.0060e-05 - accuracy: 1.0000 - val_loss: 2.8089 - val_accuracy: 0.7500\n",
      "Epoch 1816/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 2.1078e-05 - accuracy: 1.0000 - val_loss: 2.8333 - val_accuracy: 0.7500\n",
      "Epoch 1817/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 2.0007e-05 - accuracy: 1.0000 - val_loss: 2.8241 - val_accuracy: 0.7500\n",
      "Epoch 1818/2000\n",
      "80/80 [==============================] - 0s 212us/sample - loss: 1.8838e-05 - accuracy: 1.0000 - val_loss: 2.8118 - val_accuracy: 0.7500\n",
      "Epoch 1819/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 1.8083e-05 - accuracy: 1.0000 - val_loss: 2.8085 - val_accuracy: 0.7500\n",
      "Epoch 1820/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 1.9024e-05 - accuracy: 1.0000 - val_loss: 2.8050 - val_accuracy: 0.7500\n",
      "Epoch 1821/2000\n",
      "80/80 [==============================] - 0s 73us/sample - loss: 1.9292e-05 - accuracy: 1.0000 - val_loss: 2.7994 - val_accuracy: 0.7500\n",
      "Epoch 1822/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 1.9182e-05 - accuracy: 1.0000 - val_loss: 2.7924 - val_accuracy: 0.7500\n",
      "Epoch 1823/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 1.8963e-05 - accuracy: 1.0000 - val_loss: 2.7896 - val_accuracy: 0.7500\n",
      "Epoch 1824/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 1.8433e-05 - accuracy: 1.0000 - val_loss: 2.8075 - val_accuracy: 0.7500\n",
      "Epoch 1825/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 1.7758e-05 - accuracy: 1.0000 - val_loss: 2.7968 - val_accuracy: 0.7500\n",
      "Epoch 1826/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 1.8106e-05 - accuracy: 1.0000 - val_loss: 2.8094 - val_accuracy: 0.7500\n",
      "Epoch 1827/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 1.7653e-05 - accuracy: 1.0000 - val_loss: 2.7980 - val_accuracy: 0.7500\n",
      "Epoch 1828/2000\n",
      "80/80 [==============================] - 0s 77us/sample - loss: 1.8319e-05 - accuracy: 1.0000 - val_loss: 2.7940 - val_accuracy: 0.7500\n",
      "Epoch 1829/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 1.8559e-05 - accuracy: 1.0000 - val_loss: 2.8012 - val_accuracy: 0.7500\n",
      "Epoch 1830/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 1.8276e-05 - accuracy: 1.0000 - val_loss: 2.8164 - val_accuracy: 0.7500\n",
      "Epoch 1831/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 1.8982e-05 - accuracy: 1.0000 - val_loss: 2.8188 - val_accuracy: 0.7500\n",
      "Epoch 1832/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 1.8422e-05 - accuracy: 1.0000 - val_loss: 2.8154 - val_accuracy: 0.7500\n",
      "Epoch 1833/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 1.7528e-05 - accuracy: 1.0000 - val_loss: 2.8178 - val_accuracy: 0.7500\n",
      "Epoch 1834/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 1.7784e-05 - accuracy: 1.0000 - val_loss: 2.8095 - val_accuracy: 0.7500\n",
      "Epoch 1835/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 1.7295e-05 - accuracy: 1.0000 - val_loss: 2.8037 - val_accuracy: 0.7500\n",
      "Epoch 1836/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 1.8447e-05 - accuracy: 1.0000 - val_loss: 2.8103 - val_accuracy: 0.7500\n",
      "Epoch 1837/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 1.7201e-05 - accuracy: 1.0000 - val_loss: 2.8239 - val_accuracy: 0.7500\n",
      "Epoch 1838/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 1.7793e-05 - accuracy: 1.0000 - val_loss: 2.8103 - val_accuracy: 0.7500\n",
      "Epoch 1839/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 1.8309e-05 - accuracy: 1.0000 - val_loss: 2.8164 - val_accuracy: 0.7500\n",
      "Epoch 1840/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 1.7078e-05 - accuracy: 1.0000 - val_loss: 2.8153 - val_accuracy: 0.7500\n",
      "Epoch 1841/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 1.6986e-05 - accuracy: 1.0000 - val_loss: 2.8311 - val_accuracy: 0.7500\n",
      "Epoch 1842/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 1.7163e-05 - accuracy: 1.0000 - val_loss: 2.8334 - val_accuracy: 0.7500\n",
      "Epoch 1843/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 1.7356e-05 - accuracy: 1.0000 - val_loss: 2.8175 - val_accuracy: 0.7500\n",
      "Epoch 1844/2000\n",
      "80/80 [==============================] - 0s 49us/sample - loss: 1.7430e-05 - accuracy: 1.0000 - val_loss: 2.8230 - val_accuracy: 0.7500\n",
      "Epoch 1845/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 1.8457e-05 - accuracy: 1.0000 - val_loss: 2.8354 - val_accuracy: 0.7500\n",
      "Epoch 1846/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 1.7814e-05 - accuracy: 1.0000 - val_loss: 2.8309 - val_accuracy: 0.7500\n",
      "Epoch 1847/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 1.7242e-05 - accuracy: 1.0000 - val_loss: 2.8172 - val_accuracy: 0.7500\n",
      "Epoch 1848/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 1.7137e-05 - accuracy: 1.0000 - val_loss: 2.8155 - val_accuracy: 0.7500\n",
      "Epoch 1849/2000\n",
      "80/80 [==============================] - 0s 327us/sample - loss: 1.6682e-05 - accuracy: 1.0000 - val_loss: 2.8275 - val_accuracy: 0.7500\n",
      "Epoch 1850/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 1.7036e-05 - accuracy: 1.0000 - val_loss: 2.8251 - val_accuracy: 0.7500\n",
      "Epoch 1851/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 1.7312e-05 - accuracy: 1.0000 - val_loss: 2.8057 - val_accuracy: 0.7500\n",
      "Epoch 1852/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 1.7049e-05 - accuracy: 1.0000 - val_loss: 2.8147 - val_accuracy: 0.7500\n",
      "Epoch 1853/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 1.6979e-05 - accuracy: 1.0000 - val_loss: 2.8129 - val_accuracy: 0.7500\n",
      "Epoch 1854/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 1.7148e-05 - accuracy: 1.0000 - val_loss: 2.8212 - val_accuracy: 0.7500\n",
      "Epoch 1855/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 1.7737e-05 - accuracy: 1.0000 - val_loss: 2.8091 - val_accuracy: 0.7500\n",
      "Epoch 1856/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 1.7686e-05 - accuracy: 1.0000 - val_loss: 2.8039 - val_accuracy: 0.7500\n",
      "Epoch 1857/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 1.7416e-05 - accuracy: 1.0000 - val_loss: 2.8091 - val_accuracy: 0.7500\n",
      "Epoch 1858/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 1.7334e-05 - accuracy: 1.0000 - val_loss: 2.8119 - val_accuracy: 0.7500\n",
      "Epoch 1859/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 1.7383e-05 - accuracy: 1.0000 - val_loss: 2.8176 - val_accuracy: 0.7500\n",
      "Epoch 1860/2000\n",
      "80/80 [==============================] - 0s 70us/sample - loss: 1.6318e-05 - accuracy: 1.0000 - val_loss: 2.8283 - val_accuracy: 0.7500\n",
      "Epoch 1861/2000\n",
      "80/80 [==============================] - 0s 68us/sample - loss: 1.6336e-05 - accuracy: 1.0000 - val_loss: 2.8345 - val_accuracy: 0.7500\n",
      "Epoch 1862/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 1.6745e-05 - accuracy: 1.0000 - val_loss: 2.8260 - val_accuracy: 0.7500\n",
      "Epoch 1863/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 1.8661e-05 - accuracy: 1.0000 - val_loss: 2.8262 - val_accuracy: 0.7500\n",
      "Epoch 1864/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 1.7601e-05 - accuracy: 1.0000 - val_loss: 2.8200 - val_accuracy: 0.7500\n",
      "Epoch 1865/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 1.6303e-05 - accuracy: 1.0000 - val_loss: 2.8147 - val_accuracy: 0.7500\n",
      "Epoch 1866/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 1.6112e-05 - accuracy: 1.0000 - val_loss: 2.8233 - val_accuracy: 0.7500\n",
      "Epoch 1867/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 1.6588e-05 - accuracy: 1.0000 - val_loss: 2.8057 - val_accuracy: 0.7500\n",
      "Epoch 1868/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 1.6064e-05 - accuracy: 1.0000 - val_loss: 2.8013 - val_accuracy: 0.7500\n",
      "Epoch 1869/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 1.6053e-05 - accuracy: 1.0000 - val_loss: 2.8076 - val_accuracy: 0.7500\n",
      "Epoch 1870/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 1.6358e-05 - accuracy: 1.0000 - val_loss: 2.8092 - val_accuracy: 0.7500\n",
      "Epoch 1871/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 1.6158e-05 - accuracy: 1.0000 - val_loss: 2.8097 - val_accuracy: 0.7500\n",
      "Epoch 1872/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 1.6054e-05 - accuracy: 1.0000 - val_loss: 2.8033 - val_accuracy: 0.7500\n",
      "Epoch 1873/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 1.6568e-05 - accuracy: 1.0000 - val_loss: 2.8009 - val_accuracy: 0.7500\n",
      "Epoch 1874/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 1.6531e-05 - accuracy: 1.0000 - val_loss: 2.7999 - val_accuracy: 0.7500\n",
      "Epoch 1875/2000\n",
      "80/80 [==============================] - 0s 457us/sample - loss: 1.6696e-05 - accuracy: 1.0000 - val_loss: 2.7991 - val_accuracy: 0.7500\n",
      "Epoch 1876/2000\n",
      "80/80 [==============================] - 0s 193us/sample - loss: 1.6802e-05 - accuracy: 1.0000 - val_loss: 2.7978 - val_accuracy: 0.7500\n",
      "Epoch 1877/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 1.6570e-05 - accuracy: 1.0000 - val_loss: 2.7983 - val_accuracy: 0.7500\n",
      "Epoch 1878/2000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 1.5945e-05 - accuracy: 1.0000 - val_loss: 2.7930 - val_accuracy: 0.7500\n",
      "Epoch 1879/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 1.6885e-05 - accuracy: 1.0000 - val_loss: 2.8058 - val_accuracy: 0.7500\n",
      "Epoch 1880/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 1.6439e-05 - accuracy: 1.0000 - val_loss: 2.8042 - val_accuracy: 0.7500\n",
      "Epoch 1881/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 1.6173e-05 - accuracy: 1.0000 - val_loss: 2.8137 - val_accuracy: 0.7500\n",
      "Epoch 1882/2000\n",
      "80/80 [==============================] - 0s 50us/sample - loss: 1.5537e-05 - accuracy: 1.0000 - val_loss: 2.8133 - val_accuracy: 0.7500\n",
      "Epoch 1883/2000\n",
      "80/80 [==============================] - 0s 175us/sample - loss: 1.6062e-05 - accuracy: 1.0000 - val_loss: 2.8114 - val_accuracy: 0.7500\n",
      "Epoch 1884/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 1.5494e-05 - accuracy: 1.0000 - val_loss: 2.8058 - val_accuracy: 0.7500\n",
      "Epoch 1885/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 1.5809e-05 - accuracy: 1.0000 - val_loss: 2.8053 - val_accuracy: 0.7500\n",
      "Epoch 1886/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 1.5963e-05 - accuracy: 1.0000 - val_loss: 2.8083 - val_accuracy: 0.7500\n",
      "Epoch 1887/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 1.5092e-05 - accuracy: 1.0000 - val_loss: 2.7977 - val_accuracy: 0.7500\n",
      "Epoch 1888/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 1.4509e-05 - accuracy: 1.0000 - val_loss: 2.7869 - val_accuracy: 0.7500\n",
      "Epoch 1889/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 1.6553e-05 - accuracy: 1.0000 - val_loss: 2.7867 - val_accuracy: 0.7500\n",
      "Epoch 1890/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 1.7778e-05 - accuracy: 1.0000 - val_loss: 2.7838 - val_accuracy: 0.7500\n",
      "Epoch 1891/2000\n",
      "80/80 [==============================] - 0s 60us/sample - loss: 1.7330e-05 - accuracy: 1.0000 - val_loss: 2.7916 - val_accuracy: 0.7500\n",
      "Epoch 1892/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 1.5970e-05 - accuracy: 1.0000 - val_loss: 2.8060 - val_accuracy: 0.7500\n",
      "Epoch 1893/2000\n",
      "80/80 [==============================] - 0s 68us/sample - loss: 1.5928e-05 - accuracy: 1.0000 - val_loss: 2.8071 - val_accuracy: 0.7500\n",
      "Epoch 1894/2000\n",
      "80/80 [==============================] - 0s 166us/sample - loss: 1.5446e-05 - accuracy: 1.0000 - val_loss: 2.8035 - val_accuracy: 0.7500\n",
      "Epoch 1895/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 1.5358e-05 - accuracy: 1.0000 - val_loss: 2.8063 - val_accuracy: 0.7500\n",
      "Epoch 1896/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 1.5259e-05 - accuracy: 1.0000 - val_loss: 2.8012 - val_accuracy: 0.7500\n",
      "Epoch 1897/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 1.4703e-05 - accuracy: 1.0000 - val_loss: 2.8012 - val_accuracy: 0.7500\n",
      "Epoch 1898/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 1.6094e-05 - accuracy: 1.0000 - val_loss: 2.7889 - val_accuracy: 0.7500\n",
      "Epoch 1899/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 1.5844e-05 - accuracy: 1.0000 - val_loss: 2.7925 - val_accuracy: 0.7500\n",
      "Epoch 1900/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 1.5984e-05 - accuracy: 1.0000 - val_loss: 2.7931 - val_accuracy: 0.7500\n",
      "Epoch 1901/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 1.5841e-05 - accuracy: 1.0000 - val_loss: 2.7871 - val_accuracy: 0.7500\n",
      "Epoch 1902/2000\n",
      "80/80 [==============================] - 0s 64us/sample - loss: 1.5865e-05 - accuracy: 1.0000 - val_loss: 2.8070 - val_accuracy: 0.7500\n",
      "Epoch 1903/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 1.4749e-05 - accuracy: 1.0000 - val_loss: 2.8103 - val_accuracy: 0.7500\n",
      "Epoch 1904/2000\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 1.4439e-05 - accuracy: 1.0000 - val_loss: 2.8110 - val_accuracy: 0.7500\n",
      "Epoch 1905/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 1.5241e-05 - accuracy: 1.0000 - val_loss: 2.8201 - val_accuracy: 0.7500\n",
      "Epoch 1906/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 1.5482e-05 - accuracy: 1.0000 - val_loss: 2.8145 - val_accuracy: 0.7500\n",
      "Epoch 1907/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 1.5634e-05 - accuracy: 1.0000 - val_loss: 2.8125 - val_accuracy: 0.7500\n",
      "Epoch 1908/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 1.5144e-05 - accuracy: 1.0000 - val_loss: 2.8077 - val_accuracy: 0.7500\n",
      "Epoch 1909/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 1.4657e-05 - accuracy: 1.0000 - val_loss: 2.8005 - val_accuracy: 0.7500\n",
      "Epoch 1910/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 1.5147e-05 - accuracy: 1.0000 - val_loss: 2.7907 - val_accuracy: 0.7500\n",
      "Epoch 1911/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 1.5130e-05 - accuracy: 1.0000 - val_loss: 2.7874 - val_accuracy: 0.7500\n",
      "Epoch 1912/2000\n",
      "80/80 [==============================] - 0s 322us/sample - loss: 1.5399e-05 - accuracy: 1.0000 - val_loss: 2.7956 - val_accuracy: 0.7500\n",
      "Epoch 1913/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 1.4714e-05 - accuracy: 1.0000 - val_loss: 2.7942 - val_accuracy: 0.7500\n",
      "Epoch 1914/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 1.6109e-05 - accuracy: 1.0000 - val_loss: 2.7976 - val_accuracy: 0.7500\n",
      "Epoch 1915/2000\n",
      "80/80 [==============================] - 0s 340us/sample - loss: 1.5233e-05 - accuracy: 1.0000 - val_loss: 2.7904 - val_accuracy: 0.7500\n",
      "Epoch 1916/2000\n",
      "80/80 [==============================] - 0s 226us/sample - loss: 1.4922e-05 - accuracy: 1.0000 - val_loss: 2.7913 - val_accuracy: 0.7500\n",
      "Epoch 1917/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 1.4792e-05 - accuracy: 1.0000 - val_loss: 2.7915 - val_accuracy: 0.7500\n",
      "Epoch 1918/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 1.4902e-05 - accuracy: 1.0000 - val_loss: 2.7928 - val_accuracy: 0.7500\n",
      "Epoch 1919/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 1.4824e-05 - accuracy: 1.0000 - val_loss: 2.8040 - val_accuracy: 0.7500\n",
      "Epoch 1920/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 1.4427e-05 - accuracy: 1.0000 - val_loss: 2.8036 - val_accuracy: 0.7500\n",
      "Epoch 1921/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 1.5050e-05 - accuracy: 1.0000 - val_loss: 2.8058 - val_accuracy: 0.7500\n",
      "Epoch 1922/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 1.4256e-05 - accuracy: 1.0000 - val_loss: 2.7997 - val_accuracy: 0.7500\n",
      "Epoch 1923/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 1.4505e-05 - accuracy: 1.0000 - val_loss: 2.7966 - val_accuracy: 0.7500\n",
      "Epoch 1924/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 1.4208e-05 - accuracy: 1.0000 - val_loss: 2.7958 - val_accuracy: 0.7500\n",
      "Epoch 1925/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 1.4394e-05 - accuracy: 1.0000 - val_loss: 2.7930 - val_accuracy: 0.7500\n",
      "Epoch 1926/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 1.4037e-05 - accuracy: 1.0000 - val_loss: 2.7835 - val_accuracy: 0.7500\n",
      "Epoch 1927/2000\n",
      "80/80 [==============================] - 0s 235us/sample - loss: 1.4732e-05 - accuracy: 1.0000 - val_loss: 2.7929 - val_accuracy: 0.7500\n",
      "Epoch 1928/2000\n",
      "80/80 [==============================] - 0s 159us/sample - loss: 1.4343e-05 - accuracy: 1.0000 - val_loss: 2.7880 - val_accuracy: 0.7500\n",
      "Epoch 1929/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 1.4292e-05 - accuracy: 1.0000 - val_loss: 2.7891 - val_accuracy: 0.7500\n",
      "Epoch 1930/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 1.4310e-05 - accuracy: 1.0000 - val_loss: 2.7872 - val_accuracy: 0.7500\n",
      "Epoch 1931/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 1.4020e-05 - accuracy: 1.0000 - val_loss: 2.7950 - val_accuracy: 0.7500\n",
      "Epoch 1932/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 1.3950e-05 - accuracy: 1.0000 - val_loss: 2.8061 - val_accuracy: 0.7500\n",
      "Epoch 1933/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 1.4328e-05 - accuracy: 1.0000 - val_loss: 2.7946 - val_accuracy: 0.7500\n",
      "Epoch 1934/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 1.4925e-05 - accuracy: 1.0000 - val_loss: 2.7951 - val_accuracy: 0.7500\n",
      "Epoch 1935/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 1.3778e-05 - accuracy: 1.0000 - val_loss: 2.8062 - val_accuracy: 0.7500\n",
      "Epoch 1936/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 1.3933e-05 - accuracy: 1.0000 - val_loss: 2.7989 - val_accuracy: 0.7500\n",
      "Epoch 1937/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 1.3834e-05 - accuracy: 1.0000 - val_loss: 2.8026 - val_accuracy: 0.7500\n",
      "Epoch 1938/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 1.3994e-05 - accuracy: 1.0000 - val_loss: 2.8057 - val_accuracy: 0.7500\n",
      "Epoch 1939/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 1.4586e-05 - accuracy: 1.0000 - val_loss: 2.8066 - val_accuracy: 0.7500\n",
      "Epoch 1940/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 1.4660e-05 - accuracy: 1.0000 - val_loss: 2.8011 - val_accuracy: 0.7500\n",
      "Epoch 1941/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 1.5113e-05 - accuracy: 1.0000 - val_loss: 2.7995 - val_accuracy: 0.7500\n",
      "Epoch 1942/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 1.4186e-05 - accuracy: 1.0000 - val_loss: 2.7983 - val_accuracy: 0.7500\n",
      "Epoch 1943/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 1.3677e-05 - accuracy: 1.0000 - val_loss: 2.8001 - val_accuracy: 0.7500\n",
      "Epoch 1944/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 1.3655e-05 - accuracy: 1.0000 - val_loss: 2.8041 - val_accuracy: 0.7500\n",
      "Epoch 1945/2000\n",
      "80/80 [==============================] - 0s 248us/sample - loss: 1.4076e-05 - accuracy: 1.0000 - val_loss: 2.8033 - val_accuracy: 0.7500\n",
      "Epoch 1946/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 1.4238e-05 - accuracy: 1.0000 - val_loss: 2.8168 - val_accuracy: 0.7500\n",
      "Epoch 1947/2000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 1.3900e-05 - accuracy: 1.0000 - val_loss: 2.8163 - val_accuracy: 0.7500\n",
      "Epoch 1948/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 1.3821e-05 - accuracy: 1.0000 - val_loss: 2.8098 - val_accuracy: 0.7500\n",
      "Epoch 1949/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 1.4366e-05 - accuracy: 1.0000 - val_loss: 2.8176 - val_accuracy: 0.7500\n",
      "Epoch 1950/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 1.3807e-05 - accuracy: 1.0000 - val_loss: 2.7971 - val_accuracy: 0.7500\n",
      "Epoch 1951/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 1.3461e-05 - accuracy: 1.0000 - val_loss: 2.8151 - val_accuracy: 0.7500\n",
      "Epoch 1952/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 1.4011e-05 - accuracy: 1.0000 - val_loss: 2.8075 - val_accuracy: 0.7500\n",
      "Epoch 1953/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 1.3320e-05 - accuracy: 1.0000 - val_loss: 2.7962 - val_accuracy: 0.7500\n",
      "Epoch 1954/2000\n",
      "80/80 [==============================] - 0s 73us/sample - loss: 1.3324e-05 - accuracy: 1.0000 - val_loss: 2.7976 - val_accuracy: 0.7500\n",
      "Epoch 1955/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 1.3695e-05 - accuracy: 1.0000 - val_loss: 2.8023 - val_accuracy: 0.7500\n",
      "Epoch 1956/2000\n",
      "80/80 [==============================] - 0s 37us/sample - loss: 1.4030e-05 - accuracy: 1.0000 - val_loss: 2.8130 - val_accuracy: 0.7500\n",
      "Epoch 1957/2000\n",
      "80/80 [==============================] - 0s 199us/sample - loss: 1.3186e-05 - accuracy: 1.0000 - val_loss: 2.7991 - val_accuracy: 0.7500\n",
      "Epoch 1958/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 1.3256e-05 - accuracy: 1.0000 - val_loss: 2.7915 - val_accuracy: 0.7500\n",
      "Epoch 1959/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 1.3501e-05 - accuracy: 1.0000 - val_loss: 2.7973 - val_accuracy: 0.7500\n",
      "Epoch 1960/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 1.3164e-05 - accuracy: 1.0000 - val_loss: 2.7967 - val_accuracy: 0.7500\n",
      "Epoch 1961/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 1.3602e-05 - accuracy: 1.0000 - val_loss: 2.7920 - val_accuracy: 0.7500\n",
      "Epoch 1962/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 1.3045e-05 - accuracy: 1.0000 - val_loss: 2.7854 - val_accuracy: 0.7500\n",
      "Epoch 1963/2000\n",
      "80/80 [==============================] - 0s 172us/sample - loss: 1.2971e-05 - accuracy: 1.0000 - val_loss: 2.7758 - val_accuracy: 0.7500\n",
      "Epoch 1964/2000\n",
      "80/80 [==============================] - 0s 39us/sample - loss: 1.3230e-05 - accuracy: 1.0000 - val_loss: 2.7739 - val_accuracy: 0.7500\n",
      "Epoch 1965/2000\n",
      "80/80 [==============================] - 0s 231us/sample - loss: 1.3530e-05 - accuracy: 1.0000 - val_loss: 2.7719 - val_accuracy: 0.7500\n",
      "Epoch 1966/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 1.3585e-05 - accuracy: 1.0000 - val_loss: 2.7744 - val_accuracy: 0.7500\n",
      "Epoch 1967/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 1.3166e-05 - accuracy: 1.0000 - val_loss: 2.7785 - val_accuracy: 0.7500\n",
      "Epoch 1968/2000\n",
      "80/80 [==============================] - 0s 77us/sample - loss: 1.2852e-05 - accuracy: 1.0000 - val_loss: 2.7918 - val_accuracy: 0.7500\n",
      "Epoch 1969/2000\n",
      "80/80 [==============================] - 0s 181us/sample - loss: 1.2795e-05 - accuracy: 1.0000 - val_loss: 2.7931 - val_accuracy: 0.7500\n",
      "Epoch 1970/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 1.3864e-05 - accuracy: 1.0000 - val_loss: 2.7959 - val_accuracy: 0.7500\n",
      "Epoch 1971/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 1.2876e-05 - accuracy: 1.0000 - val_loss: 2.7921 - val_accuracy: 0.7500\n",
      "Epoch 1972/2000\n",
      "80/80 [==============================] - 0s 576us/sample - loss: 1.2710e-05 - accuracy: 1.0000 - val_loss: 2.7947 - val_accuracy: 0.7500\n",
      "Epoch 1973/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 1.3805e-05 - accuracy: 1.0000 - val_loss: 2.7965 - val_accuracy: 0.7500\n",
      "Epoch 1974/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 1.2826e-05 - accuracy: 1.0000 - val_loss: 2.7969 - val_accuracy: 0.7500\n",
      "Epoch 1975/2000\n",
      "80/80 [==============================] - 0s 160us/sample - loss: 1.2668e-05 - accuracy: 1.0000 - val_loss: 2.8009 - val_accuracy: 0.7500\n",
      "Epoch 1976/2000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 1.3692e-05 - accuracy: 1.0000 - val_loss: 2.8077 - val_accuracy: 0.7500\n",
      "Epoch 1977/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 1.3760e-05 - accuracy: 1.0000 - val_loss: 2.8048 - val_accuracy: 0.7500\n",
      "Epoch 1978/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 1.2751e-05 - accuracy: 1.0000 - val_loss: 2.8033 - val_accuracy: 0.7500\n",
      "Epoch 1979/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 1.2851e-05 - accuracy: 1.0000 - val_loss: 2.8037 - val_accuracy: 0.7500\n",
      "Epoch 1980/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 1.3058e-05 - accuracy: 1.0000 - val_loss: 2.8171 - val_accuracy: 0.7500\n",
      "Epoch 1981/2000\n",
      "80/80 [==============================] - 0s 71us/sample - loss: 1.2390e-05 - accuracy: 1.0000 - val_loss: 2.7996 - val_accuracy: 0.7500\n",
      "Epoch 1982/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 1.3370e-05 - accuracy: 1.0000 - val_loss: 2.7922 - val_accuracy: 0.7500\n",
      "Epoch 1983/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 1.3940e-05 - accuracy: 1.0000 - val_loss: 2.7886 - val_accuracy: 0.7500\n",
      "Epoch 1984/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 1.3279e-05 - accuracy: 1.0000 - val_loss: 2.8003 - val_accuracy: 0.7500\n",
      "Epoch 1985/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 1.2181e-05 - accuracy: 1.0000 - val_loss: 2.8009 - val_accuracy: 0.7500\n",
      "Epoch 1986/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 1.2596e-05 - accuracy: 1.0000 - val_loss: 2.8105 - val_accuracy: 0.7500\n",
      "Epoch 1987/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 1.3062e-05 - accuracy: 1.0000 - val_loss: 2.8112 - val_accuracy: 0.7500\n",
      "Epoch 1988/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 1.3627e-05 - accuracy: 1.0000 - val_loss: 2.8066 - val_accuracy: 0.7500\n",
      "Epoch 1989/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 1.3415e-05 - accuracy: 1.0000 - val_loss: 2.8020 - val_accuracy: 0.7500\n",
      "Epoch 1990/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 1.2849e-05 - accuracy: 1.0000 - val_loss: 2.7916 - val_accuracy: 0.7500\n",
      "Epoch 1991/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 1.3145e-05 - accuracy: 1.0000 - val_loss: 2.7860 - val_accuracy: 0.7500\n",
      "Epoch 1992/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 1.2103e-05 - accuracy: 1.0000 - val_loss: 2.7759 - val_accuracy: 0.7500\n",
      "Epoch 1993/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 1.2460e-05 - accuracy: 1.0000 - val_loss: 2.7801 - val_accuracy: 0.7500\n",
      "Epoch 1994/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 1.2816e-05 - accuracy: 1.0000 - val_loss: 2.7769 - val_accuracy: 0.7500\n",
      "Epoch 1995/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 1.2660e-05 - accuracy: 1.0000 - val_loss: 2.7881 - val_accuracy: 0.7500\n",
      "Epoch 1996/2000\n",
      "80/80 [==============================] - 0s 35us/sample - loss: 1.2459e-05 - accuracy: 1.0000 - val_loss: 2.7928 - val_accuracy: 0.7500\n",
      "Epoch 1997/2000\n",
      "80/80 [==============================] - 0s 210us/sample - loss: 1.2655e-05 - accuracy: 1.0000 - val_loss: 2.7914 - val_accuracy: 0.7500\n",
      "Epoch 1998/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 1.2048e-05 - accuracy: 1.0000 - val_loss: 2.8066 - val_accuracy: 0.7500\n",
      "Epoch 1999/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 1.2055e-05 - accuracy: 1.0000 - val_loss: 2.8014 - val_accuracy: 0.7500\n",
      "Epoch 2000/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 1.2357e-05 - accuracy: 1.0000 - val_loss: 2.8047 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "adam=Adam(learning_rate=0.01)\n",
    "model1.compile(loss='binary_crossentropy', optimizer=adam,metrics=['accuracy'])\n",
    "history1 = model1.fit(X, y, epochs=2000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x232fde589c8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 128)               384       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 17,025\n",
      "Trainable params: 17,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential()\n",
    "\n",
    "model2.add(Dense(128, input_dim=2,activation='relu',kernel_regularizer=tensorflow.keras.regularizers.l2(0.03)))\n",
    "model2.add(Dense(128,activation='relu',kernel_regularizer=tensorflow.keras.regularizers.l2(0.03)))\n",
    "model2.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/2000\n",
      "80/80 [==============================] - 0s 4ms/sample - loss: 3.1504 - accuracy: 0.7500 - val_loss: 1.2637 - val_accuracy: 0.6000\n",
      "Epoch 2/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 1.5443 - accuracy: 0.8125 - val_loss: 2.4843 - val_accuracy: 0.7500\n",
      "Epoch 3/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 1.9753 - accuracy: 0.8750 - val_loss: 1.9780 - val_accuracy: 0.6500\n",
      "Epoch 4/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 1.3168 - accuracy: 0.8875 - val_loss: 1.2958 - val_accuracy: 0.7500\n",
      "Epoch 5/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 1.0832 - accuracy: 0.9000 - val_loss: 1.2987 - val_accuracy: 0.7500\n",
      "Epoch 6/2000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.9718 - accuracy: 0.9000 - val_loss: 1.1739 - val_accuracy: 0.7000\n",
      "Epoch 7/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.7554 - accuracy: 0.9000 - val_loss: 1.0329 - val_accuracy: 0.7500\n",
      "Epoch 8/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.6438 - accuracy: 0.8875 - val_loss: 1.0353 - val_accuracy: 0.7000\n",
      "Epoch 9/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.5617 - accuracy: 0.8875 - val_loss: 0.8895 - val_accuracy: 0.7000\n",
      "Epoch 10/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.4740 - accuracy: 0.9000 - val_loss: 0.8645 - val_accuracy: 0.7000\n",
      "Epoch 11/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.4217 - accuracy: 0.9000 - val_loss: 0.9536 - val_accuracy: 0.5500\n",
      "Epoch 12/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.4441 - accuracy: 0.8875 - val_loss: 0.8938 - val_accuracy: 0.7500\n",
      "Epoch 13/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.4183 - accuracy: 0.8625 - val_loss: 1.1965 - val_accuracy: 0.5000\n",
      "Epoch 14/2000\n",
      "80/80 [==============================] - 0s 571us/sample - loss: 0.4285 - accuracy: 0.9000 - val_loss: 0.9481 - val_accuracy: 0.7500\n",
      "Epoch 15/2000\n",
      "80/80 [==============================] - 0s 221us/sample - loss: 0.6573 - accuracy: 0.7625 - val_loss: 0.8621 - val_accuracy: 0.7500\n",
      "Epoch 16/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.5132 - accuracy: 0.8000 - val_loss: 1.2919 - val_accuracy: 0.4500\n",
      "Epoch 17/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.5269 - accuracy: 0.8625 - val_loss: 0.8909 - val_accuracy: 0.7500\n",
      "Epoch 18/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.4484 - accuracy: 0.8625 - val_loss: 0.9120 - val_accuracy: 0.7500\n",
      "Epoch 19/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.4584 - accuracy: 0.8500 - val_loss: 0.8813 - val_accuracy: 0.7500\n",
      "Epoch 20/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.3957 - accuracy: 0.9000 - val_loss: 0.9934 - val_accuracy: 0.5000\n",
      "Epoch 21/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.3938 - accuracy: 0.9000 - val_loss: 0.7773 - val_accuracy: 0.7000\n",
      "Epoch 22/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.3435 - accuracy: 0.9000 - val_loss: 0.7202 - val_accuracy: 0.7500\n",
      "Epoch 23/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.3605 - accuracy: 0.9000 - val_loss: 0.7392 - val_accuracy: 0.7000\n",
      "Epoch 24/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.3401 - accuracy: 0.8875 - val_loss: 0.7863 - val_accuracy: 0.6500\n",
      "Epoch 25/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.3311 - accuracy: 0.8875 - val_loss: 0.7752 - val_accuracy: 0.7000\n",
      "Epoch 26/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.3276 - accuracy: 0.9000 - val_loss: 0.7783 - val_accuracy: 0.7000\n",
      "Epoch 27/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.3261 - accuracy: 0.8875 - val_loss: 0.7867 - val_accuracy: 0.7000\n",
      "Epoch 28/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.3123 - accuracy: 0.9000 - val_loss: 0.7454 - val_accuracy: 0.7500\n",
      "Epoch 29/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.3110 - accuracy: 0.8875 - val_loss: 0.7625 - val_accuracy: 0.6500\n",
      "Epoch 30/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.3269 - accuracy: 0.9125 - val_loss: 0.7650 - val_accuracy: 0.7500\n",
      "Epoch 31/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.3197 - accuracy: 0.8875 - val_loss: 0.7824 - val_accuracy: 0.7500\n",
      "Epoch 32/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.3140 - accuracy: 0.8875 - val_loss: 0.8843 - val_accuracy: 0.6000\n",
      "Epoch 33/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.3182 - accuracy: 0.9250 - val_loss: 0.9027 - val_accuracy: 0.6500\n",
      "Epoch 34/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.3154 - accuracy: 0.8875 - val_loss: 0.8209 - val_accuracy: 0.7500\n",
      "Epoch 35/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.3109 - accuracy: 0.8875 - val_loss: 0.7861 - val_accuracy: 0.6500\n",
      "Epoch 36/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.3069 - accuracy: 0.9000 - val_loss: 0.7711 - val_accuracy: 0.6500\n",
      "Epoch 37/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.3006 - accuracy: 0.9125 - val_loss: 0.7412 - val_accuracy: 0.7500\n",
      "Epoch 38/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.3043 - accuracy: 0.8875 - val_loss: 0.7840 - val_accuracy: 0.7500\n",
      "Epoch 39/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2863 - accuracy: 0.9000 - val_loss: 0.8946 - val_accuracy: 0.6000\n",
      "Epoch 40/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.3220 - accuracy: 0.9250 - val_loss: 0.8305 - val_accuracy: 0.7000\n",
      "Epoch 41/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2916 - accuracy: 0.9000 - val_loss: 0.7851 - val_accuracy: 0.7500\n",
      "Epoch 42/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.3387 - accuracy: 0.8500 - val_loss: 0.7793 - val_accuracy: 0.7000\n",
      "Epoch 43/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.2949 - accuracy: 0.9000 - val_loss: 0.7581 - val_accuracy: 0.7000\n",
      "Epoch 44/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.3015 - accuracy: 0.8875 - val_loss: 0.7398 - val_accuracy: 0.7500\n",
      "Epoch 45/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.2991 - accuracy: 0.8875 - val_loss: 0.7327 - val_accuracy: 0.7500\n",
      "Epoch 46/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.3081 - accuracy: 0.8875 - val_loss: 0.8132 - val_accuracy: 0.6500\n",
      "Epoch 47/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.3031 - accuracy: 0.9250 - val_loss: 0.8107 - val_accuracy: 0.7000\n",
      "Epoch 48/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.93 - 0s 106us/sample - loss: 0.3100 - accuracy: 0.9000 - val_loss: 0.7977 - val_accuracy: 0.7500\n",
      "Epoch 49/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.2891 - accuracy: 0.9000 - val_loss: 0.8610 - val_accuracy: 0.6000\n",
      "Epoch 50/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.3249 - accuracy: 0.9250 - val_loss: 0.7859 - val_accuracy: 0.6500\n",
      "Epoch 51/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2979 - accuracy: 0.9125 - val_loss: 0.7602 - val_accuracy: 0.7500\n",
      "Epoch 52/2000\n",
      "80/80 [==============================] - 0s 582us/sample - loss: 0.2890 - accuracy: 0.9125 - val_loss: 0.7836 - val_accuracy: 0.7000\n",
      "Epoch 53/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2873 - accuracy: 0.9125 - val_loss: 0.8000 - val_accuracy: 0.7000\n",
      "Epoch 54/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2941 - accuracy: 0.8875 - val_loss: 0.8093 - val_accuracy: 0.7500\n",
      "Epoch 55/2000\n",
      "80/80 [==============================] - 0s 163us/sample - loss: 0.3006 - accuracy: 0.8875 - val_loss: 0.8375 - val_accuracy: 0.7000\n",
      "Epoch 56/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2840 - accuracy: 0.8875 - val_loss: 0.7896 - val_accuracy: 0.7500\n",
      "Epoch 57/2000\n",
      "80/80 [==============================] - 0s 156us/sample - loss: 0.2934 - accuracy: 0.9000 - val_loss: 0.7601 - val_accuracy: 0.7500\n",
      "Epoch 58/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.2868 - accuracy: 0.9000 - val_loss: 0.8143 - val_accuracy: 0.6000\n",
      "Epoch 59/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2959 - accuracy: 0.9250 - val_loss: 0.8094 - val_accuracy: 0.6500\n",
      "Epoch 60/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2869 - accuracy: 0.8875 - val_loss: 0.7705 - val_accuracy: 0.7500\n",
      "Epoch 61/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2877 - accuracy: 0.8875 - val_loss: 0.7969 - val_accuracy: 0.7500\n",
      "Epoch 62/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2794 - accuracy: 0.9000 - val_loss: 0.8403 - val_accuracy: 0.6500\n",
      "Epoch 63/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2875 - accuracy: 0.9000 - val_loss: 0.8307 - val_accuracy: 0.7000\n",
      "Epoch 64/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2842 - accuracy: 0.9000 - val_loss: 0.7869 - val_accuracy: 0.7500\n",
      "Epoch 65/2000\n",
      "80/80 [==============================] - 0s 477us/sample - loss: 0.2835 - accuracy: 0.8875 - val_loss: 0.7726 - val_accuracy: 0.7000\n",
      "Epoch 66/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2838 - accuracy: 0.9000 - val_loss: 0.7870 - val_accuracy: 0.7000\n",
      "Epoch 67/2000\n",
      "80/80 [==============================] - 0s 154us/sample - loss: 0.2862 - accuracy: 0.9000 - val_loss: 0.7794 - val_accuracy: 0.7500\n",
      "Epoch 68/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2845 - accuracy: 0.8875 - val_loss: 0.8206 - val_accuracy: 0.7000\n",
      "Epoch 69/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2856 - accuracy: 0.9000 - val_loss: 0.7929 - val_accuracy: 0.7500\n",
      "Epoch 70/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.2770 - accuracy: 0.9125 - val_loss: 0.8162 - val_accuracy: 0.7000\n",
      "Epoch 71/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.2856 - accuracy: 0.9000 - val_loss: 0.7895 - val_accuracy: 0.7500\n",
      "Epoch 72/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2959 - accuracy: 0.8750 - val_loss: 0.7875 - val_accuracy: 0.7500\n",
      "Epoch 73/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.3244 - accuracy: 0.8875 - val_loss: 0.8640 - val_accuracy: 0.6500\n",
      "Epoch 74/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2939 - accuracy: 0.9000 - val_loss: 0.8331 - val_accuracy: 0.7500\n",
      "Epoch 75/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2951 - accuracy: 0.9000 - val_loss: 0.8472 - val_accuracy: 0.7000\n",
      "Epoch 76/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2845 - accuracy: 0.9125 - val_loss: 0.8412 - val_accuracy: 0.6500\n",
      "Epoch 77/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2911 - accuracy: 0.8875 - val_loss: 0.7488 - val_accuracy: 0.7500\n",
      "Epoch 78/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.2860 - accuracy: 0.9000 - val_loss: 0.7370 - val_accuracy: 0.7000\n",
      "Epoch 79/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2867 - accuracy: 0.9000 - val_loss: 0.7290 - val_accuracy: 0.7500\n",
      "Epoch 80/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.2872 - accuracy: 0.9000 - val_loss: 0.7921 - val_accuracy: 0.7000\n",
      "Epoch 81/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2837 - accuracy: 0.8750 - val_loss: 0.7677 - val_accuracy: 0.7500\n",
      "Epoch 82/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2784 - accuracy: 0.8875 - val_loss: 0.8126 - val_accuracy: 0.7000\n",
      "Epoch 83/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.2754 - accuracy: 0.9125 - val_loss: 0.8263 - val_accuracy: 0.7000\n",
      "Epoch 84/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.2816 - accuracy: 0.9000 - val_loss: 0.8185 - val_accuracy: 0.7000\n",
      "Epoch 85/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 0.2826 - accuracy: 0.9000 - val_loss: 0.8220 - val_accuracy: 0.7000\n",
      "Epoch 86/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2722 - accuracy: 0.9125 - val_loss: 0.7962 - val_accuracy: 0.7500\n",
      "Epoch 87/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2895 - accuracy: 0.8750 - val_loss: 0.7959 - val_accuracy: 0.7500\n",
      "Epoch 88/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2749 - accuracy: 0.9000 - val_loss: 0.8301 - val_accuracy: 0.6500\n",
      "Epoch 89/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2804 - accuracy: 0.9125 - val_loss: 0.7840 - val_accuracy: 0.7000\n",
      "Epoch 90/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2784 - accuracy: 0.9125 - val_loss: 0.7588 - val_accuracy: 0.7500\n",
      "Epoch 91/2000\n",
      "80/80 [==============================] - 0s 77us/sample - loss: 0.2730 - accuracy: 0.9000 - val_loss: 0.7527 - val_accuracy: 0.7500\n",
      "Epoch 92/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2891 - accuracy: 0.8750 - val_loss: 0.7763 - val_accuracy: 0.7000\n",
      "Epoch 93/2000\n",
      "80/80 [==============================] - 0s 579us/sample - loss: 0.3064 - accuracy: 0.8875 - val_loss: 0.8506 - val_accuracy: 0.6000\n",
      "Epoch 94/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.2778 - accuracy: 0.9125 - val_loss: 0.8010 - val_accuracy: 0.7500\n",
      "Epoch 95/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.3014 - accuracy: 0.8750 - val_loss: 0.8273 - val_accuracy: 0.7500\n",
      "Epoch 96/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2740 - accuracy: 0.9125 - val_loss: 0.9033 - val_accuracy: 0.6000\n",
      "Epoch 97/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.3055 - accuracy: 0.9125 - val_loss: 0.8437 - val_accuracy: 0.7000\n",
      "Epoch 98/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 0.3011 - accuracy: 0.8875 - val_loss: 0.7711 - val_accuracy: 0.7500\n",
      "Epoch 99/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 0.2987 - accuracy: 0.8625 - val_loss: 0.7977 - val_accuracy: 0.6500\n",
      "Epoch 100/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2860 - accuracy: 0.9125 - val_loss: 0.8046 - val_accuracy: 0.6500\n",
      "Epoch 101/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2790 - accuracy: 0.9125 - val_loss: 0.7754 - val_accuracy: 0.7500\n",
      "Epoch 102/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2807 - accuracy: 0.8875 - val_loss: 0.8075 - val_accuracy: 0.7500\n",
      "Epoch 103/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2760 - accuracy: 0.9000 - val_loss: 0.8276 - val_accuracy: 0.7000\n",
      "Epoch 104/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.2755 - accuracy: 0.9125 - val_loss: 0.8516 - val_accuracy: 0.6500\n",
      "Epoch 105/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2753 - accuracy: 0.9125 - val_loss: 0.8022 - val_accuracy: 0.7500\n",
      "Epoch 106/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.2736 - accuracy: 0.8875 - val_loss: 0.7731 - val_accuracy: 0.7500\n",
      "Epoch 107/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2793 - accuracy: 0.8875 - val_loss: 0.7788 - val_accuracy: 0.7500\n",
      "Epoch 108/2000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.2769 - accuracy: 0.9000 - val_loss: 0.7721 - val_accuracy: 0.7000\n",
      "Epoch 109/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2877 - accuracy: 0.9000 - val_loss: 0.7689 - val_accuracy: 0.7500\n",
      "Epoch 110/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2726 - accuracy: 0.9000 - val_loss: 0.8188 - val_accuracy: 0.7000\n",
      "Epoch 111/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2769 - accuracy: 0.9125 - val_loss: 0.7894 - val_accuracy: 0.7500\n",
      "Epoch 112/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.2716 - accuracy: 0.9125 - val_loss: 0.7987 - val_accuracy: 0.7000\n",
      "Epoch 113/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2806 - accuracy: 0.9000 - val_loss: 0.7728 - val_accuracy: 0.7500\n",
      "Epoch 114/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.2714 - accuracy: 0.9000 - val_loss: 0.7632 - val_accuracy: 0.7500\n",
      "Epoch 115/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2690 - accuracy: 0.9000 - val_loss: 0.7826 - val_accuracy: 0.7000\n",
      "Epoch 116/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2710 - accuracy: 0.9125 - val_loss: 0.8025 - val_accuracy: 0.7000\n",
      "Epoch 117/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2705 - accuracy: 0.9125 - val_loss: 0.7821 - val_accuracy: 0.7500\n",
      "Epoch 118/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2727 - accuracy: 0.8875 - val_loss: 0.7795 - val_accuracy: 0.7500\n",
      "Epoch 119/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2730 - accuracy: 0.8875 - val_loss: 0.7541 - val_accuracy: 0.7500\n",
      "Epoch 120/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 0.2725 - accuracy: 0.9125 - val_loss: 0.7311 - val_accuracy: 0.7500\n",
      "Epoch 121/2000\n",
      "80/80 [==============================] - 0s 212us/sample - loss: 0.2731 - accuracy: 0.9000 - val_loss: 0.7210 - val_accuracy: 0.7500\n",
      "Epoch 122/2000\n",
      "80/80 [==============================] - 0s 167us/sample - loss: 0.2889 - accuracy: 0.8625 - val_loss: 0.7417 - val_accuracy: 0.7500\n",
      "Epoch 123/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2808 - accuracy: 0.9125 - val_loss: 0.8895 - val_accuracy: 0.6000\n",
      "Epoch 124/2000\n",
      "80/80 [==============================] - 0s 216us/sample - loss: 0.2847 - accuracy: 0.9250 - val_loss: 0.8314 - val_accuracy: 0.7500\n",
      "Epoch 125/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.2932 - accuracy: 0.9000 - val_loss: 0.8426 - val_accuracy: 0.7500\n",
      "Epoch 126/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2792 - accuracy: 0.8875 - val_loss: 0.8876 - val_accuracy: 0.6500\n",
      "Epoch 127/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2818 - accuracy: 0.9250 - val_loss: 0.7988 - val_accuracy: 0.7500\n",
      "Epoch 128/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2676 - accuracy: 0.9000 - val_loss: 0.7579 - val_accuracy: 0.7500\n",
      "Epoch 129/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2730 - accuracy: 0.8875 - val_loss: 0.7649 - val_accuracy: 0.7500\n",
      "Epoch 130/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2705 - accuracy: 0.9125 - val_loss: 0.8337 - val_accuracy: 0.6000\n",
      "Epoch 131/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2800 - accuracy: 0.9000 - val_loss: 0.7856 - val_accuracy: 0.7500\n",
      "Epoch 132/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.2670 - accuracy: 0.9000 - val_loss: 0.7892 - val_accuracy: 0.7500\n",
      "Epoch 133/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2803 - accuracy: 0.8875 - val_loss: 0.8134 - val_accuracy: 0.7500\n",
      "Epoch 134/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.2654 - accuracy: 0.9125 - val_loss: 0.8720 - val_accuracy: 0.6000\n",
      "Epoch 135/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2776 - accuracy: 0.9125 - val_loss: 0.8386 - val_accuracy: 0.7000\n",
      "Epoch 136/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.2683 - accuracy: 0.9000 - val_loss: 0.8148 - val_accuracy: 0.7500\n",
      "Epoch 137/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.2707 - accuracy: 0.8875 - val_loss: 0.8142 - val_accuracy: 0.7500\n",
      "Epoch 138/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.2685 - accuracy: 0.9000 - val_loss: 0.8128 - val_accuracy: 0.7000\n",
      "Epoch 139/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.2665 - accuracy: 0.9125 - val_loss: 0.7439 - val_accuracy: 0.7500\n",
      "Epoch 140/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2681 - accuracy: 0.9000 - val_loss: 0.7301 - val_accuracy: 0.7500\n",
      "Epoch 141/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2680 - accuracy: 0.9000 - val_loss: 0.7541 - val_accuracy: 0.7000\n",
      "Epoch 142/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.2711 - accuracy: 0.9000 - val_loss: 0.7742 - val_accuracy: 0.7000\n",
      "Epoch 143/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 0.2644 - accuracy: 0.9000 - val_loss: 0.7913 - val_accuracy: 0.7500\n",
      "Epoch 144/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2811 - accuracy: 0.8875 - val_loss: 0.8227 - val_accuracy: 0.7500\n",
      "Epoch 145/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.2880 - accuracy: 0.9000 - val_loss: 0.8681 - val_accuracy: 0.6500\n",
      "Epoch 146/2000\n",
      "80/80 [==============================] - 0s 156us/sample - loss: 0.2648 - accuracy: 0.9125 - val_loss: 0.8153 - val_accuracy: 0.7500\n",
      "Epoch 147/2000\n",
      "80/80 [==============================] - 0s 157us/sample - loss: 0.2828 - accuracy: 0.9000 - val_loss: 0.7872 - val_accuracy: 0.7500\n",
      "Epoch 148/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.2909 - accuracy: 0.8875 - val_loss: 0.7815 - val_accuracy: 0.7000\n",
      "Epoch 149/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2680 - accuracy: 0.8875 - val_loss: 0.7389 - val_accuracy: 0.7500\n",
      "Epoch 150/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 0.2671 - accuracy: 0.8875 - val_loss: 0.7779 - val_accuracy: 0.7000\n",
      "Epoch 151/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.3026 - accuracy: 0.9250 - val_loss: 0.8092 - val_accuracy: 0.6000\n",
      "Epoch 152/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2640 - accuracy: 0.9000 - val_loss: 0.7930 - val_accuracy: 0.7500\n",
      "Epoch 153/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.3107 - accuracy: 0.8375 - val_loss: 0.8017 - val_accuracy: 0.7500\n",
      "Epoch 154/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2951 - accuracy: 0.8625 - val_loss: 0.9262 - val_accuracy: 0.6000\n",
      "Epoch 155/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2906 - accuracy: 0.9125 - val_loss: 0.7975 - val_accuracy: 0.7500\n",
      "Epoch 156/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2664 - accuracy: 0.8875 - val_loss: 0.7797 - val_accuracy: 0.7500\n",
      "Epoch 157/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2812 - accuracy: 0.8750 - val_loss: 0.7914 - val_accuracy: 0.7500\n",
      "Epoch 158/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2650 - accuracy: 0.9000 - val_loss: 0.8541 - val_accuracy: 0.6000\n",
      "Epoch 159/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2797 - accuracy: 0.9250 - val_loss: 0.7873 - val_accuracy: 0.7500\n",
      "Epoch 160/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.3114 - accuracy: 0.8625 - val_loss: 0.7805 - val_accuracy: 0.7500\n",
      "Epoch 161/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2825 - accuracy: 0.9125 - val_loss: 0.9295 - val_accuracy: 0.5500\n",
      "Epoch 162/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.3228 - accuracy: 0.9000 - val_loss: 0.8325 - val_accuracy: 0.7000\n",
      "Epoch 163/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.3271 - accuracy: 0.8875 - val_loss: 0.8697 - val_accuracy: 0.7500\n",
      "Epoch 164/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 0.3707 - accuracy: 0.8250 - val_loss: 0.8080 - val_accuracy: 0.7500\n",
      "Epoch 165/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2957 - accuracy: 0.9000 - val_loss: 0.9089 - val_accuracy: 0.6000\n",
      "Epoch 166/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2928 - accuracy: 0.9125 - val_loss: 0.8076 - val_accuracy: 0.7500\n",
      "Epoch 167/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.2662 - accuracy: 0.9000 - val_loss: 0.7941 - val_accuracy: 0.7500\n",
      "Epoch 168/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2748 - accuracy: 0.8875 - val_loss: 0.7935 - val_accuracy: 0.7500\n",
      "Epoch 169/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2684 - accuracy: 0.8875 - val_loss: 0.8185 - val_accuracy: 0.7000\n",
      "Epoch 170/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.2743 - accuracy: 0.9125 - val_loss: 0.8291 - val_accuracy: 0.7000\n",
      "Epoch 171/2000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.2719 - accuracy: 0.9000 - val_loss: 0.8135 - val_accuracy: 0.7000\n",
      "Epoch 172/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2662 - accuracy: 0.9000 - val_loss: 0.7998 - val_accuracy: 0.7500\n",
      "Epoch 173/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.2680 - accuracy: 0.8875 - val_loss: 0.7848 - val_accuracy: 0.7500\n",
      "Epoch 174/2000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.2716 - accuracy: 0.9000 - val_loss: 0.7921 - val_accuracy: 0.7500\n",
      "Epoch 175/2000\n",
      "80/80 [==============================] - 0s 517us/sample - loss: 0.2721 - accuracy: 0.8875 - val_loss: 0.7654 - val_accuracy: 0.7500\n",
      "Epoch 176/2000\n",
      "80/80 [==============================] - 0s 195us/sample - loss: 0.2655 - accuracy: 0.9000 - val_loss: 0.7699 - val_accuracy: 0.7500\n",
      "Epoch 177/2000\n",
      "80/80 [==============================] - 0s 315us/sample - loss: 0.2670 - accuracy: 0.9000 - val_loss: 0.7881 - val_accuracy: 0.7000\n",
      "Epoch 178/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2675 - accuracy: 0.9125 - val_loss: 0.7861 - val_accuracy: 0.7500\n",
      "Epoch 179/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.2689 - accuracy: 0.8875 - val_loss: 0.7840 - val_accuracy: 0.7500\n",
      "Epoch 180/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2698 - accuracy: 0.9000 - val_loss: 0.8356 - val_accuracy: 0.7000\n",
      "Epoch 181/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.2695 - accuracy: 0.9000 - val_loss: 0.8669 - val_accuracy: 0.6000\n",
      "Epoch 182/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.2699 - accuracy: 0.9125 - val_loss: 0.8232 - val_accuracy: 0.7500\n",
      "Epoch 183/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.2728 - accuracy: 0.8875 - val_loss: 0.8211 - val_accuracy: 0.7500\n",
      "Epoch 184/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2674 - accuracy: 0.9000 - val_loss: 0.8379 - val_accuracy: 0.7000\n",
      "Epoch 185/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.2658 - accuracy: 0.9125 - val_loss: 0.8132 - val_accuracy: 0.7000\n",
      "Epoch 186/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2704 - accuracy: 0.9125 - val_loss: 0.7759 - val_accuracy: 0.7000\n",
      "Epoch 187/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2670 - accuracy: 0.8875 - val_loss: 0.7359 - val_accuracy: 0.7500\n",
      "Epoch 188/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2847 - accuracy: 0.8750 - val_loss: 0.7394 - val_accuracy: 0.7500\n",
      "Epoch 189/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2708 - accuracy: 0.8875 - val_loss: 0.7990 - val_accuracy: 0.6500\n",
      "Epoch 190/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2725 - accuracy: 0.9125 - val_loss: 0.7565 - val_accuracy: 0.7500\n",
      "Epoch 191/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2735 - accuracy: 0.9000 - val_loss: 0.7668 - val_accuracy: 0.7500\n",
      "Epoch 192/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2646 - accuracy: 0.9000 - val_loss: 0.8283 - val_accuracy: 0.7000\n",
      "Epoch 193/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2683 - accuracy: 0.9125 - val_loss: 0.8395 - val_accuracy: 0.6500\n",
      "Epoch 194/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2769 - accuracy: 0.9000 - val_loss: 0.8090 - val_accuracy: 0.7000\n",
      "Epoch 195/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.2656 - accuracy: 0.9000 - val_loss: 0.7958 - val_accuracy: 0.7500\n",
      "Epoch 196/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2696 - accuracy: 0.8875 - val_loss: 0.7791 - val_accuracy: 0.7500\n",
      "Epoch 197/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2704 - accuracy: 0.9000 - val_loss: 0.7860 - val_accuracy: 0.7000\n",
      "Epoch 198/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.2628 - accuracy: 0.9125 - val_loss: 0.7682 - val_accuracy: 0.7500\n",
      "Epoch 199/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2691 - accuracy: 0.9000 - val_loss: 0.7561 - val_accuracy: 0.7500\n",
      "Epoch 200/2000\n",
      "80/80 [==============================] - 0s 397us/sample - loss: 0.2695 - accuracy: 0.9000 - val_loss: 0.7855 - val_accuracy: 0.7000\n",
      "Epoch 201/2000\n",
      "80/80 [==============================] - 0s 196us/sample - loss: 0.2653 - accuracy: 0.9125 - val_loss: 0.7610 - val_accuracy: 0.7500\n",
      "Epoch 202/2000\n",
      "80/80 [==============================] - 0s 186us/sample - loss: 0.2911 - accuracy: 0.8750 - val_loss: 0.7722 - val_accuracy: 0.7500\n",
      "Epoch 203/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.2808 - accuracy: 0.9125 - val_loss: 0.8412 - val_accuracy: 0.6500\n",
      "Epoch 204/2000\n",
      "80/80 [==============================] - 0s 30us/sample - loss: 0.2710 - accuracy: 0.9000 - val_loss: 0.8332 - val_accuracy: 0.7000\n",
      "Epoch 205/2000\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.2727 - accuracy: 0.9000 - val_loss: 0.7960 - val_accuracy: 0.7500\n",
      "Epoch 206/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.2646 - accuracy: 0.9000 - val_loss: 0.8111 - val_accuracy: 0.7000\n",
      "Epoch 207/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2634 - accuracy: 0.9125 - val_loss: 0.8225 - val_accuracy: 0.7000\n",
      "Epoch 208/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2688 - accuracy: 0.9125 - val_loss: 0.8023 - val_accuracy: 0.7000\n",
      "Epoch 209/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2655 - accuracy: 0.9125 - val_loss: 0.7893 - val_accuracy: 0.7500\n",
      "Epoch 210/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.2605 - accuracy: 0.9125 - val_loss: 0.7626 - val_accuracy: 0.7500\n",
      "Epoch 211/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.2724 - accuracy: 0.8875 - val_loss: 0.7657 - val_accuracy: 0.7500\n",
      "Epoch 212/2000\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.2681 - accuracy: 0.9125 - val_loss: 0.8250 - val_accuracy: 0.6500\n",
      "Epoch 213/2000\n",
      "80/80 [==============================] - 0s 160us/sample - loss: 0.2704 - accuracy: 0.9125 - val_loss: 0.7830 - val_accuracy: 0.7500\n",
      "Epoch 214/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.2663 - accuracy: 0.9000 - val_loss: 0.7828 - val_accuracy: 0.7500\n",
      "Epoch 215/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2611 - accuracy: 0.9125 - val_loss: 0.8316 - val_accuracy: 0.6000\n",
      "Epoch 216/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2809 - accuracy: 0.9125 - val_loss: 0.8211 - val_accuracy: 0.7000\n",
      "Epoch 217/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.2627 - accuracy: 0.8875 - val_loss: 0.7850 - val_accuracy: 0.7500\n",
      "Epoch 218/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.2741 - accuracy: 0.8875 - val_loss: 0.7879 - val_accuracy: 0.7500\n",
      "Epoch 219/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2574 - accuracy: 0.8875 - val_loss: 0.8408 - val_accuracy: 0.7000\n",
      "Epoch 220/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.2803 - accuracy: 0.9250 - val_loss: 0.8639 - val_accuracy: 0.6000\n",
      "Epoch 221/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2661 - accuracy: 0.9125 - val_loss: 0.8023 - val_accuracy: 0.7500\n",
      "Epoch 222/2000\n",
      "80/80 [==============================] - 0s 604us/sample - loss: 0.2657 - accuracy: 0.9000 - val_loss: 0.7989 - val_accuracy: 0.7500\n",
      "Epoch 223/2000\n",
      "80/80 [==============================] - 0s 166us/sample - loss: 0.2720 - accuracy: 0.9125 - val_loss: 0.8200 - val_accuracy: 0.7500\n",
      "Epoch 224/2000\n",
      "80/80 [==============================] - 0s 168us/sample - loss: 0.2679 - accuracy: 0.9250 - val_loss: 0.8421 - val_accuracy: 0.6500\n",
      "Epoch 225/2000\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 0.2648 - accuracy: 0.9125 - val_loss: 0.7955 - val_accuracy: 0.7500\n",
      "Epoch 226/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2741 - accuracy: 0.8875 - val_loss: 0.7918 - val_accuracy: 0.7500\n",
      "Epoch 227/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2640 - accuracy: 0.9000 - val_loss: 0.8533 - val_accuracy: 0.6500\n",
      "Epoch 228/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.2766 - accuracy: 0.9250 - val_loss: 0.8185 - val_accuracy: 0.7000\n",
      "Epoch 229/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2549 - accuracy: 0.9125 - val_loss: 0.7947 - val_accuracy: 0.7500\n",
      "Epoch 230/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.2857 - accuracy: 0.8875 - val_loss: 0.8001 - val_accuracy: 0.7500\n",
      "Epoch 231/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.2666 - accuracy: 0.9000 - val_loss: 0.8765 - val_accuracy: 0.6500\n",
      "Epoch 232/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.2782 - accuracy: 0.9250 - val_loss: 0.8217 - val_accuracy: 0.7000\n",
      "Epoch 233/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2741 - accuracy: 0.8875 - val_loss: 0.7826 - val_accuracy: 0.7500\n",
      "Epoch 234/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.2674 - accuracy: 0.8875 - val_loss: 0.7879 - val_accuracy: 0.7500\n",
      "Epoch 235/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.2610 - accuracy: 0.9125 - val_loss: 0.8344 - val_accuracy: 0.6500\n",
      "Epoch 236/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2691 - accuracy: 0.9125 - val_loss: 0.7826 - val_accuracy: 0.7500\n",
      "Epoch 237/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2702 - accuracy: 0.8750 - val_loss: 0.7684 - val_accuracy: 0.7500\n",
      "Epoch 238/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2830 - accuracy: 0.8625 - val_loss: 0.7733 - val_accuracy: 0.7500\n",
      "Epoch 239/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2658 - accuracy: 0.9125 - val_loss: 0.7961 - val_accuracy: 0.7000\n",
      "Epoch 240/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2649 - accuracy: 0.9000 - val_loss: 0.7600 - val_accuracy: 0.7500\n",
      "Epoch 241/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.2678 - accuracy: 0.8875 - val_loss: 0.7759 - val_accuracy: 0.7500\n",
      "Epoch 242/2000\n",
      "80/80 [==============================] - 0s 395us/sample - loss: 0.2738 - accuracy: 0.9125 - val_loss: 0.8464 - val_accuracy: 0.6000\n",
      "Epoch 243/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 0.2667 - accuracy: 0.9000 - val_loss: 0.8159 - val_accuracy: 0.7500\n",
      "Epoch 244/2000\n",
      "80/80 [==============================] - 0s 59us/sample - loss: 0.2665 - accuracy: 0.8875 - val_loss: 0.8075 - val_accuracy: 0.7500\n",
      "Epoch 245/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.2808 - accuracy: 0.8875 - val_loss: 0.8173 - val_accuracy: 0.7000\n",
      "Epoch 246/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.2689 - accuracy: 0.9125 - val_loss: 0.8026 - val_accuracy: 0.7000\n",
      "Epoch 247/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2658 - accuracy: 0.9000 - val_loss: 0.7743 - val_accuracy: 0.7500\n",
      "Epoch 248/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 0.2738 - accuracy: 0.8875 - val_loss: 0.7999 - val_accuracy: 0.7000\n",
      "Epoch 249/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.2610 - accuracy: 0.9125 - val_loss: 0.7847 - val_accuracy: 0.7500\n",
      "Epoch 250/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2634 - accuracy: 0.8875 - val_loss: 0.7609 - val_accuracy: 0.7500\n",
      "Epoch 251/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 0.2667 - accuracy: 0.8875 - val_loss: 0.7648 - val_accuracy: 0.7500\n",
      "Epoch 252/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 0.2699 - accuracy: 0.9125 - val_loss: 0.8014 - val_accuracy: 0.7000\n",
      "Epoch 253/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2630 - accuracy: 0.9000 - val_loss: 0.7495 - val_accuracy: 0.7500\n",
      "Epoch 254/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 0.2735 - accuracy: 0.8875 - val_loss: 0.7429 - val_accuracy: 0.7500\n",
      "Epoch 255/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2601 - accuracy: 0.8875 - val_loss: 0.8036 - val_accuracy: 0.6500\n",
      "Epoch 256/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2670 - accuracy: 0.9250 - val_loss: 0.7847 - val_accuracy: 0.7500\n",
      "Epoch 257/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2602 - accuracy: 0.9000 - val_loss: 0.7764 - val_accuracy: 0.7500\n",
      "Epoch 258/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2585 - accuracy: 0.9000 - val_loss: 0.7711 - val_accuracy: 0.7500\n",
      "Epoch 259/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.2623 - accuracy: 0.8875 - val_loss: 0.7901 - val_accuracy: 0.7500\n",
      "Epoch 260/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2574 - accuracy: 0.9125 - val_loss: 0.8120 - val_accuracy: 0.7500\n",
      "Epoch 261/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.2638 - accuracy: 0.9125 - val_loss: 0.8002 - val_accuracy: 0.7500\n",
      "Epoch 262/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2586 - accuracy: 0.9000 - val_loss: 0.8047 - val_accuracy: 0.7500\n",
      "Epoch 263/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.2661 - accuracy: 0.9125 - val_loss: 0.8074 - val_accuracy: 0.7500\n",
      "Epoch 264/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.2547 - accuracy: 0.9000 - val_loss: 0.7664 - val_accuracy: 0.7500\n",
      "Epoch 265/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2935 - accuracy: 0.8875 - val_loss: 0.7520 - val_accuracy: 0.7500\n",
      "Epoch 266/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2847 - accuracy: 0.8750 - val_loss: 0.8920 - val_accuracy: 0.6000\n",
      "Epoch 267/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.2938 - accuracy: 0.9000 - val_loss: 0.7957 - val_accuracy: 0.7500\n",
      "Epoch 268/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2547 - accuracy: 0.9125 - val_loss: 0.7933 - val_accuracy: 0.7500\n",
      "Epoch 269/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2628 - accuracy: 0.8875 - val_loss: 0.8021 - val_accuracy: 0.7500\n",
      "Epoch 270/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.2693 - accuracy: 0.8875 - val_loss: 0.8174 - val_accuracy: 0.7500\n",
      "Epoch 271/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2616 - accuracy: 0.9000 - val_loss: 0.8069 - val_accuracy: 0.7500\n",
      "Epoch 272/2000\n",
      "80/80 [==============================] - 0s 292us/sample - loss: 0.2631 - accuracy: 0.9000 - val_loss: 0.7961 - val_accuracy: 0.7500\n",
      "Epoch 273/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.2632 - accuracy: 0.8875 - val_loss: 0.7688 - val_accuracy: 0.7500\n",
      "Epoch 274/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2716 - accuracy: 0.9000 - val_loss: 0.7886 - val_accuracy: 0.7500\n",
      "Epoch 275/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.2588 - accuracy: 0.9125 - val_loss: 0.7533 - val_accuracy: 0.7500\n",
      "Epoch 276/2000\n",
      "80/80 [==============================] - 0s 50us/sample - loss: 0.2760 - accuracy: 0.8875 - val_loss: 0.7435 - val_accuracy: 0.7500\n",
      "Epoch 277/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 0.2593 - accuracy: 0.9000 - val_loss: 0.8183 - val_accuracy: 0.6000\n",
      "Epoch 278/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2707 - accuracy: 0.9375 - val_loss: 0.7843 - val_accuracy: 0.7000\n",
      "Epoch 279/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2548 - accuracy: 0.9125 - val_loss: 0.7489 - val_accuracy: 0.7500\n",
      "Epoch 280/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2727 - accuracy: 0.8750 - val_loss: 0.7505 - val_accuracy: 0.7500\n",
      "Epoch 281/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.2765 - accuracy: 0.8875 - val_loss: 0.8105 - val_accuracy: 0.7000\n",
      "Epoch 282/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 0.2625 - accuracy: 0.9125 - val_loss: 0.7874 - val_accuracy: 0.7500\n",
      "Epoch 283/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.2543 - accuracy: 0.9000 - val_loss: 0.7643 - val_accuracy: 0.7500\n",
      "Epoch 284/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.2642 - accuracy: 0.8750 - val_loss: 0.7740 - val_accuracy: 0.7500\n",
      "Epoch 285/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2585 - accuracy: 0.8875 - val_loss: 0.7910 - val_accuracy: 0.7500\n",
      "Epoch 286/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2600 - accuracy: 0.9000 - val_loss: 0.8087 - val_accuracy: 0.7500\n",
      "Epoch 287/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2585 - accuracy: 0.9125 - val_loss: 0.7874 - val_accuracy: 0.7500\n",
      "Epoch 288/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2578 - accuracy: 0.9000 - val_loss: 0.7886 - val_accuracy: 0.7500\n",
      "Epoch 289/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2587 - accuracy: 0.9000 - val_loss: 0.8101 - val_accuracy: 0.7500\n",
      "Epoch 290/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2583 - accuracy: 0.9125 - val_loss: 0.8341 - val_accuracy: 0.6500\n",
      "Epoch 291/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.2646 - accuracy: 0.9250 - val_loss: 0.7958 - val_accuracy: 0.7500\n",
      "Epoch 292/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.2574 - accuracy: 0.9000 - val_loss: 0.7831 - val_accuracy: 0.7500\n",
      "Epoch 293/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.2628 - accuracy: 0.9125 - val_loss: 0.7721 - val_accuracy: 0.7500\n",
      "Epoch 294/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2797 - accuracy: 0.8875 - val_loss: 0.7497 - val_accuracy: 0.7500\n",
      "Epoch 295/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2845 - accuracy: 0.8750 - val_loss: 0.8106 - val_accuracy: 0.6500\n",
      "Epoch 296/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2633 - accuracy: 0.9250 - val_loss: 0.7696 - val_accuracy: 0.7500\n",
      "Epoch 297/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2566 - accuracy: 0.8875 - val_loss: 0.7739 - val_accuracy: 0.7500\n",
      "Epoch 298/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2603 - accuracy: 0.8875 - val_loss: 0.7905 - val_accuracy: 0.7500\n",
      "Epoch 299/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2553 - accuracy: 0.9000 - val_loss: 0.7849 - val_accuracy: 0.7500\n",
      "Epoch 300/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.2570 - accuracy: 0.9000 - val_loss: 0.7979 - val_accuracy: 0.7500\n",
      "Epoch 301/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2562 - accuracy: 0.9000 - val_loss: 0.7978 - val_accuracy: 0.7500\n",
      "Epoch 302/2000\n",
      "80/80 [==============================] - 0s 277us/sample - loss: 0.2563 - accuracy: 0.9000 - val_loss: 0.7937 - val_accuracy: 0.7500\n",
      "Epoch 303/2000\n",
      "80/80 [==============================] - 0s 181us/sample - loss: 0.2580 - accuracy: 0.9125 - val_loss: 0.7867 - val_accuracy: 0.7500\n",
      "Epoch 304/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.2618 - accuracy: 0.9125 - val_loss: 0.7800 - val_accuracy: 0.7500\n",
      "Epoch 305/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2563 - accuracy: 0.9000 - val_loss: 0.8158 - val_accuracy: 0.7500\n",
      "Epoch 306/2000\n",
      "80/80 [==============================] - 0s 154us/sample - loss: 0.2617 - accuracy: 0.9125 - val_loss: 0.8515 - val_accuracy: 0.6500\n",
      "Epoch 307/2000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.2743 - accuracy: 0.9250 - val_loss: 0.8105 - val_accuracy: 0.7000\n",
      "Epoch 308/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.2534 - accuracy: 0.9125 - val_loss: 0.7748 - val_accuracy: 0.7500\n",
      "Epoch 309/2000\n",
      "80/80 [==============================] - 0s 73us/sample - loss: 0.2729 - accuracy: 0.8750 - val_loss: 0.7808 - val_accuracy: 0.7500\n",
      "Epoch 310/2000\n",
      "80/80 [==============================] - 0s 156us/sample - loss: 0.2570 - accuracy: 0.9000 - val_loss: 0.8260 - val_accuracy: 0.6500\n",
      "Epoch 311/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2636 - accuracy: 0.9125 - val_loss: 0.8412 - val_accuracy: 0.6500\n",
      "Epoch 312/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2663 - accuracy: 0.9250 - val_loss: 0.8173 - val_accuracy: 0.7000\n",
      "Epoch 313/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2597 - accuracy: 0.9125 - val_loss: 0.7958 - val_accuracy: 0.7500\n",
      "Epoch 314/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 0.2684 - accuracy: 0.8750 - val_loss: 0.7718 - val_accuracy: 0.7500\n",
      "Epoch 315/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.2538 - accuracy: 0.9000 - val_loss: 0.8106 - val_accuracy: 0.7000\n",
      "Epoch 316/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 0.2648 - accuracy: 0.9125 - val_loss: 0.8164 - val_accuracy: 0.7000\n",
      "Epoch 317/2000\n",
      "80/80 [==============================] - 0s 73us/sample - loss: 0.2531 - accuracy: 0.9000 - val_loss: 0.7794 - val_accuracy: 0.7500\n",
      "Epoch 318/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2832 - accuracy: 0.8875 - val_loss: 0.7683 - val_accuracy: 0.7500\n",
      "Epoch 319/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2675 - accuracy: 0.9000 - val_loss: 0.7948 - val_accuracy: 0.7000\n",
      "Epoch 320/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2671 - accuracy: 0.9125 - val_loss: 0.8187 - val_accuracy: 0.6500\n",
      "Epoch 321/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2563 - accuracy: 0.9125 - val_loss: 0.7747 - val_accuracy: 0.7500\n",
      "Epoch 322/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.2779 - accuracy: 0.8750 - val_loss: 0.7688 - val_accuracy: 0.7500\n",
      "Epoch 323/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.2543 - accuracy: 0.8875 - val_loss: 0.8305 - val_accuracy: 0.6500\n",
      "Epoch 324/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.2785 - accuracy: 0.9125 - val_loss: 0.8571 - val_accuracy: 0.6000\n",
      "Epoch 325/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2600 - accuracy: 0.9125 - val_loss: 0.7976 - val_accuracy: 0.7500\n",
      "Epoch 326/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.2672 - accuracy: 0.8875 - val_loss: 0.8037 - val_accuracy: 0.7500\n",
      "Epoch 327/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.2670 - accuracy: 0.8750 - val_loss: 0.8277 - val_accuracy: 0.7500\n",
      "Epoch 328/2000\n",
      "80/80 [==============================] - 0s 77us/sample - loss: 0.2632 - accuracy: 0.9125 - val_loss: 0.8801 - val_accuracy: 0.6000\n",
      "Epoch 329/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2716 - accuracy: 0.9250 - val_loss: 0.8022 - val_accuracy: 0.7500\n",
      "Epoch 330/2000\n",
      "80/80 [==============================] - 0s 74us/sample - loss: 0.2604 - accuracy: 0.9000 - val_loss: 0.7704 - val_accuracy: 0.7500\n",
      "Epoch 331/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2738 - accuracy: 0.8875 - val_loss: 0.7752 - val_accuracy: 0.7500\n",
      "Epoch 332/2000\n",
      "80/80 [==============================] - 0s 181us/sample - loss: 0.2596 - accuracy: 0.9125 - val_loss: 0.8382 - val_accuracy: 0.6000\n",
      "Epoch 333/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.2633 - accuracy: 0.9250 - val_loss: 0.7867 - val_accuracy: 0.7500\n",
      "Epoch 334/2000\n",
      "80/80 [==============================] - 0s 178us/sample - loss: 0.2521 - accuracy: 0.9000 - val_loss: 0.7733 - val_accuracy: 0.7500\n",
      "Epoch 335/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.2612 - accuracy: 0.8750 - val_loss: 0.7729 - val_accuracy: 0.7500\n",
      "Epoch 336/2000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.2707 - accuracy: 0.9125 - val_loss: 0.8224 - val_accuracy: 0.6500\n",
      "Epoch 337/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2608 - accuracy: 0.9250 - val_loss: 0.7881 - val_accuracy: 0.7500\n",
      "Epoch 338/2000\n",
      "80/80 [==============================] - 0s 63us/sample - loss: 0.2611 - accuracy: 0.9000 - val_loss: 0.7845 - val_accuracy: 0.7500\n",
      "Epoch 339/2000\n",
      "80/80 [==============================] - 0s 208us/sample - loss: 0.2685 - accuracy: 0.8875 - val_loss: 0.8042 - val_accuracy: 0.7500\n",
      "Epoch 340/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2506 - accuracy: 0.9000 - val_loss: 0.8637 - val_accuracy: 0.6500\n",
      "Epoch 341/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.2746 - accuracy: 0.9250 - val_loss: 0.8401 - val_accuracy: 0.7500\n",
      "Epoch 342/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2507 - accuracy: 0.9000 - val_loss: 0.8083 - val_accuracy: 0.7500\n",
      "Epoch 343/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2726 - accuracy: 0.8750 - val_loss: 0.7869 - val_accuracy: 0.7500\n",
      "Epoch 344/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2495 - accuracy: 0.9000 - val_loss: 0.8435 - val_accuracy: 0.6000\n",
      "Epoch 345/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2751 - accuracy: 0.9250 - val_loss: 0.8457 - val_accuracy: 0.6500\n",
      "Epoch 346/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2802 - accuracy: 0.9125 - val_loss: 0.7546 - val_accuracy: 0.7500\n",
      "Epoch 347/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2617 - accuracy: 0.8750 - val_loss: 0.7631 - val_accuracy: 0.7500\n",
      "Epoch 348/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.2586 - accuracy: 0.9000 - val_loss: 0.7968 - val_accuracy: 0.6500\n",
      "Epoch 349/2000\n",
      "80/80 [==============================] - 0s 152us/sample - loss: 0.2564 - accuracy: 0.9250 - val_loss: 0.7547 - val_accuracy: 0.7500\n",
      "Epoch 350/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2537 - accuracy: 0.8875 - val_loss: 0.7456 - val_accuracy: 0.7500\n",
      "Epoch 351/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2616 - accuracy: 0.8750 - val_loss: 0.7639 - val_accuracy: 0.7500\n",
      "Epoch 352/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2618 - accuracy: 0.9125 - val_loss: 0.8433 - val_accuracy: 0.6500\n",
      "Epoch 353/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2592 - accuracy: 0.9250 - val_loss: 0.7911 - val_accuracy: 0.7500\n",
      "Epoch 354/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2602 - accuracy: 0.9000 - val_loss: 0.7689 - val_accuracy: 0.7500\n",
      "Epoch 355/2000\n",
      "80/80 [==============================] - 0s 595us/sample - loss: 0.2609 - accuracy: 0.8750 - val_loss: 0.7922 - val_accuracy: 0.7500\n",
      "Epoch 356/2000\n",
      "80/80 [==============================] - 0s 172us/sample - loss: 0.2598 - accuracy: 0.9250 - val_loss: 0.8449 - val_accuracy: 0.6500\n",
      "Epoch 357/2000\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.2586 - accuracy: 0.9375 - val_loss: 0.7713 - val_accuracy: 0.7500\n",
      "Epoch 358/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2584 - accuracy: 0.8875 - val_loss: 0.7721 - val_accuracy: 0.7500\n",
      "Epoch 359/2000\n",
      "80/80 [==============================] - 0s 182us/sample - loss: 0.2547 - accuracy: 0.8750 - val_loss: 0.8099 - val_accuracy: 0.7500\n",
      "Epoch 360/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2791 - accuracy: 0.9250 - val_loss: 0.8817 - val_accuracy: 0.6000\n",
      "Epoch 361/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2668 - accuracy: 0.9125 - val_loss: 0.7649 - val_accuracy: 0.7500\n",
      "Epoch 362/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.2978 - accuracy: 0.8750 - val_loss: 0.7729 - val_accuracy: 0.7500\n",
      "Epoch 363/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2675 - accuracy: 0.8875 - val_loss: 0.8650 - val_accuracy: 0.6500\n",
      "Epoch 364/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2715 - accuracy: 0.9250 - val_loss: 0.8397 - val_accuracy: 0.7000\n",
      "Epoch 365/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.2518 - accuracy: 0.9125 - val_loss: 0.7763 - val_accuracy: 0.7500\n",
      "Epoch 366/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2716 - accuracy: 0.8875 - val_loss: 0.7540 - val_accuracy: 0.7500\n",
      "Epoch 367/2000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.2645 - accuracy: 0.8875 - val_loss: 0.7877 - val_accuracy: 0.7000\n",
      "Epoch 368/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2719 - accuracy: 0.9125 - val_loss: 0.8201 - val_accuracy: 0.6500\n",
      "Epoch 369/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.2550 - accuracy: 0.9250 - val_loss: 0.7561 - val_accuracy: 0.7500\n",
      "Epoch 370/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2721 - accuracy: 0.8750 - val_loss: 0.7679 - val_accuracy: 0.7500\n",
      "Epoch 371/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2649 - accuracy: 0.8875 - val_loss: 0.8162 - val_accuracy: 0.7500\n",
      "Epoch 372/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.2604 - accuracy: 0.9250 - val_loss: 0.8148 - val_accuracy: 0.7500\n",
      "Epoch 373/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2555 - accuracy: 0.9125 - val_loss: 0.7794 - val_accuracy: 0.7500\n",
      "Epoch 374/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2546 - accuracy: 0.9000 - val_loss: 0.7704 - val_accuracy: 0.7500\n",
      "Epoch 375/2000\n",
      "80/80 [==============================] - 0s 62us/sample - loss: 0.2525 - accuracy: 0.9000 - val_loss: 0.7579 - val_accuracy: 0.7500\n",
      "Epoch 376/2000\n",
      "80/80 [==============================] - 0s 65us/sample - loss: 0.2515 - accuracy: 0.9000 - val_loss: 0.7564 - val_accuracy: 0.7500\n",
      "Epoch 377/2000\n",
      "80/80 [==============================] - 0s 185us/sample - loss: 0.2512 - accuracy: 0.9000 - val_loss: 0.7669 - val_accuracy: 0.7500\n",
      "Epoch 378/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.2556 - accuracy: 0.9125 - val_loss: 0.7839 - val_accuracy: 0.7500\n",
      "Epoch 379/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2535 - accuracy: 0.8875 - val_loss: 0.7406 - val_accuracy: 0.7500\n",
      "Epoch 380/2000\n",
      "80/80 [==============================] - 0s 62us/sample - loss: 0.2558 - accuracy: 0.8750 - val_loss: 0.7395 - val_accuracy: 0.7500\n",
      "Epoch 381/2000\n",
      "80/80 [==============================] - 0s 199us/sample - loss: 0.2535 - accuracy: 0.9000 - val_loss: 0.7612 - val_accuracy: 0.7500\n",
      "Epoch 382/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2743 - accuracy: 0.9125 - val_loss: 0.7997 - val_accuracy: 0.7000\n",
      "Epoch 383/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2570 - accuracy: 0.9125 - val_loss: 0.7441 - val_accuracy: 0.7500\n",
      "Epoch 384/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2843 - accuracy: 0.8750 - val_loss: 0.7538 - val_accuracy: 0.7500\n",
      "Epoch 385/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2518 - accuracy: 0.9000 - val_loss: 0.8962 - val_accuracy: 0.6000\n",
      "Epoch 386/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2881 - accuracy: 0.9250 - val_loss: 0.8216 - val_accuracy: 0.7000\n",
      "Epoch 387/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2630 - accuracy: 0.9000 - val_loss: 0.7792 - val_accuracy: 0.7500\n",
      "Epoch 388/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.2666 - accuracy: 0.8750 - val_loss: 0.7923 - val_accuracy: 0.7500\n",
      "Epoch 389/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.2555 - accuracy: 0.9000 - val_loss: 0.8292 - val_accuracy: 0.7000\n",
      "Epoch 390/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2538 - accuracy: 0.9250 - val_loss: 0.8165 - val_accuracy: 0.7500\n",
      "Epoch 391/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.2501 - accuracy: 0.9125 - val_loss: 0.7735 - val_accuracy: 0.7500\n",
      "Epoch 392/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2589 - accuracy: 0.8750 - val_loss: 0.7564 - val_accuracy: 0.7500\n",
      "Epoch 393/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2517 - accuracy: 0.9250 - val_loss: 0.8404 - val_accuracy: 0.6000\n",
      "Epoch 394/2000\n",
      "80/80 [==============================] - 0s 191us/sample - loss: 0.2734 - accuracy: 0.9375 - val_loss: 0.7419 - val_accuracy: 0.7500\n",
      "Epoch 395/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.2448 - accuracy: 0.9125 - val_loss: 0.7210 - val_accuracy: 0.7500\n",
      "Epoch 396/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2587 - accuracy: 0.8750 - val_loss: 0.7370 - val_accuracy: 0.7500\n",
      "Epoch 397/2000\n",
      "80/80 [==============================] - 0s 407us/sample - loss: 0.2560 - accuracy: 0.8750 - val_loss: 0.7739 - val_accuracy: 0.7500\n",
      "Epoch 398/2000\n",
      "80/80 [==============================] - 0s 233us/sample - loss: 0.2460 - accuracy: 0.9125 - val_loss: 0.8765 - val_accuracy: 0.6000\n",
      "Epoch 399/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2805 - accuracy: 0.9250 - val_loss: 0.7936 - val_accuracy: 0.7500\n",
      "Epoch 400/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.2664 - accuracy: 0.9000 - val_loss: 0.7552 - val_accuracy: 0.7500\n",
      "Epoch 401/2000\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.2725 - accuracy: 0.8750 - val_loss: 0.7766 - val_accuracy: 0.7500\n",
      "Epoch 402/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.2473 - accuracy: 0.9000 - val_loss: 0.8220 - val_accuracy: 0.7500\n",
      "Epoch 403/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2585 - accuracy: 0.9125 - val_loss: 0.8471 - val_accuracy: 0.6500\n",
      "Epoch 404/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.2564 - accuracy: 0.9125 - val_loss: 0.7774 - val_accuracy: 0.7500\n",
      "Epoch 405/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.2679 - accuracy: 0.8750 - val_loss: 0.7675 - val_accuracy: 0.7500\n",
      "Epoch 406/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2549 - accuracy: 0.9000 - val_loss: 0.8503 - val_accuracy: 0.7000\n",
      "Epoch 407/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.2781 - accuracy: 0.9250 - val_loss: 0.8289 - val_accuracy: 0.7500\n",
      "Epoch 408/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.2562 - accuracy: 0.9000 - val_loss: 0.7739 - val_accuracy: 0.7500\n",
      "Epoch 409/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2594 - accuracy: 0.8750 - val_loss: 0.7618 - val_accuracy: 0.7500\n",
      "Epoch 410/2000\n",
      "80/80 [==============================] - 0s 71us/sample - loss: 0.2493 - accuracy: 0.9125 - val_loss: 0.7783 - val_accuracy: 0.7500\n",
      "Epoch 411/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2505 - accuracy: 0.9250 - val_loss: 0.7800 - val_accuracy: 0.7500\n",
      "Epoch 412/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.2477 - accuracy: 0.9125 - val_loss: 0.7734 - val_accuracy: 0.7500\n",
      "Epoch 413/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2547 - accuracy: 0.8875 - val_loss: 0.7588 - val_accuracy: 0.7500\n",
      "Epoch 414/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2618 - accuracy: 0.8750 - val_loss: 0.7670 - val_accuracy: 0.7500\n",
      "Epoch 415/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2517 - accuracy: 0.9125 - val_loss: 0.8176 - val_accuracy: 0.6500\n",
      "Epoch 416/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.2523 - accuracy: 0.9250 - val_loss: 0.7504 - val_accuracy: 0.7500\n",
      "Epoch 417/2000\n",
      "80/80 [==============================] - 0s 61us/sample - loss: 0.2850 - accuracy: 0.8625 - val_loss: 0.7318 - val_accuracy: 0.7500\n",
      "Epoch 418/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2522 - accuracy: 0.9000 - val_loss: 0.8736 - val_accuracy: 0.6000\n",
      "Epoch 419/2000\n",
      "80/80 [==============================] - 0s 73us/sample - loss: 0.2827 - accuracy: 0.9250 - val_loss: 0.8187 - val_accuracy: 0.7500\n",
      "Epoch 420/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2499 - accuracy: 0.9125 - val_loss: 0.7719 - val_accuracy: 0.7500\n",
      "Epoch 421/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2591 - accuracy: 0.8750 - val_loss: 0.7735 - val_accuracy: 0.7500\n",
      "Epoch 422/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2534 - accuracy: 0.8750 - val_loss: 0.7809 - val_accuracy: 0.7500\n",
      "Epoch 423/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2486 - accuracy: 0.9250 - val_loss: 0.8228 - val_accuracy: 0.6500\n",
      "Epoch 424/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2645 - accuracy: 0.9375 - val_loss: 0.7615 - val_accuracy: 0.7000\n",
      "Epoch 425/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.2329 - accuracy: 0.93 - 0s 145us/sample - loss: 0.2517 - accuracy: 0.9000 - val_loss: 0.7206 - val_accuracy: 0.7500\n",
      "Epoch 426/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2708 - accuracy: 0.8500 - val_loss: 0.7435 - val_accuracy: 0.7500\n",
      "Epoch 427/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2770 - accuracy: 0.9125 - val_loss: 0.8823 - val_accuracy: 0.6000\n",
      "Epoch 428/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.2766 - accuracy: 0.9125 - val_loss: 0.7893 - val_accuracy: 0.7500\n",
      "Epoch 429/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.2546 - accuracy: 0.8875 - val_loss: 0.7921 - val_accuracy: 0.7500\n",
      "Epoch 430/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.2476 - accuracy: 0.8875 - val_loss: 0.7950 - val_accuracy: 0.7500\n",
      "Epoch 431/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2465 - accuracy: 0.9250 - val_loss: 0.8236 - val_accuracy: 0.7000\n",
      "Epoch 432/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2615 - accuracy: 0.9375 - val_loss: 0.7744 - val_accuracy: 0.7000\n",
      "Epoch 433/2000\n",
      "80/80 [==============================] - 0s 216us/sample - loss: 0.2594 - accuracy: 0.9000 - val_loss: 0.7450 - val_accuracy: 0.7500\n",
      "Epoch 434/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.2551 - accuracy: 0.8875 - val_loss: 0.7597 - val_accuracy: 0.7500\n",
      "Epoch 435/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2451 - accuracy: 0.9125 - val_loss: 0.7891 - val_accuracy: 0.7500\n",
      "Epoch 436/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2530 - accuracy: 0.9375 - val_loss: 0.7747 - val_accuracy: 0.7500\n",
      "Epoch 437/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2426 - accuracy: 0.9125 - val_loss: 0.7410 - val_accuracy: 0.7500\n",
      "Epoch 438/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2508 - accuracy: 0.8750 - val_loss: 0.7440 - val_accuracy: 0.7500\n",
      "Epoch 439/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2497 - accuracy: 0.9000 - val_loss: 0.7766 - val_accuracy: 0.7500\n",
      "Epoch 440/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.2460 - accuracy: 0.9250 - val_loss: 0.7888 - val_accuracy: 0.7500\n",
      "Epoch 441/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2485 - accuracy: 0.9250 - val_loss: 0.7761 - val_accuracy: 0.7500\n",
      "Epoch 442/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2503 - accuracy: 0.9250 - val_loss: 0.7771 - val_accuracy: 0.7500\n",
      "Epoch 443/2000\n",
      "80/80 [==============================] - 0s 65us/sample - loss: 0.2472 - accuracy: 0.9125 - val_loss: 0.7519 - val_accuracy: 0.7500\n",
      "Epoch 444/2000\n",
      "80/80 [==============================] - 0s 227us/sample - loss: 0.2563 - accuracy: 0.8875 - val_loss: 0.7590 - val_accuracy: 0.7500\n",
      "Epoch 445/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2644 - accuracy: 0.9125 - val_loss: 0.8159 - val_accuracy: 0.7000\n",
      "Epoch 446/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2480 - accuracy: 0.9375 - val_loss: 0.7215 - val_accuracy: 0.7500\n",
      "Epoch 447/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2483 - accuracy: 0.8875 - val_loss: 0.7191 - val_accuracy: 0.7500\n",
      "Epoch 448/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2650 - accuracy: 0.8750 - val_loss: 0.7523 - val_accuracy: 0.7500\n",
      "Epoch 449/2000\n",
      "80/80 [==============================] - 0s 172us/sample - loss: 0.2446 - accuracy: 0.9125 - val_loss: 0.8065 - val_accuracy: 0.7500\n",
      "Epoch 450/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.2520 - accuracy: 0.9250 - val_loss: 0.7703 - val_accuracy: 0.7500\n",
      "Epoch 451/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2530 - accuracy: 0.9000 - val_loss: 0.7647 - val_accuracy: 0.7500\n",
      "Epoch 452/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.2424 - accuracy: 0.9125 - val_loss: 0.7997 - val_accuracy: 0.7500\n",
      "Epoch 453/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.2634 - accuracy: 0.9125 - val_loss: 0.7848 - val_accuracy: 0.7500\n",
      "Epoch 454/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2463 - accuracy: 0.9250 - val_loss: 0.7208 - val_accuracy: 0.7500\n",
      "Epoch 455/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2602 - accuracy: 0.8750 - val_loss: 0.7327 - val_accuracy: 0.7500\n",
      "Epoch 456/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2470 - accuracy: 0.8875 - val_loss: 0.7608 - val_accuracy: 0.7500\n",
      "Epoch 457/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2555 - accuracy: 0.9250 - val_loss: 0.7846 - val_accuracy: 0.7500\n",
      "Epoch 458/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2570 - accuracy: 0.9000 - val_loss: 0.7412 - val_accuracy: 0.7500\n",
      "Epoch 459/2000\n",
      "80/80 [==============================] - 0s 213us/sample - loss: 0.2466 - accuracy: 0.8875 - val_loss: 0.7459 - val_accuracy: 0.7500\n",
      "Epoch 460/2000\n",
      "80/80 [==============================] - 0s 184us/sample - loss: 0.2447 - accuracy: 0.9250 - val_loss: 0.7640 - val_accuracy: 0.7500\n",
      "Epoch 461/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2422 - accuracy: 0.9250 - val_loss: 0.7380 - val_accuracy: 0.7500\n",
      "Epoch 462/2000\n",
      "80/80 [==============================] - 0s 239us/sample - loss: 0.2426 - accuracy: 0.9000 - val_loss: 0.7394 - val_accuracy: 0.7500\n",
      "Epoch 463/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2448 - accuracy: 0.8875 - val_loss: 0.7743 - val_accuracy: 0.7500\n",
      "Epoch 464/2000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.2468 - accuracy: 0.9250 - val_loss: 0.8051 - val_accuracy: 0.7500\n",
      "Epoch 465/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2505 - accuracy: 0.9375 - val_loss: 0.7451 - val_accuracy: 0.7500\n",
      "Epoch 466/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.2422 - accuracy: 0.8875 - val_loss: 0.7265 - val_accuracy: 0.7500\n",
      "Epoch 467/2000\n",
      "80/80 [==============================] - 0s 157us/sample - loss: 0.2501 - accuracy: 0.8875 - val_loss: 0.7288 - val_accuracy: 0.7500\n",
      "Epoch 468/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2437 - accuracy: 0.8875 - val_loss: 0.7440 - val_accuracy: 0.7500\n",
      "Epoch 469/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.2418 - accuracy: 0.9125 - val_loss: 0.7491 - val_accuracy: 0.7500\n",
      "Epoch 470/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2546 - accuracy: 0.9250 - val_loss: 0.7220 - val_accuracy: 0.7500\n",
      "Epoch 471/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2372 - accuracy: 0.9000 - val_loss: 0.7130 - val_accuracy: 0.7500\n",
      "Epoch 472/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2633 - accuracy: 0.8750 - val_loss: 0.7216 - val_accuracy: 0.7500\n",
      "Epoch 473/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2402 - accuracy: 0.9000 - val_loss: 0.8049 - val_accuracy: 0.7000\n",
      "Epoch 474/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2556 - accuracy: 0.9375 - val_loss: 0.7869 - val_accuracy: 0.7500\n",
      "Epoch 475/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2474 - accuracy: 0.9125 - val_loss: 0.7482 - val_accuracy: 0.7500\n",
      "Epoch 476/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2455 - accuracy: 0.8875 - val_loss: 0.7262 - val_accuracy: 0.7500\n",
      "Epoch 477/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.2453 - accuracy: 0.9000 - val_loss: 0.7067 - val_accuracy: 0.7500\n",
      "Epoch 478/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.2444 - accuracy: 0.9250 - val_loss: 0.7226 - val_accuracy: 0.7500\n",
      "Epoch 479/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 0.2445 - accuracy: 0.9375 - val_loss: 0.7123 - val_accuracy: 0.7500\n",
      "Epoch 480/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.2621 - accuracy: 0.9000 - val_loss: 0.6865 - val_accuracy: 0.7500\n",
      "Epoch 481/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2569 - accuracy: 0.9125 - val_loss: 0.7680 - val_accuracy: 0.8000\n",
      "Epoch 482/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2512 - accuracy: 0.9250 - val_loss: 0.7205 - val_accuracy: 0.7500\n",
      "Epoch 483/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2413 - accuracy: 0.9000 - val_loss: 0.7153 - val_accuracy: 0.7500\n",
      "Epoch 484/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.2393 - accuracy: 0.9250 - val_loss: 0.7029 - val_accuracy: 0.7500\n",
      "Epoch 485/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2462 - accuracy: 0.8875 - val_loss: 0.7061 - val_accuracy: 0.7500\n",
      "Epoch 486/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.2396 - accuracy: 0.9125 - val_loss: 0.7545 - val_accuracy: 0.7500\n",
      "Epoch 487/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.2514 - accuracy: 0.9375 - val_loss: 0.7609 - val_accuracy: 0.7500\n",
      "Epoch 488/2000\n",
      "80/80 [==============================] - 0s 170us/sample - loss: 0.2433 - accuracy: 0.9250 - val_loss: 0.7571 - val_accuracy: 0.7500\n",
      "Epoch 489/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2542 - accuracy: 0.8750 - val_loss: 0.7566 - val_accuracy: 0.7500\n",
      "Epoch 490/2000\n",
      "80/80 [==============================] - 0s 53us/sample - loss: 0.2400 - accuracy: 0.9250 - val_loss: 0.8203 - val_accuracy: 0.7500\n",
      "Epoch 491/2000\n",
      "80/80 [==============================] - 0s 197us/sample - loss: 0.2541 - accuracy: 0.9375 - val_loss: 0.7550 - val_accuracy: 0.7500\n",
      "Epoch 492/2000\n",
      "80/80 [==============================] - 0s 13us/sample - loss: 0.2504 - accuracy: 0.9125 - val_loss: 0.7244 - val_accuracy: 0.7500\n",
      "Epoch 493/2000\n",
      "80/80 [==============================] - 0s 250us/sample - loss: 0.2382 - accuracy: 0.9250 - val_loss: 0.7665 - val_accuracy: 0.8000\n",
      "Epoch 494/2000\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.2452 - accuracy: 0.9250 - val_loss: 0.7538 - val_accuracy: 0.7500\n",
      "Epoch 495/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.2405 - accuracy: 0.9125 - val_loss: 0.7207 - val_accuracy: 0.7500\n",
      "Epoch 496/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2402 - accuracy: 0.8875 - val_loss: 0.7053 - val_accuracy: 0.7500\n",
      "Epoch 497/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2495 - accuracy: 0.9250 - val_loss: 0.7250 - val_accuracy: 0.7500\n",
      "Epoch 498/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2436 - accuracy: 0.9000 - val_loss: 0.6976 - val_accuracy: 0.7500\n",
      "Epoch 499/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2420 - accuracy: 0.8875 - val_loss: 0.7207 - val_accuracy: 0.7500\n",
      "Epoch 500/2000\n",
      "80/80 [==============================] - 0s 159us/sample - loss: 0.2533 - accuracy: 0.9125 - val_loss: 0.7766 - val_accuracy: 0.7500\n",
      "Epoch 501/2000\n",
      "80/80 [==============================] - 0s 366us/sample - loss: 0.2385 - accuracy: 0.9375 - val_loss: 0.7402 - val_accuracy: 0.7500\n",
      "Epoch 502/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.2542 - accuracy: 0.8875 - val_loss: 0.7188 - val_accuracy: 0.7500\n",
      "Epoch 503/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.2560 - accuracy: 0.8875 - val_loss: 0.7446 - val_accuracy: 0.7500\n",
      "Epoch 504/2000\n",
      "80/80 [==============================] - 0s 639us/sample - loss: 0.2578 - accuracy: 0.9375 - val_loss: 0.7173 - val_accuracy: 0.7500\n",
      "Epoch 505/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2396 - accuracy: 0.9250 - val_loss: 0.7083 - val_accuracy: 0.7500\n",
      "Epoch 506/2000\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 0.2501 - accuracy: 0.8750 - val_loss: 0.7497 - val_accuracy: 0.7500\n",
      "Epoch 507/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.2420 - accuracy: 0.8875 - val_loss: 0.7757 - val_accuracy: 0.7500\n",
      "Epoch 508/2000\n",
      "80/80 [==============================] - 0s 207us/sample - loss: 0.2423 - accuracy: 0.9250 - val_loss: 0.7557 - val_accuracy: 0.7500\n",
      "Epoch 509/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.2396 - accuracy: 0.9125 - val_loss: 0.7055 - val_accuracy: 0.7500\n",
      "Epoch 510/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2451 - accuracy: 0.8875 - val_loss: 0.7166 - val_accuracy: 0.7500\n",
      "Epoch 511/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2527 - accuracy: 0.9125 - val_loss: 0.8156 - val_accuracy: 0.7500\n",
      "Epoch 512/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2541 - accuracy: 0.9250 - val_loss: 0.7621 - val_accuracy: 0.7500\n",
      "Epoch 513/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.2497 - accuracy: 0.8750 - val_loss: 0.7010 - val_accuracy: 0.7500\n",
      "Epoch 514/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.2374 - accuracy: 0.8875 - val_loss: 0.7081 - val_accuracy: 0.7500\n",
      "Epoch 515/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.2553 - accuracy: 0.9375 - val_loss: 0.7334 - val_accuracy: 0.7500\n",
      "Epoch 516/2000\n",
      "80/80 [==============================] - 0s 77us/sample - loss: 0.2375 - accuracy: 0.9375 - val_loss: 0.6756 - val_accuracy: 0.7500\n",
      "Epoch 517/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.2642 - accuracy: 0.8750 - val_loss: 0.7031 - val_accuracy: 0.7500\n",
      "Epoch 518/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.2504 - accuracy: 0.8875 - val_loss: 0.7874 - val_accuracy: 0.7500\n",
      "Epoch 519/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.2460 - accuracy: 0.9375 - val_loss: 0.7789 - val_accuracy: 0.7500\n",
      "Epoch 520/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.2382 - accuracy: 0.9375 - val_loss: 0.7279 - val_accuracy: 0.7500\n",
      "Epoch 521/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2423 - accuracy: 0.8875 - val_loss: 0.7193 - val_accuracy: 0.7500\n",
      "Epoch 522/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2388 - accuracy: 0.9125 - val_loss: 0.7284 - val_accuracy: 0.7500\n",
      "Epoch 523/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.2379 - accuracy: 0.9375 - val_loss: 0.7411 - val_accuracy: 0.7500\n",
      "Epoch 524/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.2355 - accuracy: 0.9250 - val_loss: 0.7147 - val_accuracy: 0.7500\n",
      "Epoch 525/2000\n",
      "80/80 [==============================] - 0s 163us/sample - loss: 0.2519 - accuracy: 0.8875 - val_loss: 0.7124 - val_accuracy: 0.7500\n",
      "Epoch 526/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.2432 - accuracy: 0.9000 - val_loss: 0.7524 - val_accuracy: 0.7500\n",
      "Epoch 527/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.2467 - accuracy: 0.9375 - val_loss: 0.7116 - val_accuracy: 0.7500\n",
      "Epoch 528/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.2378 - accuracy: 0.9250 - val_loss: 0.6852 - val_accuracy: 0.7500\n",
      "Epoch 529/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2422 - accuracy: 0.9000 - val_loss: 0.7044 - val_accuracy: 0.7500\n",
      "Epoch 530/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2396 - accuracy: 0.9000 - val_loss: 0.7342 - val_accuracy: 0.7500\n",
      "Epoch 531/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2343 - accuracy: 0.9125 - val_loss: 0.7814 - val_accuracy: 0.7500\n",
      "Epoch 532/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2437 - accuracy: 0.9375 - val_loss: 0.7520 - val_accuracy: 0.7500\n",
      "Epoch 533/2000\n",
      "80/80 [==============================] - 0s 192us/sample - loss: 0.2388 - accuracy: 0.8875 - val_loss: 0.7174 - val_accuracy: 0.7500\n",
      "Epoch 534/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2438 - accuracy: 0.8875 - val_loss: 0.7236 - val_accuracy: 0.7500\n",
      "Epoch 535/2000\n",
      "80/80 [==============================] - 0s 229us/sample - loss: 0.2386 - accuracy: 0.9000 - val_loss: 0.7155 - val_accuracy: 0.8000\n",
      "Epoch 536/2000\n",
      "80/80 [==============================] - 0s 170us/sample - loss: 0.2397 - accuracy: 0.9375 - val_loss: 0.7082 - val_accuracy: 0.7500\n",
      "Epoch 537/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2342 - accuracy: 0.9250 - val_loss: 0.6913 - val_accuracy: 0.7500\n",
      "Epoch 538/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2454 - accuracy: 0.8875 - val_loss: 0.7174 - val_accuracy: 0.7500\n",
      "Epoch 539/2000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.2354 - accuracy: 0.9250 - val_loss: 0.7449 - val_accuracy: 0.7500\n",
      "Epoch 540/2000\n",
      "80/80 [==============================] - 0s 306us/sample - loss: 0.2434 - accuracy: 0.9125 - val_loss: 0.7088 - val_accuracy: 0.7500\n",
      "Epoch 541/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2416 - accuracy: 0.9000 - val_loss: 0.7016 - val_accuracy: 0.7500\n",
      "Epoch 542/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2409 - accuracy: 0.9250 - val_loss: 0.7466 - val_accuracy: 0.7500\n",
      "Epoch 543/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2485 - accuracy: 0.9375 - val_loss: 0.6769 - val_accuracy: 0.7500\n",
      "Epoch 544/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2362 - accuracy: 0.9125 - val_loss: 0.7083 - val_accuracy: 0.7500\n",
      "Epoch 545/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.2390 - accuracy: 0.9000 - val_loss: 0.7054 - val_accuracy: 0.7500\n",
      "Epoch 546/2000\n",
      "80/80 [==============================] - 0s 235us/sample - loss: 0.2366 - accuracy: 0.9250 - val_loss: 0.6934 - val_accuracy: 0.7500\n",
      "Epoch 547/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2411 - accuracy: 0.9250 - val_loss: 0.6665 - val_accuracy: 0.7500\n",
      "Epoch 548/2000\n",
      "80/80 [==============================] - 0s 170us/sample - loss: 0.2364 - accuracy: 0.9375 - val_loss: 0.6891 - val_accuracy: 0.7500\n",
      "Epoch 549/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2344 - accuracy: 0.9375 - val_loss: 0.6850 - val_accuracy: 0.7500\n",
      "Epoch 550/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.2330 - accuracy: 0.9125 - val_loss: 0.6874 - val_accuracy: 0.7500\n",
      "Epoch 551/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.2543 - accuracy: 0.8750 - val_loss: 0.6868 - val_accuracy: 0.7500\n",
      "Epoch 552/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2392 - accuracy: 0.9375 - val_loss: 0.7624 - val_accuracy: 0.7500\n",
      "Epoch 553/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2476 - accuracy: 0.9375 - val_loss: 0.6731 - val_accuracy: 0.7500\n",
      "Epoch 554/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.2347 - accuracy: 0.9125 - val_loss: 0.6919 - val_accuracy: 0.7500\n",
      "Epoch 555/2000\n",
      "80/80 [==============================] - 0s 244us/sample - loss: 0.2409 - accuracy: 0.9000 - val_loss: 0.7050 - val_accuracy: 0.7500\n",
      "Epoch 556/2000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.2350 - accuracy: 0.9000 - val_loss: 0.7112 - val_accuracy: 0.8000\n",
      "Epoch 557/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2336 - accuracy: 0.9125 - val_loss: 0.7209 - val_accuracy: 0.8000\n",
      "Epoch 558/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2359 - accuracy: 0.9375 - val_loss: 0.7058 - val_accuracy: 0.7500\n",
      "Epoch 559/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2536 - accuracy: 0.8875 - val_loss: 0.6810 - val_accuracy: 0.7500\n",
      "Epoch 560/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2318 - accuracy: 0.8875 - val_loss: 0.7419 - val_accuracy: 0.7500\n",
      "Epoch 561/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2503 - accuracy: 0.9375 - val_loss: 0.7383 - val_accuracy: 0.7500\n",
      "Epoch 562/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.2648 - accuracy: 0.9000 - val_loss: 0.7014 - val_accuracy: 0.7500\n",
      "Epoch 563/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2421 - accuracy: 0.8875 - val_loss: 0.7754 - val_accuracy: 0.8000\n",
      "Epoch 564/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2411 - accuracy: 0.9375 - val_loss: 0.8498 - val_accuracy: 0.7000\n",
      "Epoch 565/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2559 - accuracy: 0.9375 - val_loss: 0.6965 - val_accuracy: 0.7500\n",
      "Epoch 566/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2332 - accuracy: 0.9125 - val_loss: 0.6707 - val_accuracy: 0.7500\n",
      "Epoch 567/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2477 - accuracy: 0.8875 - val_loss: 0.6790 - val_accuracy: 0.7500\n",
      "Epoch 568/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2384 - accuracy: 0.9000 - val_loss: 0.7577 - val_accuracy: 0.7500\n",
      "Epoch 569/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.2385 - accuracy: 0.9375 - val_loss: 0.7169 - val_accuracy: 0.8000\n",
      "Epoch 570/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.2361 - accuracy: 0.9000 - val_loss: 0.6943 - val_accuracy: 0.7500\n",
      "Epoch 571/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.2365 - accuracy: 0.9125 - val_loss: 0.7218 - val_accuracy: 0.8000\n",
      "Epoch 572/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2362 - accuracy: 0.9375 - val_loss: 0.7042 - val_accuracy: 0.7500\n",
      "Epoch 573/2000\n",
      "80/80 [==============================] - 0s 47us/sample - loss: 0.2356 - accuracy: 0.9375 - val_loss: 0.6890 - val_accuracy: 0.7500\n",
      "Epoch 574/2000\n",
      "80/80 [==============================] - 0s 593us/sample - loss: 0.2399 - accuracy: 0.9000 - val_loss: 0.6852 - val_accuracy: 0.7500\n",
      "Epoch 575/2000\n",
      "80/80 [==============================] - 0s 42us/sample - loss: 0.2408 - accuracy: 0.8875 - val_loss: 0.7260 - val_accuracy: 0.7500\n",
      "Epoch 576/2000\n",
      "80/80 [==============================] - 0s 7us/sample - loss: 0.2681 - accuracy: 0.9375 - val_loss: 0.8397 - val_accuracy: 0.7000\n",
      "Epoch 577/2000\n",
      "80/80 [==============================] - 0s 293us/sample - loss: 0.2451 - accuracy: 0.9250 - val_loss: 0.7450 - val_accuracy: 0.7500\n",
      "Epoch 578/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2764 - accuracy: 0.9000 - val_loss: 0.7268 - val_accuracy: 0.7500\n",
      "Epoch 579/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2475 - accuracy: 0.8750 - val_loss: 0.7502 - val_accuracy: 0.7500\n",
      "Epoch 580/2000\n",
      "80/80 [==============================] - 0s 164us/sample - loss: 0.2452 - accuracy: 0.9375 - val_loss: 0.7190 - val_accuracy: 0.7500\n",
      "Epoch 581/2000\n",
      "80/80 [==============================] - 0s 168us/sample - loss: 0.2303 - accuracy: 0.9250 - val_loss: 0.6732 - val_accuracy: 0.7500\n",
      "Epoch 582/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.2529 - accuracy: 0.8875 - val_loss: 0.6881 - val_accuracy: 0.7500\n",
      "Epoch 583/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2466 - accuracy: 0.9125 - val_loss: 0.7620 - val_accuracy: 0.7500\n",
      "Epoch 584/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2358 - accuracy: 0.9375 - val_loss: 0.7164 - val_accuracy: 0.7500\n",
      "Epoch 585/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2351 - accuracy: 0.9000 - val_loss: 0.6880 - val_accuracy: 0.7500\n",
      "Epoch 586/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2488 - accuracy: 0.9000 - val_loss: 0.6817 - val_accuracy: 0.7500\n",
      "Epoch 587/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2357 - accuracy: 0.9250 - val_loss: 0.6818 - val_accuracy: 0.7500\n",
      "Epoch 588/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.2323 - accuracy: 0.9125 - val_loss: 0.7070 - val_accuracy: 0.7500\n",
      "Epoch 589/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.2417 - accuracy: 0.9000 - val_loss: 0.7139 - val_accuracy: 0.7500\n",
      "Epoch 590/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.2488 - accuracy: 0.9000 - val_loss: 0.7290 - val_accuracy: 0.7500\n",
      "Epoch 591/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.2299 - accuracy: 0.9125 - val_loss: 0.6900 - val_accuracy: 0.7500\n",
      "Epoch 592/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.2715 - accuracy: 0.9000 - val_loss: 0.7008 - val_accuracy: 0.7500\n",
      "Epoch 593/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2445 - accuracy: 0.9250 - val_loss: 0.8788 - val_accuracy: 0.6000\n",
      "Epoch 594/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.2645 - accuracy: 0.9375 - val_loss: 0.7900 - val_accuracy: 0.7500\n",
      "Epoch 595/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2291 - accuracy: 0.9000 - val_loss: 0.7487 - val_accuracy: 0.7500\n",
      "Epoch 596/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2654 - accuracy: 0.9125 - val_loss: 0.6914 - val_accuracy: 0.7500\n",
      "Epoch 597/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2343 - accuracy: 0.9000 - val_loss: 0.7450 - val_accuracy: 0.7500\n",
      "Epoch 598/2000\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.2530 - accuracy: 0.9375 - val_loss: 0.7268 - val_accuracy: 0.7500\n",
      "Epoch 599/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2267 - accuracy: 0.9250 - val_loss: 0.6795 - val_accuracy: 0.7500\n",
      "Epoch 600/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2524 - accuracy: 0.9000 - val_loss: 0.7166 - val_accuracy: 0.7500\n",
      "Epoch 601/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2506 - accuracy: 0.8875 - val_loss: 0.8028 - val_accuracy: 0.7500\n",
      "Epoch 602/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2523 - accuracy: 0.9375 - val_loss: 0.7606 - val_accuracy: 0.8000\n",
      "Epoch 603/2000\n",
      "80/80 [==============================] - 0s 310us/sample - loss: 0.2257 - accuracy: 0.9125 - val_loss: 0.6903 - val_accuracy: 0.7500\n",
      "Epoch 604/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2544 - accuracy: 0.9000 - val_loss: 0.6733 - val_accuracy: 0.7500\n",
      "Epoch 605/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2371 - accuracy: 0.9000 - val_loss: 0.7134 - val_accuracy: 0.7500\n",
      "Epoch 606/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.2346 - accuracy: 0.9375 - val_loss: 0.7051 - val_accuracy: 0.8000\n",
      "Epoch 607/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2330 - accuracy: 0.9000 - val_loss: 0.7032 - val_accuracy: 0.7500\n",
      "Epoch 608/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.2318 - accuracy: 0.9125 - val_loss: 0.7209 - val_accuracy: 0.8000\n",
      "Epoch 609/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2315 - accuracy: 0.9125 - val_loss: 0.7185 - val_accuracy: 0.8000\n",
      "Epoch 610/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.2311 - accuracy: 0.9125 - val_loss: 0.6935 - val_accuracy: 0.7500\n",
      "Epoch 611/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2306 - accuracy: 0.9125 - val_loss: 0.6999 - val_accuracy: 0.7500\n",
      "Epoch 612/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2298 - accuracy: 0.9250 - val_loss: 0.6951 - val_accuracy: 0.7500\n",
      "Epoch 613/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2300 - accuracy: 0.9125 - val_loss: 0.6850 - val_accuracy: 0.7500\n",
      "Epoch 614/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2301 - accuracy: 0.9125 - val_loss: 0.6800 - val_accuracy: 0.7500\n",
      "Epoch 615/2000\n",
      "80/80 [==============================] - 0s 625us/sample - loss: 0.2323 - accuracy: 0.9125 - val_loss: 0.7104 - val_accuracy: 0.8000\n",
      "Epoch 616/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.2317 - accuracy: 0.9125 - val_loss: 0.6964 - val_accuracy: 0.7500\n",
      "Epoch 617/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2305 - accuracy: 0.8875 - val_loss: 0.6908 - val_accuracy: 0.7500\n",
      "Epoch 618/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2291 - accuracy: 0.9125 - val_loss: 0.6964 - val_accuracy: 0.8000\n",
      "Epoch 619/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2285 - accuracy: 0.9250 - val_loss: 0.7037 - val_accuracy: 0.7500\n",
      "Epoch 620/2000\n",
      "80/80 [==============================] - 0s 55us/sample - loss: 0.2380 - accuracy: 0.9250 - val_loss: 0.6879 - val_accuracy: 0.7500\n",
      "Epoch 621/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2328 - accuracy: 0.9125 - val_loss: 0.7169 - val_accuracy: 0.7500\n",
      "Epoch 622/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2387 - accuracy: 0.9125 - val_loss: 0.6945 - val_accuracy: 0.7500\n",
      "Epoch 623/2000\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.2306 - accuracy: 0.9000 - val_loss: 0.7219 - val_accuracy: 0.8000\n",
      "Epoch 624/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.2313 - accuracy: 0.9375 - val_loss: 0.7657 - val_accuracy: 0.7500\n",
      "Epoch 625/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2396 - accuracy: 0.9250 - val_loss: 0.7057 - val_accuracy: 0.7500\n",
      "Epoch 626/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2345 - accuracy: 0.8875 - val_loss: 0.6971 - val_accuracy: 0.8000\n",
      "Epoch 627/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2450 - accuracy: 0.9250 - val_loss: 0.7342 - val_accuracy: 0.7500\n",
      "Epoch 628/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2358 - accuracy: 0.9375 - val_loss: 0.6787 - val_accuracy: 0.7500\n",
      "Epoch 629/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2341 - accuracy: 0.9000 - val_loss: 0.6815 - val_accuracy: 0.7500\n",
      "Epoch 630/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.2326 - accuracy: 0.8875 - val_loss: 0.6867 - val_accuracy: 0.7500\n",
      "Epoch 631/2000\n",
      "80/80 [==============================] - 0s 166us/sample - loss: 0.2380 - accuracy: 0.9250 - val_loss: 0.7403 - val_accuracy: 0.7500\n",
      "Epoch 632/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.2430 - accuracy: 0.9375 - val_loss: 0.6958 - val_accuracy: 0.7500\n",
      "Epoch 633/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2386 - accuracy: 0.9125 - val_loss: 0.6774 - val_accuracy: 0.7500\n",
      "Epoch 634/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.2293 - accuracy: 0.9000 - val_loss: 0.7253 - val_accuracy: 0.7500\n",
      "Epoch 635/2000\n",
      "80/80 [==============================] - 0s 177us/sample - loss: 0.2312 - accuracy: 0.9375 - val_loss: 0.7327 - val_accuracy: 0.7500\n",
      "Epoch 636/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2295 - accuracy: 0.9375 - val_loss: 0.7096 - val_accuracy: 0.7500\n",
      "Epoch 637/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2351 - accuracy: 0.9000 - val_loss: 0.7162 - val_accuracy: 0.7500\n",
      "Epoch 638/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.2259 - accuracy: 0.9000 - val_loss: 0.7508 - val_accuracy: 0.7500\n",
      "Epoch 639/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2377 - accuracy: 0.9375 - val_loss: 0.7268 - val_accuracy: 0.7500\n",
      "Epoch 640/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2397 - accuracy: 0.9000 - val_loss: 0.6520 - val_accuracy: 0.7500\n",
      "Epoch 641/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2442 - accuracy: 0.9125 - val_loss: 0.6804 - val_accuracy: 0.7500\n",
      "Epoch 642/2000\n",
      "80/80 [==============================] - 0s 164us/sample - loss: 0.2303 - accuracy: 0.9375 - val_loss: 0.6456 - val_accuracy: 0.7500\n",
      "Epoch 643/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2338 - accuracy: 0.9125 - val_loss: 0.6663 - val_accuracy: 0.7500\n",
      "Epoch 644/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2289 - accuracy: 0.9125 - val_loss: 0.7079 - val_accuracy: 0.8000\n",
      "Epoch 645/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.2300 - accuracy: 0.9125 - val_loss: 0.6935 - val_accuracy: 0.8000\n",
      "Epoch 646/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.2254 - accuracy: 0.9125 - val_loss: 0.6513 - val_accuracy: 0.7500\n",
      "Epoch 647/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2353 - accuracy: 0.9000 - val_loss: 0.6466 - val_accuracy: 0.8000\n",
      "Epoch 648/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2298 - accuracy: 0.9125 - val_loss: 0.6699 - val_accuracy: 0.7500\n",
      "Epoch 649/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.2280 - accuracy: 0.9250 - val_loss: 0.6768 - val_accuracy: 0.8000\n",
      "Epoch 650/2000\n",
      "80/80 [==============================] - 0s 683us/sample - loss: 0.2254 - accuracy: 0.9125 - val_loss: 0.7056 - val_accuracy: 0.7500\n",
      "Epoch 651/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2268 - accuracy: 0.9125 - val_loss: 0.7174 - val_accuracy: 0.8000\n",
      "Epoch 652/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.2261 - accuracy: 0.9125 - val_loss: 0.6897 - val_accuracy: 0.7500\n",
      "Epoch 653/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.2288 - accuracy: 0.9000 - val_loss: 0.6607 - val_accuracy: 0.7500\n",
      "Epoch 654/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2333 - accuracy: 0.9125 - val_loss: 0.6509 - val_accuracy: 0.8000\n",
      "Epoch 655/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2287 - accuracy: 0.9125 - val_loss: 0.6568 - val_accuracy: 0.8000\n",
      "Epoch 656/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.2275 - accuracy: 0.9125 - val_loss: 0.7031 - val_accuracy: 0.8000\n",
      "Epoch 657/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2336 - accuracy: 0.9250 - val_loss: 0.7233 - val_accuracy: 0.8000\n",
      "Epoch 658/2000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.2328 - accuracy: 0.9250 - val_loss: 0.6925 - val_accuracy: 0.7500\n",
      "Epoch 659/2000\n",
      "80/80 [==============================] - 0s 248us/sample - loss: 0.2271 - accuracy: 0.9375 - val_loss: 0.6812 - val_accuracy: 0.7500\n",
      "Epoch 660/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.2493 - accuracy: 0.9125 - val_loss: 0.6621 - val_accuracy: 0.8000\n",
      "Epoch 661/2000\n",
      "80/80 [==============================] - 0s 69us/sample - loss: 0.2186 - accuracy: 0.9375 - val_loss: 0.7459 - val_accuracy: 0.7500\n",
      "Epoch 662/2000\n",
      "80/80 [==============================] - 0s 73us/sample - loss: 0.2465 - accuracy: 0.9375 - val_loss: 0.6983 - val_accuracy: 0.8000\n",
      "Epoch 663/2000\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 0.2440 - accuracy: 0.9125 - val_loss: 0.6788 - val_accuracy: 0.7500\n",
      "Epoch 664/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2335 - accuracy: 0.9000 - val_loss: 0.7165 - val_accuracy: 0.7500\n",
      "Epoch 665/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2289 - accuracy: 0.9375 - val_loss: 0.8053 - val_accuracy: 0.7000\n",
      "Epoch 666/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.2514 - accuracy: 0.9375 - val_loss: 0.6966 - val_accuracy: 0.7500\n",
      "Epoch 667/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.2321 - accuracy: 0.8875 - val_loss: 0.7056 - val_accuracy: 0.7500\n",
      "Epoch 668/2000\n",
      "80/80 [==============================] - 0s 62us/sample - loss: 0.2312 - accuracy: 0.8875 - val_loss: 0.7470 - val_accuracy: 0.8000\n",
      "Epoch 669/2000\n",
      "80/80 [==============================] - 0s 175us/sample - loss: 0.2332 - accuracy: 0.9250 - val_loss: 0.7701 - val_accuracy: 0.8000\n",
      "Epoch 670/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.2358 - accuracy: 0.9375 - val_loss: 0.7450 - val_accuracy: 0.8000\n",
      "Epoch 671/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.2304 - accuracy: 0.9375 - val_loss: 0.6986 - val_accuracy: 0.8000\n",
      "Epoch 672/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2235 - accuracy: 0.9125 - val_loss: 0.6640 - val_accuracy: 0.7500\n",
      "Epoch 673/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2290 - accuracy: 0.9000 - val_loss: 0.6532 - val_accuracy: 0.8000\n",
      "Epoch 674/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.2290 - accuracy: 0.9125 - val_loss: 0.6921 - val_accuracy: 0.7500\n",
      "Epoch 675/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2615 - accuracy: 0.9250 - val_loss: 0.7583 - val_accuracy: 0.7500\n",
      "Epoch 676/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2287 - accuracy: 0.9250 - val_loss: 0.7054 - val_accuracy: 0.7500\n",
      "Epoch 677/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2797 - accuracy: 0.9250 - val_loss: 0.7027 - val_accuracy: 0.7500\n",
      "Epoch 678/2000\n",
      "80/80 [==============================] - 0s 73us/sample - loss: 0.2307 - accuracy: 0.9125 - val_loss: 0.8487 - val_accuracy: 0.7000\n",
      "Epoch 679/2000\n",
      "80/80 [==============================] - 0s 282us/sample - loss: 0.2642 - accuracy: 0.9375 - val_loss: 0.7227 - val_accuracy: 0.7500\n",
      "Epoch 680/2000\n",
      "80/80 [==============================] - 0s 175us/sample - loss: 0.2249 - accuracy: 0.9250 - val_loss: 0.7084 - val_accuracy: 0.7500\n",
      "Epoch 681/2000\n",
      "80/80 [==============================] - 0s 172us/sample - loss: 0.2507 - accuracy: 0.9000 - val_loss: 0.7019 - val_accuracy: 0.7500\n",
      "Epoch 682/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.2421 - accuracy: 0.9125 - val_loss: 0.7680 - val_accuracy: 0.7500\n",
      "Epoch 683/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.2359 - accuracy: 0.9375 - val_loss: 0.6773 - val_accuracy: 0.8000\n",
      "Epoch 684/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.2252 - accuracy: 0.9000 - val_loss: 0.6454 - val_accuracy: 0.7500\n",
      "Epoch 685/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2315 - accuracy: 0.9125 - val_loss: 0.6600 - val_accuracy: 0.8000\n",
      "Epoch 686/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2321 - accuracy: 0.8875 - val_loss: 0.6510 - val_accuracy: 0.7500\n",
      "Epoch 687/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2228 - accuracy: 0.9125 - val_loss: 0.6796 - val_accuracy: 0.7500\n",
      "Epoch 688/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.2281 - accuracy: 0.9375 - val_loss: 0.6762 - val_accuracy: 0.8000\n",
      "Epoch 689/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2359 - accuracy: 0.9000 - val_loss: 0.6726 - val_accuracy: 0.8000\n",
      "Epoch 690/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2358 - accuracy: 0.9125 - val_loss: 0.7126 - val_accuracy: 0.7500\n",
      "Epoch 691/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.2263 - accuracy: 0.9375 - val_loss: 0.6652 - val_accuracy: 0.7500\n",
      "Epoch 692/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2428 - accuracy: 0.9000 - val_loss: 0.6683 - val_accuracy: 0.7500\n",
      "Epoch 693/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2299 - accuracy: 0.9125 - val_loss: 0.7615 - val_accuracy: 0.7500\n",
      "Epoch 694/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.2334 - accuracy: 0.9250 - val_loss: 0.7297 - val_accuracy: 0.7500\n",
      "Epoch 695/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2301 - accuracy: 0.9125 - val_loss: 0.6912 - val_accuracy: 0.7500\n",
      "Epoch 696/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2354 - accuracy: 0.8875 - val_loss: 0.6447 - val_accuracy: 0.7500\n",
      "Epoch 697/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2327 - accuracy: 0.9125 - val_loss: 0.6782 - val_accuracy: 0.7500\n",
      "Epoch 698/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2382 - accuracy: 0.9375 - val_loss: 0.6725 - val_accuracy: 0.8000\n",
      "Epoch 699/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.2235 - accuracy: 0.9375 - val_loss: 0.6602 - val_accuracy: 0.7500\n",
      "Epoch 700/2000\n",
      "80/80 [==============================] - 0s 282us/sample - loss: 0.2334 - accuracy: 0.9000 - val_loss: 0.6699 - val_accuracy: 0.7500\n",
      "Epoch 701/2000\n",
      "80/80 [==============================] - 0s 37us/sample - loss: 0.2264 - accuracy: 0.9000 - val_loss: 0.7108 - val_accuracy: 0.7500\n",
      "Epoch 702/2000\n",
      "80/80 [==============================] - 0s 188us/sample - loss: 0.2391 - accuracy: 0.9375 - val_loss: 0.7131 - val_accuracy: 0.7500\n",
      "Epoch 703/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2476 - accuracy: 0.9000 - val_loss: 0.6637 - val_accuracy: 0.7500\n",
      "Epoch 704/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2219 - accuracy: 0.9000 - val_loss: 0.7326 - val_accuracy: 0.7500\n",
      "Epoch 705/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2421 - accuracy: 0.9375 - val_loss: 0.7912 - val_accuracy: 0.7500\n",
      "Epoch 706/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2480 - accuracy: 0.9375 - val_loss: 0.7229 - val_accuracy: 0.7500\n",
      "Epoch 707/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2328 - accuracy: 0.8875 - val_loss: 0.7093 - val_accuracy: 0.7500\n",
      "Epoch 708/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2391 - accuracy: 0.9250 - val_loss: 0.7247 - val_accuracy: 0.7500\n",
      "Epoch 709/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.2314 - accuracy: 0.9250 - val_loss: 0.6538 - val_accuracy: 0.8000\n",
      "Epoch 710/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2340 - accuracy: 0.9125 - val_loss: 0.6550 - val_accuracy: 0.8000\n",
      "Epoch 711/2000\n",
      "80/80 [==============================] - 0s 465us/sample - loss: 0.2263 - accuracy: 0.9125 - val_loss: 0.6533 - val_accuracy: 0.8000\n",
      "Epoch 712/2000\n",
      "80/80 [==============================] - 0s 160us/sample - loss: 0.2250 - accuracy: 0.9125 - val_loss: 0.6686 - val_accuracy: 0.8000\n",
      "Epoch 713/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.2227 - accuracy: 0.9250 - val_loss: 0.6829 - val_accuracy: 0.7500\n",
      "Epoch 714/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2252 - accuracy: 0.9250 - val_loss: 0.6732 - val_accuracy: 0.8000\n",
      "Epoch 715/2000\n",
      "80/80 [==============================] - 0s 69us/sample - loss: 0.2230 - accuracy: 0.9125 - val_loss: 0.6862 - val_accuracy: 0.8000\n",
      "Epoch 716/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2237 - accuracy: 0.9250 - val_loss: 0.6651 - val_accuracy: 0.8000\n",
      "Epoch 717/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2268 - accuracy: 0.9125 - val_loss: 0.6388 - val_accuracy: 0.8000\n",
      "Epoch 718/2000\n",
      "80/80 [==============================] - 0s 172us/sample - loss: 0.2233 - accuracy: 0.9250 - val_loss: 0.6864 - val_accuracy: 0.7500\n",
      "Epoch 719/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.2297 - accuracy: 0.9375 - val_loss: 0.7103 - val_accuracy: 0.8000\n",
      "Epoch 720/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2241 - accuracy: 0.9250 - val_loss: 0.6863 - val_accuracy: 0.7500\n",
      "Epoch 721/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2442 - accuracy: 0.8875 - val_loss: 0.6782 - val_accuracy: 0.7500\n",
      "Epoch 722/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2348 - accuracy: 0.9125 - val_loss: 0.7528 - val_accuracy: 0.7500\n",
      "Epoch 723/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2342 - accuracy: 0.9375 - val_loss: 0.6368 - val_accuracy: 0.7500\n",
      "Epoch 724/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2207 - accuracy: 0.9000 - val_loss: 0.6513 - val_accuracy: 0.7500\n",
      "Epoch 725/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.2520 - accuracy: 0.9000 - val_loss: 0.6879 - val_accuracy: 0.7500\n",
      "Epoch 726/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2307 - accuracy: 0.9000 - val_loss: 0.7247 - val_accuracy: 0.8000\n",
      "Epoch 727/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2292 - accuracy: 0.9375 - val_loss: 0.6572 - val_accuracy: 0.8000\n",
      "Epoch 728/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2223 - accuracy: 0.9125 - val_loss: 0.6415 - val_accuracy: 0.7500\n",
      "Epoch 729/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.2275 - accuracy: 0.9250 - val_loss: 0.6152 - val_accuracy: 0.8000\n",
      "Epoch 730/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.2249 - accuracy: 0.9250 - val_loss: 0.6191 - val_accuracy: 0.7500\n",
      "Epoch 731/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.2258 - accuracy: 0.9250 - val_loss: 0.6818 - val_accuracy: 0.8000\n",
      "Epoch 732/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2276 - accuracy: 0.9250 - val_loss: 0.7154 - val_accuracy: 0.7500\n",
      "Epoch 733/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2225 - accuracy: 0.9250 - val_loss: 0.6749 - val_accuracy: 0.7500\n",
      "Epoch 734/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2272 - accuracy: 0.9000 - val_loss: 0.6775 - val_accuracy: 0.7500\n",
      "Epoch 735/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2227 - accuracy: 0.9250 - val_loss: 0.7172 - val_accuracy: 0.7500\n",
      "Epoch 736/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.2238 - accuracy: 0.9250 - val_loss: 0.6721 - val_accuracy: 0.7500\n",
      "Epoch 737/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.2217 - accuracy: 0.9250 - val_loss: 0.6378 - val_accuracy: 0.7500\n",
      "Epoch 738/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2269 - accuracy: 0.9250 - val_loss: 0.6382 - val_accuracy: 0.7500\n",
      "Epoch 739/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2248 - accuracy: 0.9125 - val_loss: 0.6883 - val_accuracy: 0.8000\n",
      "Epoch 740/2000\n",
      "80/80 [==============================] - 0s 156us/sample - loss: 0.2235 - accuracy: 0.9125 - val_loss: 0.7035 - val_accuracy: 0.8000\n",
      "Epoch 741/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2275 - accuracy: 0.9375 - val_loss: 0.6833 - val_accuracy: 0.8000\n",
      "Epoch 742/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.2595 - accuracy: 0.87 - 0s 194us/sample - loss: 0.2267 - accuracy: 0.9000 - val_loss: 0.6278 - val_accuracy: 0.7500\n",
      "Epoch 743/2000\n",
      "80/80 [==============================] - 0s 307us/sample - loss: 0.2288 - accuracy: 0.9125 - val_loss: 0.6485 - val_accuracy: 0.7500\n",
      "Epoch 744/2000\n",
      "80/80 [==============================] - 0s 228us/sample - loss: 0.2322 - accuracy: 0.9250 - val_loss: 0.6741 - val_accuracy: 0.7500\n",
      "Epoch 745/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2326 - accuracy: 0.9250 - val_loss: 0.6470 - val_accuracy: 0.7500\n",
      "Epoch 746/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2228 - accuracy: 0.9125 - val_loss: 0.6926 - val_accuracy: 0.7500\n",
      "Epoch 747/2000\n",
      "80/80 [==============================] - 0s 175us/sample - loss: 0.2292 - accuracy: 0.9375 - val_loss: 0.7689 - val_accuracy: 0.7500\n",
      "Epoch 748/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2398 - accuracy: 0.9250 - val_loss: 0.6910 - val_accuracy: 0.7500\n",
      "Epoch 749/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.2299 - accuracy: 0.8875 - val_loss: 0.6703 - val_accuracy: 0.7500\n",
      "Epoch 750/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2208 - accuracy: 0.9125 - val_loss: 0.6879 - val_accuracy: 0.7500\n",
      "Epoch 751/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.2280 - accuracy: 0.9375 - val_loss: 0.6596 - val_accuracy: 0.7500\n",
      "Epoch 752/2000\n",
      "80/80 [==============================] - 0s 248us/sample - loss: 0.2171 - accuracy: 0.9125 - val_loss: 0.6234 - val_accuracy: 0.7500\n",
      "Epoch 753/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2284 - accuracy: 0.9125 - val_loss: 0.6359 - val_accuracy: 0.8000\n",
      "Epoch 754/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.2178 - accuracy: 0.9125 - val_loss: 0.6872 - val_accuracy: 0.7500\n",
      "Epoch 755/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2321 - accuracy: 0.9375 - val_loss: 0.6955 - val_accuracy: 0.8000\n",
      "Epoch 756/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2140 - accuracy: 0.9125 - val_loss: 0.6618 - val_accuracy: 0.7500\n",
      "Epoch 757/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2506 - accuracy: 0.9000 - val_loss: 0.6565 - val_accuracy: 0.7500\n",
      "Epoch 758/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2192 - accuracy: 0.9125 - val_loss: 0.7613 - val_accuracy: 0.8000\n",
      "Epoch 759/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2433 - accuracy: 0.9375 - val_loss: 0.6664 - val_accuracy: 0.8000\n",
      "Epoch 760/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2404 - accuracy: 0.9000 - val_loss: 0.6783 - val_accuracy: 0.7500\n",
      "Epoch 761/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2415 - accuracy: 0.8875 - val_loss: 0.7719 - val_accuracy: 0.8000\n",
      "Epoch 762/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2328 - accuracy: 0.9250 - val_loss: 0.7518 - val_accuracy: 0.8000\n",
      "Epoch 763/2000\n",
      "80/80 [==============================] - 0s 69us/sample - loss: 0.2268 - accuracy: 0.9125 - val_loss: 0.6793 - val_accuracy: 0.7500\n",
      "Epoch 764/2000\n",
      "80/80 [==============================] - 0s 204us/sample - loss: 0.2266 - accuracy: 0.8875 - val_loss: 0.6319 - val_accuracy: 0.8000\n",
      "Epoch 765/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2268 - accuracy: 0.9250 - val_loss: 0.6182 - val_accuracy: 0.7500\n",
      "Epoch 766/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2198 - accuracy: 0.9375 - val_loss: 0.5969 - val_accuracy: 0.8000\n",
      "Epoch 767/2000\n",
      "80/80 [==============================] - 0s 156us/sample - loss: 0.2290 - accuracy: 0.9250 - val_loss: 0.6453 - val_accuracy: 0.8000\n",
      "Epoch 768/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2309 - accuracy: 0.9250 - val_loss: 0.7213 - val_accuracy: 0.7500\n",
      "Epoch 769/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.2838 - accuracy: 0.87 - 0s 91us/sample - loss: 0.2301 - accuracy: 0.9375 - val_loss: 0.6520 - val_accuracy: 0.7500\n",
      "Epoch 770/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2237 - accuracy: 0.9250 - val_loss: 0.6464 - val_accuracy: 0.8000\n",
      "Epoch 771/2000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.2235 - accuracy: 0.9125 - val_loss: 0.6706 - val_accuracy: 0.8000\n",
      "Epoch 772/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.2296 - accuracy: 0.9000 - val_loss: 0.6760 - val_accuracy: 0.7500\n",
      "Epoch 773/2000\n",
      "80/80 [==============================] - 0s 692us/sample - loss: 0.2425 - accuracy: 0.9125 - val_loss: 0.7602 - val_accuracy: 0.7500\n",
      "Epoch 774/2000\n",
      "80/80 [==============================] - 0s 219us/sample - loss: 0.2317 - accuracy: 0.9375 - val_loss: 0.6898 - val_accuracy: 0.7500\n",
      "Epoch 775/2000\n",
      "80/80 [==============================] - 0s 163us/sample - loss: 0.2276 - accuracy: 0.9125 - val_loss: 0.6693 - val_accuracy: 0.7500\n",
      "Epoch 776/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2472 - accuracy: 0.9000 - val_loss: 0.6741 - val_accuracy: 0.7500\n",
      "Epoch 777/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.2268 - accuracy: 0.9250 - val_loss: 0.6638 - val_accuracy: 0.7500\n",
      "Epoch 778/2000\n",
      "80/80 [==============================] - 0s 32us/sample - loss: 0.2241 - accuracy: 0.9125 - val_loss: 0.6469 - val_accuracy: 0.8000\n",
      "Epoch 779/2000\n",
      "80/80 [==============================] - 0s 223us/sample - loss: 0.2257 - accuracy: 0.9125 - val_loss: 0.6789 - val_accuracy: 0.7500\n",
      "Epoch 780/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2217 - accuracy: 0.9250 - val_loss: 0.6498 - val_accuracy: 0.8000\n",
      "Epoch 781/2000\n",
      "80/80 [==============================] - 0s 71us/sample - loss: 0.2214 - accuracy: 0.9250 - val_loss: 0.6703 - val_accuracy: 0.7500\n",
      "Epoch 782/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.2212 - accuracy: 0.9125 - val_loss: 0.7337 - val_accuracy: 0.7500\n",
      "Epoch 783/2000\n",
      "80/80 [==============================] - 0s 151us/sample - loss: 0.2234 - accuracy: 0.9375 - val_loss: 0.7432 - val_accuracy: 0.8000\n",
      "Epoch 784/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 0.2251 - accuracy: 0.9375 - val_loss: 0.7083 - val_accuracy: 0.7500\n",
      "Epoch 785/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2285 - accuracy: 0.9000 - val_loss: 0.6661 - val_accuracy: 0.7500\n",
      "Epoch 786/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2262 - accuracy: 0.9125 - val_loss: 0.6678 - val_accuracy: 0.7500\n",
      "Epoch 787/2000\n",
      "80/80 [==============================] - 0s 209us/sample - loss: 0.2213 - accuracy: 0.9250 - val_loss: 0.6689 - val_accuracy: 0.7500\n",
      "Epoch 788/2000\n",
      "80/80 [==============================] - 0s 198us/sample - loss: 0.2267 - accuracy: 0.9375 - val_loss: 0.6742 - val_accuracy: 0.8000\n",
      "Epoch 789/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2214 - accuracy: 0.9000 - val_loss: 0.6728 - val_accuracy: 0.7500\n",
      "Epoch 790/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2289 - accuracy: 0.8875 - val_loss: 0.6623 - val_accuracy: 0.7500\n",
      "Epoch 791/2000\n",
      "80/80 [==============================] - 0s 177us/sample - loss: 0.2189 - accuracy: 0.9250 - val_loss: 0.6934 - val_accuracy: 0.7500\n",
      "Epoch 792/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2247 - accuracy: 0.9250 - val_loss: 0.6243 - val_accuracy: 0.8000\n",
      "Epoch 793/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2183 - accuracy: 0.9125 - val_loss: 0.6161 - val_accuracy: 0.8000\n",
      "Epoch 794/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2187 - accuracy: 0.9125 - val_loss: 0.6552 - val_accuracy: 0.7500\n",
      "Epoch 795/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2292 - accuracy: 0.9250 - val_loss: 0.6629 - val_accuracy: 0.8000\n",
      "Epoch 796/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2290 - accuracy: 0.9000 - val_loss: 0.6373 - val_accuracy: 0.7500\n",
      "Epoch 797/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2293 - accuracy: 0.9000 - val_loss: 0.6641 - val_accuracy: 0.8000\n",
      "Epoch 798/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.2179 - accuracy: 0.9250 - val_loss: 0.6646 - val_accuracy: 0.8000\n",
      "Epoch 799/2000\n",
      "80/80 [==============================] - 0s 624us/sample - loss: 0.2220 - accuracy: 0.9250 - val_loss: 0.6447 - val_accuracy: 0.8000\n",
      "Epoch 800/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2194 - accuracy: 0.9125 - val_loss: 0.6410 - val_accuracy: 0.8000\n",
      "Epoch 801/2000\n",
      "80/80 [==============================] - 0s 164us/sample - loss: 0.2240 - accuracy: 0.9125 - val_loss: 0.6852 - val_accuracy: 0.8000\n",
      "Epoch 802/2000\n",
      "80/80 [==============================] - 0s 164us/sample - loss: 0.2176 - accuracy: 0.9125 - val_loss: 0.6650 - val_accuracy: 0.7500\n",
      "Epoch 803/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2228 - accuracy: 0.8875 - val_loss: 0.6465 - val_accuracy: 0.7500\n",
      "Epoch 804/2000\n",
      "80/80 [==============================] - 0s 235us/sample - loss: 0.2223 - accuracy: 0.9125 - val_loss: 0.6739 - val_accuracy: 0.7500\n",
      "Epoch 805/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2197 - accuracy: 0.9375 - val_loss: 0.6466 - val_accuracy: 0.8000\n",
      "Epoch 806/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.2187 - accuracy: 0.9125 - val_loss: 0.6452 - val_accuracy: 0.8000\n",
      "Epoch 807/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2185 - accuracy: 0.9125 - val_loss: 0.6850 - val_accuracy: 0.7500\n",
      "Epoch 808/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2201 - accuracy: 0.9375 - val_loss: 0.6794 - val_accuracy: 0.8000\n",
      "Epoch 809/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.2155 - accuracy: 0.9125 - val_loss: 0.6654 - val_accuracy: 0.8000\n",
      "Epoch 810/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2191 - accuracy: 0.9125 - val_loss: 0.6534 - val_accuracy: 0.8000\n",
      "Epoch 811/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 0.2213 - accuracy: 0.9125 - val_loss: 0.6620 - val_accuracy: 0.7500\n",
      "Epoch 812/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.2174 - accuracy: 0.9125 - val_loss: 0.6825 - val_accuracy: 0.7500\n",
      "Epoch 813/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2173 - accuracy: 0.9250 - val_loss: 0.6661 - val_accuracy: 0.7500\n",
      "Epoch 814/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2254 - accuracy: 0.9250 - val_loss: 0.6348 - val_accuracy: 0.7500\n",
      "Epoch 815/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2184 - accuracy: 0.9250 - val_loss: 0.6920 - val_accuracy: 0.7500\n",
      "Epoch 816/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2278 - accuracy: 0.9375 - val_loss: 0.6790 - val_accuracy: 0.8000\n",
      "Epoch 817/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2174 - accuracy: 0.9125 - val_loss: 0.6914 - val_accuracy: 0.7500\n",
      "Epoch 818/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2332 - accuracy: 0.8875 - val_loss: 0.6967 - val_accuracy: 0.7500\n",
      "Epoch 819/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2313 - accuracy: 0.9125 - val_loss: 0.6677 - val_accuracy: 0.7500\n",
      "Epoch 820/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2386 - accuracy: 0.9000 - val_loss: 0.6254 - val_accuracy: 0.7500\n",
      "Epoch 821/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2244 - accuracy: 0.9125 - val_loss: 0.6620 - val_accuracy: 0.7500\n",
      "Epoch 822/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2205 - accuracy: 0.9250 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
      "Epoch 823/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2234 - accuracy: 0.9250 - val_loss: 0.6644 - val_accuracy: 0.8000\n",
      "Epoch 824/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2321 - accuracy: 0.8875 - val_loss: 0.6510 - val_accuracy: 0.7500\n",
      "Epoch 825/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2177 - accuracy: 0.9125 - val_loss: 0.6837 - val_accuracy: 0.7500\n",
      "Epoch 826/2000\n",
      "80/80 [==============================] - 0s 197us/sample - loss: 0.2253 - accuracy: 0.9250 - val_loss: 0.6363 - val_accuracy: 0.8000\n",
      "Epoch 827/2000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.2174 - accuracy: 0.9250 - val_loss: 0.6198 - val_accuracy: 0.8000\n",
      "Epoch 828/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.2212 - accuracy: 0.9125 - val_loss: 0.6457 - val_accuracy: 0.7500\n",
      "Epoch 829/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2177 - accuracy: 0.9125 - val_loss: 0.6981 - val_accuracy: 0.8000\n",
      "Epoch 830/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2252 - accuracy: 0.9125 - val_loss: 0.6864 - val_accuracy: 0.8000\n",
      "Epoch 831/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2200 - accuracy: 0.9125 - val_loss: 0.6668 - val_accuracy: 0.7500\n",
      "Epoch 832/2000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.2176 - accuracy: 0.9125 - val_loss: 0.6207 - val_accuracy: 0.8000\n",
      "Epoch 833/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2194 - accuracy: 0.9125 - val_loss: 0.6017 - val_accuracy: 0.8000\n",
      "Epoch 834/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.2388 - accuracy: 0.9250 - val_loss: 0.6087 - val_accuracy: 0.8000\n",
      "Epoch 835/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.2359 - accuracy: 0.9250 - val_loss: 0.6368 - val_accuracy: 0.7500\n",
      "Epoch 836/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2174 - accuracy: 0.9250 - val_loss: 0.7908 - val_accuracy: 0.7500\n",
      "Epoch 837/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.2874 - accuracy: 0.9250 - val_loss: 0.8450 - val_accuracy: 0.7500\n",
      "Epoch 838/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2329 - accuracy: 0.9250 - val_loss: 0.7422 - val_accuracy: 0.7500\n",
      "Epoch 839/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2615 - accuracy: 0.9250 - val_loss: 0.6628 - val_accuracy: 0.7500\n",
      "Epoch 840/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.2282 - accuracy: 0.9125 - val_loss: 0.7203 - val_accuracy: 0.7500\n",
      "Epoch 841/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2276 - accuracy: 0.9375 - val_loss: 0.6420 - val_accuracy: 0.8000\n",
      "Epoch 842/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2190 - accuracy: 0.9250 - val_loss: 0.6405 - val_accuracy: 0.7500\n",
      "Epoch 843/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2194 - accuracy: 0.9250 - val_loss: 0.6805 - val_accuracy: 0.7500\n",
      "Epoch 844/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2182 - accuracy: 0.9375 - val_loss: 0.7319 - val_accuracy: 0.7500\n",
      "Epoch 845/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.2233 - accuracy: 0.9375 - val_loss: 0.6595 - val_accuracy: 0.8000\n",
      "Epoch 846/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 0.2483 - accuracy: 0.9250 - val_loss: 0.6423 - val_accuracy: 0.7500\n",
      "Epoch 847/2000\n",
      "80/80 [==============================] - 0s 281us/sample - loss: 0.2187 - accuracy: 0.8875 - val_loss: 0.6941 - val_accuracy: 0.7500\n",
      "Epoch 848/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2243 - accuracy: 0.9375 - val_loss: 0.7021 - val_accuracy: 0.7500\n",
      "Epoch 849/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2301 - accuracy: 0.9375 - val_loss: 0.6188 - val_accuracy: 0.8000\n",
      "Epoch 850/2000\n",
      "80/80 [==============================] - 0s 55us/sample - loss: 0.2207 - accuracy: 0.9250 - val_loss: 0.6335 - val_accuracy: 0.7500\n",
      "Epoch 851/2000\n",
      "80/80 [==============================] - 0s 236us/sample - loss: 0.2140 - accuracy: 0.9250 - val_loss: 0.6713 - val_accuracy: 0.7500\n",
      "Epoch 852/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2217 - accuracy: 0.9375 - val_loss: 0.6695 - val_accuracy: 0.7500\n",
      "Epoch 853/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2247 - accuracy: 0.9125 - val_loss: 0.6375 - val_accuracy: 0.7500\n",
      "Epoch 854/2000\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 0.2219 - accuracy: 0.9125 - val_loss: 0.6729 - val_accuracy: 0.7500\n",
      "Epoch 855/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2174 - accuracy: 0.9375 - val_loss: 0.7423 - val_accuracy: 0.7500\n",
      "Epoch 856/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2279 - accuracy: 0.9250 - val_loss: 0.6730 - val_accuracy: 0.8000\n",
      "Epoch 857/2000\n",
      "80/80 [==============================] - 0s 688us/sample - loss: 0.2158 - accuracy: 0.9125 - val_loss: 0.6635 - val_accuracy: 0.7500\n",
      "Epoch 858/2000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.2201 - accuracy: 0.9125 - val_loss: 0.6748 - val_accuracy: 0.8000\n",
      "Epoch 859/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2209 - accuracy: 0.9125 - val_loss: 0.6961 - val_accuracy: 0.7500\n",
      "Epoch 860/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.2221 - accuracy: 0.9250 - val_loss: 0.6376 - val_accuracy: 0.8000\n",
      "Epoch 861/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.2130 - accuracy: 0.9250 - val_loss: 0.6616 - val_accuracy: 0.7500\n",
      "Epoch 862/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.2189 - accuracy: 0.9375 - val_loss: 0.6801 - val_accuracy: 0.7500\n",
      "Epoch 863/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2148 - accuracy: 0.9250 - val_loss: 0.6344 - val_accuracy: 0.7500\n",
      "Epoch 864/2000\n",
      "80/80 [==============================] - 0s 184us/sample - loss: 0.2236 - accuracy: 0.9125 - val_loss: 0.6352 - val_accuracy: 0.7500\n",
      "Epoch 865/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2250 - accuracy: 0.9000 - val_loss: 0.6262 - val_accuracy: 0.7500\n",
      "Epoch 866/2000\n",
      "80/80 [==============================] - 0s 208us/sample - loss: 0.2248 - accuracy: 0.9125 - val_loss: 0.6919 - val_accuracy: 0.7500\n",
      "Epoch 867/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.2155 - accuracy: 0.9250 - val_loss: 0.6448 - val_accuracy: 0.7500\n",
      "Epoch 868/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 0.2285 - accuracy: 0.9125 - val_loss: 0.6287 - val_accuracy: 0.7500\n",
      "Epoch 869/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2219 - accuracy: 0.9125 - val_loss: 0.6528 - val_accuracy: 0.7500\n",
      "Epoch 870/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2190 - accuracy: 0.9250 - val_loss: 0.6172 - val_accuracy: 0.8000\n",
      "Epoch 871/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2213 - accuracy: 0.9125 - val_loss: 0.6431 - val_accuracy: 0.7500\n",
      "Epoch 872/2000\n",
      "80/80 [==============================] - 0s 178us/sample - loss: 0.2223 - accuracy: 0.9000 - val_loss: 0.7170 - val_accuracy: 0.8000\n",
      "Epoch 873/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2248 - accuracy: 0.9250 - val_loss: 0.7196 - val_accuracy: 0.8000\n",
      "Epoch 874/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2241 - accuracy: 0.9125 - val_loss: 0.6362 - val_accuracy: 0.7500\n",
      "Epoch 875/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2188 - accuracy: 0.9250 - val_loss: 0.6285 - val_accuracy: 0.7500\n",
      "Epoch 876/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.2240 - accuracy: 0.9125 - val_loss: 0.6141 - val_accuracy: 0.7500\n",
      "Epoch 877/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2338 - accuracy: 0.9250 - val_loss: 0.6593 - val_accuracy: 0.7500\n",
      "Epoch 878/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2092 - accuracy: 0.9250 - val_loss: 0.6743 - val_accuracy: 0.7500\n",
      "Epoch 879/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.2436 - accuracy: 0.9125 - val_loss: 0.6879 - val_accuracy: 0.7500\n",
      "Epoch 880/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.2110 - accuracy: 0.9000 - val_loss: 0.7491 - val_accuracy: 0.7500\n",
      "Epoch 881/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2406 - accuracy: 0.9375 - val_loss: 0.6875 - val_accuracy: 0.7500\n",
      "Epoch 882/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2163 - accuracy: 0.9250 - val_loss: 0.6524 - val_accuracy: 0.7500\n",
      "Epoch 883/2000\n",
      "80/80 [==============================] - 0s 612us/sample - loss: 0.2332 - accuracy: 0.9250 - val_loss: 0.6883 - val_accuracy: 0.8000\n",
      "Epoch 884/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2401 - accuracy: 0.9250 - val_loss: 0.7586 - val_accuracy: 0.7500\n",
      "Epoch 885/2000\n",
      "80/80 [==============================] - 0s 164us/sample - loss: 0.2214 - accuracy: 0.9250 - val_loss: 0.7275 - val_accuracy: 0.7500\n",
      "Epoch 886/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.2205 - accuracy: 0.8875 - val_loss: 0.7202 - val_accuracy: 0.7500\n",
      "Epoch 887/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2172 - accuracy: 0.9000 - val_loss: 0.7046 - val_accuracy: 0.7500\n",
      "Epoch 888/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2170 - accuracy: 0.9250 - val_loss: 0.6863 - val_accuracy: 0.7500\n",
      "Epoch 889/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2295 - accuracy: 0.9125 - val_loss: 0.6371 - val_accuracy: 0.7500\n",
      "Epoch 890/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.2174 - accuracy: 0.9250 - val_loss: 0.6756 - val_accuracy: 0.8000\n",
      "Epoch 891/2000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.2187 - accuracy: 0.9375 - val_loss: 0.7258 - val_accuracy: 0.7500\n",
      "Epoch 892/2000\n",
      "80/80 [==============================] - 0s 303us/sample - loss: 0.2227 - accuracy: 0.9250 - val_loss: 0.6717 - val_accuracy: 0.8000\n",
      "Epoch 893/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.2140 - accuracy: 0.9125 - val_loss: 0.6367 - val_accuracy: 0.8000\n",
      "Epoch 894/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2137 - accuracy: 0.9125 - val_loss: 0.6216 - val_accuracy: 0.8000\n",
      "Epoch 895/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.2185 - accuracy: 0.9250 - val_loss: 0.6337 - val_accuracy: 0.7500\n",
      "Epoch 896/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2153 - accuracy: 0.9250 - val_loss: 0.6229 - val_accuracy: 0.7500\n",
      "Epoch 897/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.2155 - accuracy: 0.9250 - val_loss: 0.6589 - val_accuracy: 0.8000\n",
      "Epoch 898/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.2508 - accuracy: 0.9250 - val_loss: 0.7059 - val_accuracy: 0.7500\n",
      "Epoch 899/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2155 - accuracy: 0.9250 - val_loss: 0.6551 - val_accuracy: 0.7500\n",
      "Epoch 900/2000\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 0.2597 - accuracy: 0.9375 - val_loss: 0.6647 - val_accuracy: 0.7500\n",
      "Epoch 901/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.2240 - accuracy: 0.9125 - val_loss: 0.7876 - val_accuracy: 0.8000\n",
      "Epoch 902/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2385 - accuracy: 0.9375 - val_loss: 0.6908 - val_accuracy: 0.8000\n",
      "Epoch 903/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2197 - accuracy: 0.9125 - val_loss: 0.6619 - val_accuracy: 0.7500\n",
      "Epoch 904/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2171 - accuracy: 0.8875 - val_loss: 0.6859 - val_accuracy: 0.8000\n",
      "Epoch 905/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2111 - accuracy: 0.9250 - val_loss: 0.7186 - val_accuracy: 0.7500\n",
      "Epoch 906/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2181 - accuracy: 0.9375 - val_loss: 0.6850 - val_accuracy: 0.8000\n",
      "Epoch 907/2000\n",
      "80/80 [==============================] - 0s 253us/sample - loss: 0.2176 - accuracy: 0.9250 - val_loss: 0.6648 - val_accuracy: 0.8000\n",
      "Epoch 908/2000\n",
      "80/80 [==============================] - 0s 184us/sample - loss: 0.2224 - accuracy: 0.8875 - val_loss: 0.6317 - val_accuracy: 0.7500\n",
      "Epoch 909/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2215 - accuracy: 0.9125 - val_loss: 0.6521 - val_accuracy: 0.7500\n",
      "Epoch 910/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2201 - accuracy: 0.9250 - val_loss: 0.6049 - val_accuracy: 0.8000\n",
      "Epoch 911/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2166 - accuracy: 0.9250 - val_loss: 0.6399 - val_accuracy: 0.7500\n",
      "Epoch 912/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 0.2208 - accuracy: 0.9250 - val_loss: 0.6932 - val_accuracy: 0.7500\n",
      "Epoch 913/2000\n",
      "80/80 [==============================] - 0s 256us/sample - loss: 0.2194 - accuracy: 0.9375 - val_loss: 0.6436 - val_accuracy: 0.7500\n",
      "Epoch 914/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2153 - accuracy: 0.9000 - val_loss: 0.6714 - val_accuracy: 0.7500\n",
      "Epoch 915/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2331 - accuracy: 0.9125 - val_loss: 0.6927 - val_accuracy: 0.8000\n",
      "Epoch 916/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2388 - accuracy: 0.9125 - val_loss: 0.7685 - val_accuracy: 0.7500\n",
      "Epoch 917/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2176 - accuracy: 0.9375 - val_loss: 0.6538 - val_accuracy: 0.7500\n",
      "Epoch 918/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.2632 - accuracy: 0.8875 - val_loss: 0.6446 - val_accuracy: 0.7500\n",
      "Epoch 919/2000\n",
      "80/80 [==============================] - 0s 533us/sample - loss: 0.2100 - accuracy: 0.9250 - val_loss: 0.8270 - val_accuracy: 0.7500\n",
      "Epoch 920/2000\n",
      "80/80 [==============================] - 0s 159us/sample - loss: 0.2883 - accuracy: 0.9375 - val_loss: 0.8067 - val_accuracy: 0.7500\n",
      "Epoch 921/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2193 - accuracy: 0.9250 - val_loss: 0.7003 - val_accuracy: 0.7500\n",
      "Epoch 922/2000\n",
      "80/80 [==============================] - 0s 21us/sample - loss: 0.2376 - accuracy: 0.9250 - val_loss: 0.6455 - val_accuracy: 0.7500\n",
      "Epoch 923/2000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.2222 - accuracy: 0.9375 - val_loss: 0.6867 - val_accuracy: 0.7500\n",
      "Epoch 924/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2450 - accuracy: 0.9375 - val_loss: 0.6972 - val_accuracy: 0.7500\n",
      "Epoch 925/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2300 - accuracy: 0.9000 - val_loss: 0.6805 - val_accuracy: 0.7500\n",
      "Epoch 926/2000\n",
      "80/80 [==============================] - 0s 231us/sample - loss: 0.2249 - accuracy: 0.8875 - val_loss: 0.6968 - val_accuracy: 0.8000\n",
      "Epoch 927/2000\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 0.2177 - accuracy: 0.9375 - val_loss: 0.7080 - val_accuracy: 0.7500\n",
      "Epoch 928/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.2230 - accuracy: 0.9375 - val_loss: 0.6430 - val_accuracy: 0.8000\n",
      "Epoch 929/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2285 - accuracy: 0.8875 - val_loss: 0.6266 - val_accuracy: 0.7500\n",
      "Epoch 930/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.2282 - accuracy: 0.9125 - val_loss: 0.6877 - val_accuracy: 0.7500\n",
      "Epoch 931/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2212 - accuracy: 0.9375 - val_loss: 0.7397 - val_accuracy: 0.7500\n",
      "Epoch 932/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2210 - accuracy: 0.9375 - val_loss: 0.6640 - val_accuracy: 0.7500\n",
      "Epoch 933/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2134 - accuracy: 0.9125 - val_loss: 0.6450 - val_accuracy: 0.7500\n",
      "Epoch 934/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2233 - accuracy: 0.9000 - val_loss: 0.6478 - val_accuracy: 0.8000\n",
      "Epoch 935/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2087 - accuracy: 0.9250 - val_loss: 0.6779 - val_accuracy: 0.7500\n",
      "Epoch 936/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2229 - accuracy: 0.9375 - val_loss: 0.6437 - val_accuracy: 0.7500\n",
      "Epoch 937/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2130 - accuracy: 0.9125 - val_loss: 0.6260 - val_accuracy: 0.7500\n",
      "Epoch 938/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2237 - accuracy: 0.9250 - val_loss: 0.6520 - val_accuracy: 0.8000\n",
      "Epoch 939/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2195 - accuracy: 0.9250 - val_loss: 0.7043 - val_accuracy: 0.7500\n",
      "Epoch 940/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2220 - accuracy: 0.9375 - val_loss: 0.6466 - val_accuracy: 0.8000\n",
      "Epoch 941/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2185 - accuracy: 0.9000 - val_loss: 0.6539 - val_accuracy: 0.7500\n",
      "Epoch 942/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2080 - accuracy: 0.9125 - val_loss: 0.6909 - val_accuracy: 0.7500\n",
      "Epoch 943/2000\n",
      "80/80 [==============================] - 0s 223us/sample - loss: 0.2256 - accuracy: 0.9375 - val_loss: 0.7093 - val_accuracy: 0.7500\n",
      "Epoch 944/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2110 - accuracy: 0.9375 - val_loss: 0.6225 - val_accuracy: 0.7500\n",
      "Epoch 945/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2309 - accuracy: 0.9000 - val_loss: 0.6371 - val_accuracy: 0.7500\n",
      "Epoch 946/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2130 - accuracy: 0.9250 - val_loss: 0.7068 - val_accuracy: 0.7500\n",
      "Epoch 947/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2289 - accuracy: 0.9375 - val_loss: 0.6802 - val_accuracy: 0.7500\n",
      "Epoch 948/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2327 - accuracy: 0.9000 - val_loss: 0.6314 - val_accuracy: 0.7500\n",
      "Epoch 949/2000\n",
      "80/80 [==============================] - 0s 523us/sample - loss: 0.2269 - accuracy: 0.9125 - val_loss: 0.6632 - val_accuracy: 0.7500\n",
      "Epoch 950/2000\n",
      "80/80 [==============================] - 0s 387us/sample - loss: 0.2207 - accuracy: 0.9375 - val_loss: 0.6366 - val_accuracy: 0.7500\n",
      "Epoch 951/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.2139 - accuracy: 0.9250 - val_loss: 0.6155 - val_accuracy: 0.7500\n",
      "Epoch 952/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2313 - accuracy: 0.9250 - val_loss: 0.6652 - val_accuracy: 0.8000\n",
      "Epoch 953/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.2136 - accuracy: 0.9375 - val_loss: 0.8110 - val_accuracy: 0.7500\n",
      "Epoch 954/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2515 - accuracy: 0.9375 - val_loss: 0.6946 - val_accuracy: 0.8000\n",
      "Epoch 955/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2111 - accuracy: 0.9125 - val_loss: 0.6857 - val_accuracy: 0.7500\n",
      "Epoch 956/2000\n",
      "80/80 [==============================] - 0s 74us/sample - loss: 0.2288 - accuracy: 0.9000 - val_loss: 0.6800 - val_accuracy: 0.7500\n",
      "Epoch 957/2000\n",
      "80/80 [==============================] - 0s 176us/sample - loss: 0.2342 - accuracy: 0.9125 - val_loss: 0.7349 - val_accuracy: 0.7500\n",
      "Epoch 958/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.2239 - accuracy: 0.9375 - val_loss: 0.6441 - val_accuracy: 0.8000\n",
      "Epoch 959/2000\n",
      "80/80 [==============================] - 0s 247us/sample - loss: 0.2277 - accuracy: 0.9250 - val_loss: 0.6339 - val_accuracy: 0.7500\n",
      "Epoch 960/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.2271 - accuracy: 0.9125 - val_loss: 0.6767 - val_accuracy: 0.7500\n",
      "Epoch 961/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2164 - accuracy: 0.9375 - val_loss: 0.8166 - val_accuracy: 0.7500\n",
      "Epoch 962/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2311 - accuracy: 0.9375 - val_loss: 0.7273 - val_accuracy: 0.7500\n",
      "Epoch 963/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.2483 - accuracy: 0.9000 - val_loss: 0.6909 - val_accuracy: 0.7500\n",
      "Epoch 964/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2383 - accuracy: 0.9125 - val_loss: 0.6694 - val_accuracy: 0.7500\n",
      "Epoch 965/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.2142 - accuracy: 0.9375 - val_loss: 0.6960 - val_accuracy: 0.8000\n",
      "Epoch 966/2000\n",
      "80/80 [==============================] - 0s 208us/sample - loss: 0.2307 - accuracy: 0.9375 - val_loss: 0.6420 - val_accuracy: 0.8000\n",
      "Epoch 967/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2153 - accuracy: 0.9125 - val_loss: 0.6655 - val_accuracy: 0.7500\n",
      "Epoch 968/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2481 - accuracy: 0.9000 - val_loss: 0.6738 - val_accuracy: 0.7500\n",
      "Epoch 969/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2065 - accuracy: 0.9125 - val_loss: 0.7385 - val_accuracy: 0.7500\n",
      "Epoch 970/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2292 - accuracy: 0.9375 - val_loss: 0.7420 - val_accuracy: 0.7500\n",
      "Epoch 971/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.2217 - accuracy: 0.9375 - val_loss: 0.6415 - val_accuracy: 0.8000\n",
      "Epoch 972/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2105 - accuracy: 0.9250 - val_loss: 0.6212 - val_accuracy: 0.7500\n",
      "Epoch 973/2000\n",
      "80/80 [==============================] - 0s 275us/sample - loss: 0.2166 - accuracy: 0.9250 - val_loss: 0.6348 - val_accuracy: 0.8000\n",
      "Epoch 974/2000\n",
      "80/80 [==============================] - 0s 57us/sample - loss: 0.2148 - accuracy: 0.9250 - val_loss: 0.6830 - val_accuracy: 0.7500\n",
      "Epoch 975/2000\n",
      "80/80 [==============================] - 0s 219us/sample - loss: 0.2154 - accuracy: 0.9250 - val_loss: 0.6420 - val_accuracy: 0.7500\n",
      "Epoch 976/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2268 - accuracy: 0.9125 - val_loss: 0.6357 - val_accuracy: 0.7500\n",
      "Epoch 977/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2187 - accuracy: 0.9250 - val_loss: 0.6962 - val_accuracy: 0.7500\n",
      "Epoch 978/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.2157 - accuracy: 0.9375 - val_loss: 0.6414 - val_accuracy: 0.8000\n",
      "Epoch 979/2000\n",
      "80/80 [==============================] - 0s 674us/sample - loss: 0.2130 - accuracy: 0.9250 - val_loss: 0.6293 - val_accuracy: 0.8000\n",
      "Epoch 980/2000\n",
      "80/80 [==============================] - 0s 177us/sample - loss: 0.2122 - accuracy: 0.9250 - val_loss: 0.6561 - val_accuracy: 0.8000\n",
      "Epoch 981/2000\n",
      "80/80 [==============================] - 0s 229us/sample - loss: 0.2109 - accuracy: 0.9250 - val_loss: 0.7092 - val_accuracy: 0.7500\n",
      "Epoch 982/2000\n",
      "80/80 [==============================] - 0s 224us/sample - loss: 0.2179 - accuracy: 0.9375 - val_loss: 0.6670 - val_accuracy: 0.8000\n",
      "Epoch 983/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2139 - accuracy: 0.9125 - val_loss: 0.6418 - val_accuracy: 0.7500\n",
      "Epoch 984/2000\n",
      "80/80 [==============================] - 0s 55us/sample - loss: 0.2177 - accuracy: 0.9000 - val_loss: 0.6710 - val_accuracy: 0.8000\n",
      "Epoch 985/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2094 - accuracy: 0.9125 - val_loss: 0.6747 - val_accuracy: 0.8000\n",
      "Epoch 986/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.2179 - accuracy: 0.9375 - val_loss: 0.6631 - val_accuracy: 0.8000\n",
      "Epoch 987/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2078 - accuracy: 0.9125 - val_loss: 0.6237 - val_accuracy: 0.7500\n",
      "Epoch 988/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2174 - accuracy: 0.9250 - val_loss: 0.6066 - val_accuracy: 0.8000\n",
      "Epoch 989/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2125 - accuracy: 0.9250 - val_loss: 0.6389 - val_accuracy: 0.7500\n",
      "Epoch 990/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2229 - accuracy: 0.9250 - val_loss: 0.6651 - val_accuracy: 0.7500\n",
      "Epoch 991/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2085 - accuracy: 0.9250 - val_loss: 0.6203 - val_accuracy: 0.7500\n",
      "Epoch 992/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2172 - accuracy: 0.9250 - val_loss: 0.6306 - val_accuracy: 0.8000\n",
      "Epoch 993/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2142 - accuracy: 0.9125 - val_loss: 0.6598 - val_accuracy: 0.7500\n",
      "Epoch 994/2000\n",
      "80/80 [==============================] - 0s 307us/sample - loss: 0.2196 - accuracy: 0.9125 - val_loss: 0.6236 - val_accuracy: 0.7500\n",
      "Epoch 995/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2149 - accuracy: 0.9375 - val_loss: 0.6512 - val_accuracy: 0.7500\n",
      "Epoch 996/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.2163 - accuracy: 0.9250 - val_loss: 0.6212 - val_accuracy: 0.8000\n",
      "Epoch 997/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2122 - accuracy: 0.9250 - val_loss: 0.6480 - val_accuracy: 0.8000\n",
      "Epoch 998/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2168 - accuracy: 0.9125 - val_loss: 0.6763 - val_accuracy: 0.8000\n",
      "Epoch 999/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.2119 - accuracy: 0.9375 - val_loss: 0.7271 - val_accuracy: 0.7500\n",
      "Epoch 1000/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2264 - accuracy: 0.9250 - val_loss: 0.6634 - val_accuracy: 0.8000\n",
      "Epoch 1001/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.2091 - accuracy: 0.9125 - val_loss: 0.6647 - val_accuracy: 0.8000\n",
      "Epoch 1002/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2069 - accuracy: 0.9250 - val_loss: 0.6580 - val_accuracy: 0.7500\n",
      "Epoch 1003/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2169 - accuracy: 0.9250 - val_loss: 0.6368 - val_accuracy: 0.7500\n",
      "Epoch 1004/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2104 - accuracy: 0.9250 - val_loss: 0.6169 - val_accuracy: 0.8000\n",
      "Epoch 1005/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.2127 - accuracy: 0.9250 - val_loss: 0.6006 - val_accuracy: 0.8000\n",
      "Epoch 1006/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2104 - accuracy: 0.9125 - val_loss: 0.6028 - val_accuracy: 0.7500\n",
      "Epoch 1007/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.2335 - accuracy: 0.9125 - val_loss: 0.6089 - val_accuracy: 0.7500\n",
      "Epoch 1008/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.2177 - accuracy: 0.9250 - val_loss: 0.7027 - val_accuracy: 0.7500\n",
      "Epoch 1009/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2310 - accuracy: 0.9375 - val_loss: 0.6164 - val_accuracy: 0.8000\n",
      "Epoch 1010/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2251 - accuracy: 0.9000 - val_loss: 0.6323 - val_accuracy: 0.7000\n",
      "Epoch 1011/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.2659 - accuracy: 0.9125 - val_loss: 0.6758 - val_accuracy: 0.8000\n",
      "Epoch 1012/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.2060 - accuracy: 0.9250 - val_loss: 0.7532 - val_accuracy: 0.7500\n",
      "Epoch 1013/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2279 - accuracy: 0.9375 - val_loss: 0.6866 - val_accuracy: 0.7500\n",
      "Epoch 1014/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.2142 - accuracy: 0.9250 - val_loss: 0.6190 - val_accuracy: 0.7500\n",
      "Epoch 1015/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2295 - accuracy: 0.9125 - val_loss: 0.6303 - val_accuracy: 0.8000\n",
      "Epoch 1016/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.2116 - accuracy: 0.9250 - val_loss: 0.6804 - val_accuracy: 0.7500\n",
      "Epoch 1017/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.2154 - accuracy: 0.9250 - val_loss: 0.6510 - val_accuracy: 0.8000\n",
      "Epoch 1018/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 0.2100 - accuracy: 0.9250 - val_loss: 0.6494 - val_accuracy: 0.8000\n",
      "Epoch 1019/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2102 - accuracy: 0.9250 - val_loss: 0.6893 - val_accuracy: 0.7500\n",
      "Epoch 1020/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2108 - accuracy: 0.9250 - val_loss: 0.6796 - val_accuracy: 0.7500\n",
      "Epoch 1021/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2081 - accuracy: 0.9250 - val_loss: 0.6305 - val_accuracy: 0.8000\n",
      "Epoch 1022/2000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.2111 - accuracy: 0.9250 - val_loss: 0.6110 - val_accuracy: 0.8000\n",
      "Epoch 1023/2000\n",
      "80/80 [==============================] - 0s 168us/sample - loss: 0.2119 - accuracy: 0.9375 - val_loss: 0.6436 - val_accuracy: 0.7500\n",
      "Epoch 1024/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.2096 - accuracy: 0.9250 - val_loss: 0.6264 - val_accuracy: 0.8000\n",
      "Epoch 1025/2000\n",
      "80/80 [==============================] - 0s 790us/sample - loss: 0.2152 - accuracy: 0.9250 - val_loss: 0.6378 - val_accuracy: 0.7500\n",
      "Epoch 1026/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.2074 - accuracy: 0.9250 - val_loss: 0.7073 - val_accuracy: 0.7500\n",
      "Epoch 1027/2000\n",
      "80/80 [==============================] - 0s 205us/sample - loss: 0.2152 - accuracy: 0.9250 - val_loss: 0.6849 - val_accuracy: 0.7500\n",
      "Epoch 1028/2000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.2114 - accuracy: 0.9375 - val_loss: 0.6535 - val_accuracy: 0.7500\n",
      "Epoch 1029/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.2145 - accuracy: 0.9125 - val_loss: 0.6362 - val_accuracy: 0.7500\n",
      "Epoch 1030/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2095 - accuracy: 0.9125 - val_loss: 0.6854 - val_accuracy: 0.7500\n",
      "Epoch 1031/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2380 - accuracy: 0.9375 - val_loss: 0.7523 - val_accuracy: 0.8000\n",
      "Epoch 1032/2000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.2124 - accuracy: 0.9375 - val_loss: 0.6502 - val_accuracy: 0.7500\n",
      "Epoch 1033/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2504 - accuracy: 0.9250 - val_loss: 0.6928 - val_accuracy: 0.7500\n",
      "Epoch 1034/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2497 - accuracy: 0.9125 - val_loss: 0.7695 - val_accuracy: 0.8000\n",
      "Epoch 1035/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.2361 - accuracy: 0.9375 - val_loss: 0.8086 - val_accuracy: 0.7500\n",
      "Epoch 1036/2000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.2502 - accuracy: 0.9125 - val_loss: 0.6850 - val_accuracy: 0.8000\n",
      "Epoch 1037/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2122 - accuracy: 0.9125 - val_loss: 0.6426 - val_accuracy: 0.8000\n",
      "Epoch 1038/2000\n",
      "80/80 [==============================] - 0s 154us/sample - loss: 0.2105 - accuracy: 0.9250 - val_loss: 0.6136 - val_accuracy: 0.7500\n",
      "Epoch 1039/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.2101 - accuracy: 0.9250 - val_loss: 0.6013 - val_accuracy: 0.8000\n",
      "Epoch 1040/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.2086 - accuracy: 0.9250 - val_loss: 0.6090 - val_accuracy: 0.7500\n",
      "Epoch 1041/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2155 - accuracy: 0.9250 - val_loss: 0.6562 - val_accuracy: 0.8000\n",
      "Epoch 1042/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2083 - accuracy: 0.9125 - val_loss: 0.6664 - val_accuracy: 0.7500\n",
      "Epoch 1043/2000\n",
      "80/80 [==============================] - 0s 204us/sample - loss: 0.2092 - accuracy: 0.9125 - val_loss: 0.6467 - val_accuracy: 0.8000\n",
      "Epoch 1044/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.2134 - accuracy: 0.9125 - val_loss: 0.6287 - val_accuracy: 0.8000\n",
      "Epoch 1045/2000\n",
      "80/80 [==============================] - 0s 261us/sample - loss: 0.2094 - accuracy: 0.9250 - val_loss: 0.6835 - val_accuracy: 0.8000\n",
      "Epoch 1046/2000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.2215 - accuracy: 0.9375 - val_loss: 0.6170 - val_accuracy: 0.8000\n",
      "Epoch 1047/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.2067 - accuracy: 0.9250 - val_loss: 0.6232 - val_accuracy: 0.7500\n",
      "Epoch 1048/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2141 - accuracy: 0.8875 - val_loss: 0.6356 - val_accuracy: 0.8000\n",
      "Epoch 1049/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2067 - accuracy: 0.9125 - val_loss: 0.6576 - val_accuracy: 0.7500\n",
      "Epoch 1050/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2165 - accuracy: 0.9375 - val_loss: 0.5780 - val_accuracy: 0.8000\n",
      "Epoch 1051/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2239 - accuracy: 0.9500 - val_loss: 0.6092 - val_accuracy: 0.7500\n",
      "Epoch 1052/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2205 - accuracy: 0.9500 - val_loss: 0.6976 - val_accuracy: 0.8000\n",
      "Epoch 1053/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2291 - accuracy: 0.9375 - val_loss: 0.7634 - val_accuracy: 0.7500\n",
      "Epoch 1054/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.2232 - accuracy: 0.9250 - val_loss: 0.6478 - val_accuracy: 0.7500\n",
      "Epoch 1055/2000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.2165 - accuracy: 0.9000 - val_loss: 0.6002 - val_accuracy: 0.7500\n",
      "Epoch 1056/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2109 - accuracy: 0.9250 - val_loss: 0.6002 - val_accuracy: 0.8000\n",
      "Epoch 1057/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2084 - accuracy: 0.9375 - val_loss: 0.6047 - val_accuracy: 0.7500\n",
      "Epoch 1058/2000\n",
      "80/80 [==============================] - 0s 802us/sample - loss: 0.2163 - accuracy: 0.9375 - val_loss: 0.5895 - val_accuracy: 0.8000\n",
      "Epoch 1059/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2112 - accuracy: 0.9125 - val_loss: 0.6377 - val_accuracy: 0.7500\n",
      "Epoch 1060/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2067 - accuracy: 0.9250 - val_loss: 0.6383 - val_accuracy: 0.8000\n",
      "Epoch 1061/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.2056 - accuracy: 0.9125 - val_loss: 0.6353 - val_accuracy: 0.8000\n",
      "Epoch 1062/2000\n",
      "80/80 [==============================] - 0s 269us/sample - loss: 0.2068 - accuracy: 0.9250 - val_loss: 0.6248 - val_accuracy: 0.7500\n",
      "Epoch 1063/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2084 - accuracy: 0.9375 - val_loss: 0.5889 - val_accuracy: 0.8000\n",
      "Epoch 1064/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2070 - accuracy: 0.9375 - val_loss: 0.6275 - val_accuracy: 0.7500\n",
      "Epoch 1065/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.2224 - accuracy: 0.9125 - val_loss: 0.6400 - val_accuracy: 0.8000\n",
      "Epoch 1066/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2068 - accuracy: 0.9250 - val_loss: 0.6943 - val_accuracy: 0.7500\n",
      "Epoch 1067/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2157 - accuracy: 0.9375 - val_loss: 0.6559 - val_accuracy: 0.8000\n",
      "Epoch 1068/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2234 - accuracy: 0.9000 - val_loss: 0.6216 - val_accuracy: 0.7500\n",
      "Epoch 1069/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2044 - accuracy: 0.9125 - val_loss: 0.6715 - val_accuracy: 0.7500\n",
      "Epoch 1070/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2125 - accuracy: 0.9375 - val_loss: 0.6976 - val_accuracy: 0.8000\n",
      "Epoch 1071/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.2185 - accuracy: 0.9375 - val_loss: 0.6187 - val_accuracy: 0.8000\n",
      "Epoch 1072/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2050 - accuracy: 0.9125 - val_loss: 0.6075 - val_accuracy: 0.7500\n",
      "Epoch 1073/2000\n",
      "80/80 [==============================] - 0s 302us/sample - loss: 0.2116 - accuracy: 0.9125 - val_loss: 0.6308 - val_accuracy: 0.8000\n",
      "Epoch 1074/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2027 - accuracy: 0.9125 - val_loss: 0.6978 - val_accuracy: 0.7500\n",
      "Epoch 1075/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2270 - accuracy: 0.9375 - val_loss: 0.7279 - val_accuracy: 0.7500\n",
      "Epoch 1076/2000\n",
      "80/80 [==============================] - 0s 170us/sample - loss: 0.2100 - accuracy: 0.9375 - val_loss: 0.6052 - val_accuracy: 0.7500\n",
      "Epoch 1077/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2176 - accuracy: 0.9500 - val_loss: 0.6062 - val_accuracy: 0.7500\n",
      "Epoch 1078/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.2076 - accuracy: 0.9375 - val_loss: 0.6874 - val_accuracy: 0.7500\n",
      "Epoch 1079/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2346 - accuracy: 0.9375 - val_loss: 0.6720 - val_accuracy: 0.7500\n",
      "Epoch 1080/2000\n",
      "80/80 [==============================] - 0s 156us/sample - loss: 0.2064 - accuracy: 0.9250 - val_loss: 0.6118 - val_accuracy: 0.7500\n",
      "Epoch 1081/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.2321 - accuracy: 0.9250 - val_loss: 0.6343 - val_accuracy: 0.7500\n",
      "Epoch 1082/2000\n",
      "80/80 [==============================] - 0s 185us/sample - loss: 0.2129 - accuracy: 0.9250 - val_loss: 0.7498 - val_accuracy: 0.8000\n",
      "Epoch 1083/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.2264 - accuracy: 0.9375 - val_loss: 0.7012 - val_accuracy: 0.8000\n",
      "Epoch 1084/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.2128 - accuracy: 0.9000 - val_loss: 0.6702 - val_accuracy: 0.7500\n",
      "Epoch 1085/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.2195 - accuracy: 0.8875 - val_loss: 0.6310 - val_accuracy: 0.8000\n",
      "Epoch 1086/2000\n",
      "80/80 [==============================] - 0s 298us/sample - loss: 0.2101 - accuracy: 0.9250 - val_loss: 0.5642 - val_accuracy: 0.8000\n",
      "Epoch 1087/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.2179 - accuracy: 0.9500 - val_loss: 0.5817 - val_accuracy: 0.8000\n",
      "Epoch 1088/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2146 - accuracy: 0.9125 - val_loss: 0.6913 - val_accuracy: 0.7500\n",
      "Epoch 1089/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2101 - accuracy: 0.9250 - val_loss: 0.6186 - val_accuracy: 0.8000\n",
      "Epoch 1090/2000\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.2068 - accuracy: 0.9250 - val_loss: 0.5953 - val_accuracy: 0.8000\n",
      "Epoch 1091/2000\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.2162 - accuracy: 0.9250 - val_loss: 0.5776 - val_accuracy: 0.8000\n",
      "Epoch 1092/2000\n",
      "80/80 [==============================] - 0s 149us/sample - loss: 0.2136 - accuracy: 0.9250 - val_loss: 0.5806 - val_accuracy: 0.8000\n",
      "Epoch 1093/2000\n",
      "80/80 [==============================] - 0s 194us/sample - loss: 0.2045 - accuracy: 0.9375 - val_loss: 0.5830 - val_accuracy: 0.8000\n",
      "Epoch 1094/2000\n",
      "80/80 [==============================] - 0s 242us/sample - loss: 0.2082 - accuracy: 0.9375 - val_loss: 0.6210 - val_accuracy: 0.8000\n",
      "Epoch 1095/2000\n",
      "80/80 [==============================] - 0s 168us/sample - loss: 0.2054 - accuracy: 0.9250 - val_loss: 0.6576 - val_accuracy: 0.8000\n",
      "Epoch 1096/2000\n",
      "80/80 [==============================] - 0s 169us/sample - loss: 0.2113 - accuracy: 0.9125 - val_loss: 0.6713 - val_accuracy: 0.8000\n",
      "Epoch 1097/2000\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.2135 - accuracy: 0.8875 - val_loss: 0.6240 - val_accuracy: 0.7500\n",
      "Epoch 1098/2000\n",
      "80/80 [==============================] - 0s 192us/sample - loss: 0.2148 - accuracy: 0.9125 - val_loss: 0.6413 - val_accuracy: 0.8000\n",
      "Epoch 1099/2000\n",
      "80/80 [==============================] - 0s 169us/sample - loss: 0.2051 - accuracy: 0.9250 - val_loss: 0.5877 - val_accuracy: 0.8000\n",
      "Epoch 1100/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.2056 - accuracy: 0.9125 - val_loss: 0.5789 - val_accuracy: 0.8000\n",
      "Epoch 1101/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2256 - accuracy: 0.9250 - val_loss: 0.5830 - val_accuracy: 0.8000\n",
      "Epoch 1102/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.1932 - accuracy: 0.9375 - val_loss: 0.7099 - val_accuracy: 0.8000\n",
      "Epoch 1103/2000\n",
      "80/80 [==============================] - 0s 157us/sample - loss: 0.2417 - accuracy: 0.9250 - val_loss: 0.6478 - val_accuracy: 0.7500\n",
      "Epoch 1104/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.1922 - accuracy: 0.9250 - val_loss: 0.6084 - val_accuracy: 0.7500\n",
      "Epoch 1105/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.2533 - accuracy: 0.9250 - val_loss: 0.6541 - val_accuracy: 0.7500\n",
      "Epoch 1106/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.2264 - accuracy: 0.9000 - val_loss: 0.7858 - val_accuracy: 0.8000\n",
      "Epoch 1107/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2468 - accuracy: 0.9375 - val_loss: 0.7130 - val_accuracy: 0.7500\n",
      "Epoch 1108/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.2545 - accuracy: 0.9250 - val_loss: 0.6330 - val_accuracy: 0.7500\n",
      "Epoch 1109/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2298 - accuracy: 0.9125 - val_loss: 0.6720 - val_accuracy: 0.7500\n",
      "Epoch 1110/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.2072 - accuracy: 0.9250 - val_loss: 0.6985 - val_accuracy: 0.7500\n",
      "Epoch 1111/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.2113 - accuracy: 0.9250 - val_loss: 0.6294 - val_accuracy: 0.8000\n",
      "Epoch 1112/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2181 - accuracy: 0.9250 - val_loss: 0.6023 - val_accuracy: 0.7500\n",
      "Epoch 1113/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2105 - accuracy: 0.9500 - val_loss: 0.6354 - val_accuracy: 0.8000\n",
      "Epoch 1114/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2032 - accuracy: 0.9250 - val_loss: 0.6919 - val_accuracy: 0.8000\n",
      "Epoch 1115/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.2192 - accuracy: 0.9250 - val_loss: 0.6638 - val_accuracy: 0.7500\n",
      "Epoch 1116/2000\n",
      "80/80 [==============================] - 0s 269us/sample - loss: 0.2106 - accuracy: 0.9375 - val_loss: 0.6432 - val_accuracy: 0.7500\n",
      "Epoch 1117/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2141 - accuracy: 0.9125 - val_loss: 0.6002 - val_accuracy: 0.7500\n",
      "Epoch 1118/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2119 - accuracy: 0.9250 - val_loss: 0.6197 - val_accuracy: 0.7500\n",
      "Epoch 1119/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2242 - accuracy: 0.9375 - val_loss: 0.7234 - val_accuracy: 0.8000\n",
      "Epoch 1120/2000\n",
      "80/80 [==============================] - 0s 224us/sample - loss: 0.2181 - accuracy: 0.9375 - val_loss: 0.6264 - val_accuracy: 0.7500\n",
      "Epoch 1121/2000\n",
      "80/80 [==============================] - 0s 288us/sample - loss: 0.2096 - accuracy: 0.9125 - val_loss: 0.6458 - val_accuracy: 0.7500\n",
      "Epoch 1122/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.2101 - accuracy: 0.9000 - val_loss: 0.6832 - val_accuracy: 0.8000\n",
      "Epoch 1123/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.2059 - accuracy: 0.90 - 0s 111us/sample - loss: 0.2161 - accuracy: 0.9375 - val_loss: 0.6828 - val_accuracy: 0.7500\n",
      "Epoch 1124/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2097 - accuracy: 0.9125 - val_loss: 0.5820 - val_accuracy: 0.8000\n",
      "Epoch 1125/2000\n",
      "80/80 [==============================] - 0s 246us/sample - loss: 0.2149 - accuracy: 0.9250 - val_loss: 0.6098 - val_accuracy: 0.8000\n",
      "Epoch 1126/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.1984 - accuracy: 0.9250 - val_loss: 0.6701 - val_accuracy: 0.7500\n",
      "Epoch 1127/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2227 - accuracy: 0.9375 - val_loss: 0.6327 - val_accuracy: 0.7500\n",
      "Epoch 1128/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.2212 - accuracy: 0.9250 - val_loss: 0.5828 - val_accuracy: 0.7500\n",
      "Epoch 1129/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2292 - accuracy: 0.9125 - val_loss: 0.6232 - val_accuracy: 0.7500\n",
      "Epoch 1130/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.2082 - accuracy: 0.9125 - val_loss: 0.7095 - val_accuracy: 0.7500\n",
      "Epoch 1131/2000\n",
      "80/80 [==============================] - 0s 160us/sample - loss: 0.2210 - accuracy: 0.9375 - val_loss: 0.6360 - val_accuracy: 0.8000\n",
      "Epoch 1132/2000\n",
      "80/80 [==============================] - 0s 298us/sample - loss: 0.2110 - accuracy: 0.9125 - val_loss: 0.5742 - val_accuracy: 0.8000\n",
      "Epoch 1133/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.2059 - accuracy: 0.9375 - val_loss: 0.6064 - val_accuracy: 0.7500\n",
      "Epoch 1134/2000\n",
      "80/80 [==============================] - 0s 179us/sample - loss: 0.2120 - accuracy: 0.9250 - val_loss: 0.6116 - val_accuracy: 0.7500\n",
      "Epoch 1135/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.2003 - accuracy: 0.9375 - val_loss: 0.6063 - val_accuracy: 0.7500\n",
      "Epoch 1136/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2259 - accuracy: 0.9250 - val_loss: 0.6478 - val_accuracy: 0.8000\n",
      "Epoch 1137/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2278 - accuracy: 0.9250 - val_loss: 0.7254 - val_accuracy: 0.8000\n",
      "Epoch 1138/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2160 - accuracy: 0.9375 - val_loss: 0.5975 - val_accuracy: 0.7500\n",
      "Epoch 1139/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2255 - accuracy: 0.9125 - val_loss: 0.5947 - val_accuracy: 0.7500\n",
      "Epoch 1140/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2027 - accuracy: 0.9375 - val_loss: 0.6992 - val_accuracy: 0.8000\n",
      "Epoch 1141/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2157 - accuracy: 0.9375 - val_loss: 0.6790 - val_accuracy: 0.7500\n",
      "Epoch 1142/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2031 - accuracy: 0.9250 - val_loss: 0.6465 - val_accuracy: 0.8000\n",
      "Epoch 1143/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.2078 - accuracy: 0.9250 - val_loss: 0.6650 - val_accuracy: 0.7500\n",
      "Epoch 1144/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.2131 - accuracy: 0.9125 - val_loss: 0.6779 - val_accuracy: 0.8000\n",
      "Epoch 1145/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.2000 - accuracy: 0.9250 - val_loss: 0.6975 - val_accuracy: 0.7500\n",
      "Epoch 1146/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2210 - accuracy: 0.9375 - val_loss: 0.6346 - val_accuracy: 0.7500\n",
      "Epoch 1147/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 0.2134 - accuracy: 0.9250 - val_loss: 0.5832 - val_accuracy: 0.8000\n",
      "Epoch 1148/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2032 - accuracy: 0.9125 - val_loss: 0.6271 - val_accuracy: 0.7500\n",
      "Epoch 1149/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2048 - accuracy: 0.9250 - val_loss: 0.6271 - val_accuracy: 0.7500\n",
      "Epoch 1150/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2062 - accuracy: 0.9250 - val_loss: 0.6126 - val_accuracy: 0.7500\n",
      "Epoch 1151/2000\n",
      "80/80 [==============================] - 0s 681us/sample - loss: 0.2033 - accuracy: 0.9250 - val_loss: 0.6299 - val_accuracy: 0.8000\n",
      "Epoch 1152/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2097 - accuracy: 0.9125 - val_loss: 0.6450 - val_accuracy: 0.8000\n",
      "Epoch 1153/2000\n",
      "80/80 [==============================] - 0s 45us/sample - loss: 0.2068 - accuracy: 0.9125 - val_loss: 0.6127 - val_accuracy: 0.7500\n",
      "Epoch 1154/2000\n",
      "80/80 [==============================] - 0s 301us/sample - loss: 0.2155 - accuracy: 0.9125 - val_loss: 0.6013 - val_accuracy: 0.8000\n",
      "Epoch 1155/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2114 - accuracy: 0.9125 - val_loss: 0.6059 - val_accuracy: 0.8000\n",
      "Epoch 1156/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.2100 - accuracy: 0.9250 - val_loss: 0.5804 - val_accuracy: 0.7500\n",
      "Epoch 1157/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.2133 - accuracy: 0.9000 - val_loss: 0.6006 - val_accuracy: 0.8000\n",
      "Epoch 1158/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.2047 - accuracy: 0.9250 - val_loss: 0.5868 - val_accuracy: 0.8000\n",
      "Epoch 1159/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.2038 - accuracy: 0.9250 - val_loss: 0.6137 - val_accuracy: 0.7500\n",
      "Epoch 1160/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2036 - accuracy: 0.9250 - val_loss: 0.6197 - val_accuracy: 0.7500\n",
      "Epoch 1161/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2070 - accuracy: 0.9250 - val_loss: 0.5948 - val_accuracy: 0.8000\n",
      "Epoch 1162/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.2004 - accuracy: 0.9250 - val_loss: 0.6277 - val_accuracy: 0.7500\n",
      "Epoch 1163/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.2077 - accuracy: 0.9375 - val_loss: 0.6724 - val_accuracy: 0.8000\n",
      "Epoch 1164/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.2092 - accuracy: 0.9250 - val_loss: 0.6151 - val_accuracy: 0.8000\n",
      "Epoch 1165/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.2026 - accuracy: 0.9250 - val_loss: 0.6003 - val_accuracy: 0.8000\n",
      "Epoch 1166/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2035 - accuracy: 0.9250 - val_loss: 0.6070 - val_accuracy: 0.8000\n",
      "Epoch 1167/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.2028 - accuracy: 0.9250 - val_loss: 0.6290 - val_accuracy: 0.8000\n",
      "Epoch 1168/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.2014 - accuracy: 0.9250 - val_loss: 0.6344 - val_accuracy: 0.8000\n",
      "Epoch 1169/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2010 - accuracy: 0.9250 - val_loss: 0.6327 - val_accuracy: 0.8000\n",
      "Epoch 1170/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.2028 - accuracy: 0.9250 - val_loss: 0.6350 - val_accuracy: 0.8000\n",
      "Epoch 1171/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.2019 - accuracy: 0.9250 - val_loss: 0.6219 - val_accuracy: 0.8000\n",
      "Epoch 1172/2000\n",
      "80/80 [==============================] - 0s 224us/sample - loss: 0.1998 - accuracy: 0.9125 - val_loss: 0.6282 - val_accuracy: 0.7500\n",
      "Epoch 1173/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2050 - accuracy: 0.9250 - val_loss: 0.6064 - val_accuracy: 0.7500\n",
      "Epoch 1174/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.1995 - accuracy: 0.9250 - val_loss: 0.5944 - val_accuracy: 0.8000\n",
      "Epoch 1175/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.2084 - accuracy: 0.9250 - val_loss: 0.6182 - val_accuracy: 0.7500\n",
      "Epoch 1176/2000\n",
      "80/80 [==============================] - 0s 148us/sample - loss: 0.2035 - accuracy: 0.9375 - val_loss: 0.6608 - val_accuracy: 0.8000\n",
      "Epoch 1177/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2058 - accuracy: 0.9125 - val_loss: 0.6251 - val_accuracy: 0.8000\n",
      "Epoch 1178/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.2011 - accuracy: 0.9250 - val_loss: 0.5947 - val_accuracy: 0.7500\n",
      "Epoch 1179/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2017 - accuracy: 0.9250 - val_loss: 0.5758 - val_accuracy: 0.8000\n",
      "Epoch 1180/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2007 - accuracy: 0.9375 - val_loss: 0.5870 - val_accuracy: 0.8000\n",
      "Epoch 1181/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2040 - accuracy: 0.9250 - val_loss: 0.6341 - val_accuracy: 0.8000\n",
      "Epoch 1182/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.2027 - accuracy: 0.9125 - val_loss: 0.6850 - val_accuracy: 0.7500\n",
      "Epoch 1183/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.2118 - accuracy: 0.9375 - val_loss: 0.6708 - val_accuracy: 0.7500\n",
      "Epoch 1184/2000\n",
      "80/80 [==============================] - 0s 631us/sample - loss: 0.2152 - accuracy: 0.9250 - val_loss: 0.5999 - val_accuracy: 0.8000\n",
      "Epoch 1185/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.2080 - accuracy: 0.9250 - val_loss: 0.5862 - val_accuracy: 0.8000\n",
      "Epoch 1186/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 0.2028 - accuracy: 0.9250 - val_loss: 0.6405 - val_accuracy: 0.8000\n",
      "Epoch 1187/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.2116 - accuracy: 0.9250 - val_loss: 0.5795 - val_accuracy: 0.7500\n",
      "Epoch 1188/2000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.2056 - accuracy: 0.9250 - val_loss: 0.5937 - val_accuracy: 0.8000\n",
      "Epoch 1189/2000\n",
      "80/80 [==============================] - 0s 239us/sample - loss: 0.2077 - accuracy: 0.9250 - val_loss: 0.5964 - val_accuracy: 0.8000\n",
      "Epoch 1190/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2011 - accuracy: 0.9250 - val_loss: 0.6005 - val_accuracy: 0.7500\n",
      "Epoch 1191/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.2073 - accuracy: 0.9125 - val_loss: 0.6364 - val_accuracy: 0.8000\n",
      "Epoch 1192/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2056 - accuracy: 0.9250 - val_loss: 0.7154 - val_accuracy: 0.8000\n",
      "Epoch 1193/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.2206 - accuracy: 0.9375 - val_loss: 0.6127 - val_accuracy: 0.8000\n",
      "Epoch 1194/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2079 - accuracy: 0.8875 - val_loss: 0.5918 - val_accuracy: 0.7500\n",
      "Epoch 1195/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2074 - accuracy: 0.9250 - val_loss: 0.6404 - val_accuracy: 0.7500\n",
      "Epoch 1196/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.2059 - accuracy: 0.9250 - val_loss: 0.6166 - val_accuracy: 0.8000\n",
      "Epoch 1197/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2092 - accuracy: 0.9250 - val_loss: 0.6249 - val_accuracy: 0.8000\n",
      "Epoch 1198/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2027 - accuracy: 0.9250 - val_loss: 0.5865 - val_accuracy: 0.7500\n",
      "Epoch 1199/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2106 - accuracy: 0.9250 - val_loss: 0.6525 - val_accuracy: 0.7500\n",
      "Epoch 1200/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.2056 - accuracy: 0.9250 - val_loss: 0.6411 - val_accuracy: 0.7500\n",
      "Epoch 1201/2000\n",
      "80/80 [==============================] - 0s 153us/sample - loss: 0.2009 - accuracy: 0.9375 - val_loss: 0.6114 - val_accuracy: 0.7500\n",
      "Epoch 1202/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.2108 - accuracy: 0.9500 - val_loss: 0.6049 - val_accuracy: 0.8000\n",
      "Epoch 1203/2000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.2027 - accuracy: 0.9250 - val_loss: 0.6128 - val_accuracy: 0.7500\n",
      "Epoch 1204/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2003 - accuracy: 0.9250 - val_loss: 0.5924 - val_accuracy: 0.8000\n",
      "Epoch 1205/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.1998 - accuracy: 0.9250 - val_loss: 0.6132 - val_accuracy: 0.8000\n",
      "Epoch 1206/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.2042 - accuracy: 0.9250 - val_loss: 0.6239 - val_accuracy: 0.7500\n",
      "Epoch 1207/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.1994 - accuracy: 0.9250 - val_loss: 0.6032 - val_accuracy: 0.7500\n",
      "Epoch 1208/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2043 - accuracy: 0.9250 - val_loss: 0.6050 - val_accuracy: 0.8000\n",
      "Epoch 1209/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2046 - accuracy: 0.9250 - val_loss: 0.6503 - val_accuracy: 0.7500\n",
      "Epoch 1210/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2065 - accuracy: 0.9250 - val_loss: 0.6202 - val_accuracy: 0.8000\n",
      "Epoch 1211/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.2022 - accuracy: 0.9250 - val_loss: 0.5647 - val_accuracy: 0.8000\n",
      "Epoch 1212/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2151 - accuracy: 0.9375 - val_loss: 0.5333 - val_accuracy: 0.8000\n",
      "Epoch 1213/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.2026 - accuracy: 0.9375 - val_loss: 0.6401 - val_accuracy: 0.8000\n",
      "Epoch 1214/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.2168 - accuracy: 0.9375 - val_loss: 0.6143 - val_accuracy: 0.8000\n",
      "Epoch 1215/2000\n",
      "80/80 [==============================] - 0s 151us/sample - loss: 0.2110 - accuracy: 0.9125 - val_loss: 0.6157 - val_accuracy: 0.7500\n",
      "Epoch 1216/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.2128 - accuracy: 0.9250 - val_loss: 0.6373 - val_accuracy: 0.7500\n",
      "Epoch 1217/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2074 - accuracy: 0.9375 - val_loss: 0.5838 - val_accuracy: 0.8000\n",
      "Epoch 1218/2000\n",
      "80/80 [==============================] - 0s 221us/sample - loss: 0.2000 - accuracy: 0.9500 - val_loss: 0.5554 - val_accuracy: 0.7500\n",
      "Epoch 1219/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2096 - accuracy: 0.9375 - val_loss: 0.6181 - val_accuracy: 0.8000\n",
      "Epoch 1220/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.1993 - accuracy: 0.9250 - val_loss: 0.7389 - val_accuracy: 0.7500\n",
      "Epoch 1221/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.2166 - accuracy: 0.9375 - val_loss: 0.6761 - val_accuracy: 0.8000\n",
      "Epoch 1222/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.1982 - accuracy: 0.9375 - val_loss: 0.6194 - val_accuracy: 0.7500\n",
      "Epoch 1223/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.2186 - accuracy: 0.9250 - val_loss: 0.6055 - val_accuracy: 0.8000\n",
      "Epoch 1224/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2333 - accuracy: 0.9125 - val_loss: 0.6260 - val_accuracy: 0.7500\n",
      "Epoch 1225/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2066 - accuracy: 0.9375 - val_loss: 0.5603 - val_accuracy: 0.7000\n",
      "Epoch 1226/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2309 - accuracy: 0.9125 - val_loss: 0.6261 - val_accuracy: 0.8000\n",
      "Epoch 1227/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.1995 - accuracy: 0.9375 - val_loss: 0.7495 - val_accuracy: 0.8000\n",
      "Epoch 1228/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.2145 - accuracy: 0.9250 - val_loss: 0.6638 - val_accuracy: 0.8000\n",
      "Epoch 1229/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.2015 - accuracy: 0.9250 - val_loss: 0.6113 - val_accuracy: 0.8000\n",
      "Epoch 1230/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.2168 - accuracy: 0.9250 - val_loss: 0.5927 - val_accuracy: 0.8000\n",
      "Epoch 1231/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.1992 - accuracy: 0.9375 - val_loss: 0.6375 - val_accuracy: 0.7500\n",
      "Epoch 1232/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2190 - accuracy: 0.9250 - val_loss: 0.6825 - val_accuracy: 0.8000\n",
      "Epoch 1233/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2118 - accuracy: 0.9250 - val_loss: 0.6197 - val_accuracy: 0.8000\n",
      "Epoch 1234/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2014 - accuracy: 0.9375 - val_loss: 0.6602 - val_accuracy: 0.7500\n",
      "Epoch 1235/2000\n",
      "80/80 [==============================] - 0s 224us/sample - loss: 0.2098 - accuracy: 0.9250 - val_loss: 0.6930 - val_accuracy: 0.8000\n",
      "Epoch 1236/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.2031 - accuracy: 0.9000 - val_loss: 0.6199 - val_accuracy: 0.7500\n",
      "Epoch 1237/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2117 - accuracy: 0.9250 - val_loss: 0.5763 - val_accuracy: 0.8000\n",
      "Epoch 1238/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.1991 - accuracy: 0.9250 - val_loss: 0.5411 - val_accuracy: 0.8000\n",
      "Epoch 1239/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.2053 - accuracy: 0.9375 - val_loss: 0.5641 - val_accuracy: 0.8000\n",
      "Epoch 1240/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.2031 - accuracy: 0.9375 - val_loss: 0.6688 - val_accuracy: 0.7500\n",
      "Epoch 1241/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2049 - accuracy: 0.9250 - val_loss: 0.6114 - val_accuracy: 0.8000\n",
      "Epoch 1242/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.2060 - accuracy: 0.9375 - val_loss: 0.6028 - val_accuracy: 0.8000\n",
      "Epoch 1243/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.1989 - accuracy: 0.9250 - val_loss: 0.6363 - val_accuracy: 0.7500\n",
      "Epoch 1244/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2059 - accuracy: 0.9250 - val_loss: 0.6022 - val_accuracy: 0.8000\n",
      "Epoch 1245/2000\n",
      "80/80 [==============================] - 0s 515us/sample - loss: 0.1977 - accuracy: 0.9500 - val_loss: 0.5854 - val_accuracy: 0.7500\n",
      "Epoch 1246/2000\n",
      "80/80 [==============================] - 0s 23us/sample - loss: 0.2113 - accuracy: 0.9250 - val_loss: 0.6117 - val_accuracy: 0.8000\n",
      "Epoch 1247/2000\n",
      "80/80 [==============================] - 0s 204us/sample - loss: 0.2178 - accuracy: 0.9125 - val_loss: 0.6411 - val_accuracy: 0.7500\n",
      "Epoch 1248/2000\n",
      "80/80 [==============================] - 0s 231us/sample - loss: 0.2045 - accuracy: 0.9250 - val_loss: 0.5856 - val_accuracy: 0.8000\n",
      "Epoch 1249/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.2007 - accuracy: 0.9375 - val_loss: 0.6103 - val_accuracy: 0.7500\n",
      "Epoch 1250/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2026 - accuracy: 0.9250 - val_loss: 0.6363 - val_accuracy: 0.7500\n",
      "Epoch 1251/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.2154 - accuracy: 0.9000 - val_loss: 0.6254 - val_accuracy: 0.8000\n",
      "Epoch 1252/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.1964 - accuracy: 0.9250 - val_loss: 0.6594 - val_accuracy: 0.7500\n",
      "Epoch 1253/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2045 - accuracy: 0.9250 - val_loss: 0.6349 - val_accuracy: 0.7500\n",
      "Epoch 1254/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2147 - accuracy: 0.9125 - val_loss: 0.5924 - val_accuracy: 0.8000\n",
      "Epoch 1255/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.1992 - accuracy: 0.9250 - val_loss: 0.6525 - val_accuracy: 0.7500\n",
      "Epoch 1256/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2075 - accuracy: 0.9250 - val_loss: 0.6662 - val_accuracy: 0.7500\n",
      "Epoch 1257/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.1976 - accuracy: 0.9250 - val_loss: 0.5939 - val_accuracy: 0.7500\n",
      "Epoch 1258/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2107 - accuracy: 0.9250 - val_loss: 0.5715 - val_accuracy: 0.7500\n",
      "Epoch 1259/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.2071 - accuracy: 0.9375 - val_loss: 0.6374 - val_accuracy: 0.7500\n",
      "Epoch 1260/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.2114 - accuracy: 0.9375 - val_loss: 0.6488 - val_accuracy: 0.8000\n",
      "Epoch 1261/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.2156 - accuracy: 0.9125 - val_loss: 0.6160 - val_accuracy: 0.7500\n",
      "Epoch 1262/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.2288 - accuracy: 0.9000 - val_loss: 0.6340 - val_accuracy: 0.8000\n",
      "Epoch 1263/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2078 - accuracy: 0.9250 - val_loss: 0.5795 - val_accuracy: 0.7500\n",
      "Epoch 1264/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.1975 - accuracy: 0.9375 - val_loss: 0.5257 - val_accuracy: 0.8000\n",
      "Epoch 1265/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.2254 - accuracy: 0.9125 - val_loss: 0.5764 - val_accuracy: 0.7500\n",
      "Epoch 1266/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2246 - accuracy: 0.9500 - val_loss: 0.7267 - val_accuracy: 0.8000\n",
      "Epoch 1267/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2172 - accuracy: 0.9250 - val_loss: 0.6296 - val_accuracy: 0.7500\n",
      "Epoch 1268/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2315 - accuracy: 0.9250 - val_loss: 0.6574 - val_accuracy: 0.7500\n",
      "Epoch 1269/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2269 - accuracy: 0.9375 - val_loss: 0.7791 - val_accuracy: 0.8000\n",
      "Epoch 1270/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2234 - accuracy: 0.9375 - val_loss: 0.6616 - val_accuracy: 0.8000\n",
      "Epoch 1271/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2072 - accuracy: 0.9000 - val_loss: 0.5888 - val_accuracy: 0.7500\n",
      "Epoch 1272/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2079 - accuracy: 0.9375 - val_loss: 0.6047 - val_accuracy: 0.7500\n",
      "Epoch 1273/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2082 - accuracy: 0.9375 - val_loss: 0.6151 - val_accuracy: 0.8000\n",
      "Epoch 1274/2000\n",
      "80/80 [==============================] - 0s 185us/sample - loss: 0.2007 - accuracy: 0.9375 - val_loss: 0.5940 - val_accuracy: 0.8000\n",
      "Epoch 1275/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2037 - accuracy: 0.9375 - val_loss: 0.6034 - val_accuracy: 0.8000\n",
      "Epoch 1276/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.2094 - accuracy: 0.9250 - val_loss: 0.6667 - val_accuracy: 0.8000\n",
      "Epoch 1277/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2070 - accuracy: 0.9250 - val_loss: 0.5966 - val_accuracy: 0.8000\n",
      "Epoch 1278/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.1972 - accuracy: 0.9375 - val_loss: 0.5571 - val_accuracy: 0.8000\n",
      "Epoch 1279/2000\n",
      "80/80 [==============================] - 0s 593us/sample - loss: 0.2014 - accuracy: 0.9500 - val_loss: 0.5620 - val_accuracy: 0.7500\n",
      "Epoch 1280/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2062 - accuracy: 0.9375 - val_loss: 0.6057 - val_accuracy: 0.7500\n",
      "Epoch 1281/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.1973 - accuracy: 0.9375 - val_loss: 0.5699 - val_accuracy: 0.7500\n",
      "Epoch 1282/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.2058 - accuracy: 0.9500 - val_loss: 0.6050 - val_accuracy: 0.8000\n",
      "Epoch 1283/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.2021 - accuracy: 0.9250 - val_loss: 0.6396 - val_accuracy: 0.8000\n",
      "Epoch 1284/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.2039 - accuracy: 0.9250 - val_loss: 0.5840 - val_accuracy: 0.8000\n",
      "Epoch 1285/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.2001 - accuracy: 0.9500 - val_loss: 0.5570 - val_accuracy: 0.8000\n",
      "Epoch 1286/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2020 - accuracy: 0.9375 - val_loss: 0.5873 - val_accuracy: 0.7500\n",
      "Epoch 1287/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.1986 - accuracy: 0.9375 - val_loss: 0.6153 - val_accuracy: 0.8000\n",
      "Epoch 1288/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.2181 - accuracy: 0.9125 - val_loss: 0.6138 - val_accuracy: 0.7500\n",
      "Epoch 1289/2000\n",
      "80/80 [==============================] - 0s 151us/sample - loss: 0.1992 - accuracy: 0.9250 - val_loss: 0.6913 - val_accuracy: 0.8000\n",
      "Epoch 1290/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2081 - accuracy: 0.9375 - val_loss: 0.5911 - val_accuracy: 0.8000\n",
      "Epoch 1291/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.1976 - accuracy: 0.9250 - val_loss: 0.5550 - val_accuracy: 0.7500\n",
      "Epoch 1292/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.2111 - accuracy: 0.9375 - val_loss: 0.5901 - val_accuracy: 0.7500\n",
      "Epoch 1293/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.2021 - accuracy: 0.9250 - val_loss: 0.6233 - val_accuracy: 0.7500\n",
      "Epoch 1294/2000\n",
      "80/80 [==============================] - 0s 297us/sample - loss: 0.1979 - accuracy: 0.9250 - val_loss: 0.5730 - val_accuracy: 0.7500\n",
      "Epoch 1295/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2092 - accuracy: 0.9375 - val_loss: 0.5961 - val_accuracy: 0.8000\n",
      "Epoch 1296/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.2010 - accuracy: 0.9375 - val_loss: 0.6215 - val_accuracy: 0.7500\n",
      "Epoch 1297/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2008 - accuracy: 0.9250 - val_loss: 0.6181 - val_accuracy: 0.8000\n",
      "Epoch 1298/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.1995 - accuracy: 0.9375 - val_loss: 0.5761 - val_accuracy: 0.8000\n",
      "Epoch 1299/2000\n",
      "80/80 [==============================] - 0s 38us/sample - loss: 0.1989 - accuracy: 0.9375 - val_loss: 0.5567 - val_accuracy: 0.8000\n",
      "Epoch 1300/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 0.1981 - accuracy: 0.9500 - val_loss: 0.6177 - val_accuracy: 0.8000\n",
      "Epoch 1301/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2038 - accuracy: 0.9250 - val_loss: 0.6188 - val_accuracy: 0.7500\n",
      "Epoch 1302/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.1965 - accuracy: 0.9250 - val_loss: 0.5685 - val_accuracy: 0.8000\n",
      "Epoch 1303/2000\n",
      "80/80 [==============================] - 0s 162us/sample - loss: 0.1993 - accuracy: 0.9375 - val_loss: 0.5989 - val_accuracy: 0.8000\n",
      "Epoch 1304/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.1962 - accuracy: 0.9375 - val_loss: 0.6600 - val_accuracy: 0.7500\n",
      "Epoch 1305/2000\n",
      "80/80 [==============================] - 0s 791us/sample - loss: 0.1990 - accuracy: 0.9250 - val_loss: 0.6480 - val_accuracy: 0.8000\n",
      "Epoch 1306/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2137 - accuracy: 0.9125 - val_loss: 0.6562 - val_accuracy: 0.7500\n",
      "Epoch 1307/2000\n",
      "80/80 [==============================] - 0s 177us/sample - loss: 0.2116 - accuracy: 0.9000 - val_loss: 0.6717 - val_accuracy: 0.8000\n",
      "Epoch 1308/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2068 - accuracy: 0.9250 - val_loss: 0.5879 - val_accuracy: 0.8000\n",
      "Epoch 1309/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.1943 - accuracy: 0.9250 - val_loss: 0.5666 - val_accuracy: 0.7500\n",
      "Epoch 1310/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2244 - accuracy: 0.9250 - val_loss: 0.6035 - val_accuracy: 0.8000\n",
      "Epoch 1311/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2084 - accuracy: 0.9500 - val_loss: 0.7921 - val_accuracy: 0.8000\n",
      "Epoch 1312/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.2326 - accuracy: 0.9125 - val_loss: 0.7160 - val_accuracy: 0.7500\n",
      "Epoch 1313/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2014 - accuracy: 0.9125 - val_loss: 0.6469 - val_accuracy: 0.7500\n",
      "Epoch 1314/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.2065 - accuracy: 0.9125 - val_loss: 0.5743 - val_accuracy: 0.8000\n",
      "Epoch 1315/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2261 - accuracy: 0.9375 - val_loss: 0.5815 - val_accuracy: 0.8000\n",
      "Epoch 1316/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.2220 - accuracy: 0.9500 - val_loss: 0.5080 - val_accuracy: 0.7000\n",
      "Epoch 1317/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2145 - accuracy: 0.9375 - val_loss: 0.6368 - val_accuracy: 0.7500\n",
      "Epoch 1318/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.2034 - accuracy: 0.9375 - val_loss: 0.8021 - val_accuracy: 0.8000\n",
      "Epoch 1319/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2176 - accuracy: 0.9375 - val_loss: 0.7050 - val_accuracy: 0.8000\n",
      "Epoch 1320/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.1985 - accuracy: 0.9125 - val_loss: 0.6377 - val_accuracy: 0.7500\n",
      "Epoch 1321/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2006 - accuracy: 0.9250 - val_loss: 0.5912 - val_accuracy: 0.8000\n",
      "Epoch 1322/2000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.1975 - accuracy: 0.9375 - val_loss: 0.6001 - val_accuracy: 0.7500\n",
      "Epoch 1323/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2002 - accuracy: 0.9375 - val_loss: 0.6114 - val_accuracy: 0.7500\n",
      "Epoch 1324/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.1967 - accuracy: 0.9375 - val_loss: 0.6219 - val_accuracy: 0.8000\n",
      "Epoch 1325/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2026 - accuracy: 0.9375 - val_loss: 0.6502 - val_accuracy: 0.7500\n",
      "Epoch 1326/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.2082 - accuracy: 0.9375 - val_loss: 0.6893 - val_accuracy: 0.8000\n",
      "Epoch 1327/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.2031 - accuracy: 0.9250 - val_loss: 0.6891 - val_accuracy: 0.7500\n",
      "Epoch 1328/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 0.2016 - accuracy: 0.9250 - val_loss: 0.6041 - val_accuracy: 0.8000\n",
      "Epoch 1329/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.1980 - accuracy: 0.9500 - val_loss: 0.5873 - val_accuracy: 0.8000\n",
      "Epoch 1330/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.1979 - accuracy: 0.9500 - val_loss: 0.5939 - val_accuracy: 0.8000\n",
      "Epoch 1331/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.2019 - accuracy: 0.9375 - val_loss: 0.6425 - val_accuracy: 0.7500\n",
      "Epoch 1332/2000\n",
      "80/80 [==============================] - 0s 240us/sample - loss: 0.1990 - accuracy: 0.9250 - val_loss: 0.5981 - val_accuracy: 0.8000\n",
      "Epoch 1333/2000\n",
      "80/80 [==============================] - 0s 226us/sample - loss: 0.1937 - accuracy: 0.9500 - val_loss: 0.5728 - val_accuracy: 0.8000\n",
      "Epoch 1334/2000\n",
      "80/80 [==============================] - 0s 151us/sample - loss: 0.2014 - accuracy: 0.9500 - val_loss: 0.5817 - val_accuracy: 0.8000\n",
      "Epoch 1335/2000\n",
      "80/80 [==============================] - 0s 169us/sample - loss: 0.1919 - accuracy: 0.9375 - val_loss: 0.6432 - val_accuracy: 0.8000\n",
      "Epoch 1336/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2061 - accuracy: 0.9250 - val_loss: 0.6006 - val_accuracy: 0.7500\n",
      "Epoch 1337/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.1928 - accuracy: 0.9500 - val_loss: 0.5993 - val_accuracy: 0.8000\n",
      "Epoch 1338/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.2195 - accuracy: 0.9250 - val_loss: 0.6361 - val_accuracy: 0.8000\n",
      "Epoch 1339/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2011 - accuracy: 0.9250 - val_loss: 0.7729 - val_accuracy: 0.8000\n",
      "Epoch 1340/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.2185 - accuracy: 0.9375 - val_loss: 0.6424 - val_accuracy: 0.8000\n",
      "Epoch 1341/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2119 - accuracy: 0.9250 - val_loss: 0.6172 - val_accuracy: 0.7500\n",
      "Epoch 1342/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2083 - accuracy: 0.9375 - val_loss: 0.6465 - val_accuracy: 0.7500\n",
      "Epoch 1343/2000\n",
      "80/80 [==============================] - 0s 169us/sample - loss: 0.2229 - accuracy: 0.9125 - val_loss: 0.7827 - val_accuracy: 0.7500\n",
      "Epoch 1344/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2159 - accuracy: 0.9375 - val_loss: 0.6062 - val_accuracy: 0.7500\n",
      "Epoch 1345/2000\n",
      "80/80 [==============================] - 0s 156us/sample - loss: 0.2527 - accuracy: 0.9125 - val_loss: 0.6472 - val_accuracy: 0.7500\n",
      "Epoch 1346/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2061 - accuracy: 0.9125 - val_loss: 0.8209 - val_accuracy: 0.8000\n",
      "Epoch 1347/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2440 - accuracy: 0.9375 - val_loss: 0.8320 - val_accuracy: 0.8000\n",
      "Epoch 1348/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2140 - accuracy: 0.9375 - val_loss: 0.7121 - val_accuracy: 0.7500\n",
      "Epoch 1349/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.2237 - accuracy: 0.9125 - val_loss: 0.6560 - val_accuracy: 0.7500\n",
      "Epoch 1350/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.2282 - accuracy: 0.9250 - val_loss: 0.6217 - val_accuracy: 0.7500\n",
      "Epoch 1351/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.2058 - accuracy: 0.9375 - val_loss: 0.7044 - val_accuracy: 0.8000\n",
      "Epoch 1352/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2054 - accuracy: 0.9375 - val_loss: 0.6222 - val_accuracy: 0.8000\n",
      "Epoch 1353/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.1985 - accuracy: 0.9375 - val_loss: 0.6265 - val_accuracy: 0.7500\n",
      "Epoch 1354/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2147 - accuracy: 0.9250 - val_loss: 0.6566 - val_accuracy: 0.8000\n",
      "Epoch 1355/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 0.2014 - accuracy: 0.9250 - val_loss: 0.6905 - val_accuracy: 0.7500\n",
      "Epoch 1356/2000\n",
      "80/80 [==============================] - 0s 423us/sample - loss: 0.1995 - accuracy: 0.9250 - val_loss: 0.6046 - val_accuracy: 0.8000\n",
      "Epoch 1357/2000\n",
      "80/80 [==============================] - 0s 328us/sample - loss: 0.1942 - accuracy: 0.9375 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1358/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.1972 - accuracy: 0.9500 - val_loss: 0.5542 - val_accuracy: 0.8000\n",
      "Epoch 1359/2000\n",
      "80/80 [==============================] - 0s 74us/sample - loss: 0.2023 - accuracy: 0.9375 - val_loss: 0.6064 - val_accuracy: 0.7500\n",
      "Epoch 1360/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.1992 - accuracy: 0.9375 - val_loss: 0.5930 - val_accuracy: 0.8000\n",
      "Epoch 1361/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 0.1937 - accuracy: 0.9375 - val_loss: 0.6462 - val_accuracy: 0.8000\n",
      "Epoch 1362/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.2028 - accuracy: 0.9250 - val_loss: 0.6370 - val_accuracy: 0.8000\n",
      "Epoch 1363/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 0.2042 - accuracy: 0.9250 - val_loss: 0.5746 - val_accuracy: 0.8000\n",
      "Epoch 1364/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.1967 - accuracy: 0.9500 - val_loss: 0.5971 - val_accuracy: 0.8000\n",
      "Epoch 1365/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2025 - accuracy: 0.9250 - val_loss: 0.5752 - val_accuracy: 0.7500\n",
      "Epoch 1366/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.1974 - accuracy: 0.9375 - val_loss: 0.5786 - val_accuracy: 0.8000\n",
      "Epoch 1367/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.1968 - accuracy: 0.9125 - val_loss: 0.6107 - val_accuracy: 0.7500\n",
      "Epoch 1368/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.2046 - accuracy: 0.9250 - val_loss: 0.6766 - val_accuracy: 0.8000\n",
      "Epoch 1369/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2045 - accuracy: 0.9250 - val_loss: 0.6472 - val_accuracy: 0.8000\n",
      "Epoch 1370/2000\n",
      "80/80 [==============================] - 0s 309us/sample - loss: 0.1983 - accuracy: 0.9250 - val_loss: 0.5913 - val_accuracy: 0.8000\n",
      "Epoch 1371/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.2036 - accuracy: 0.9500 - val_loss: 0.5541 - val_accuracy: 0.8000\n",
      "Epoch 1372/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.1989 - accuracy: 0.9500 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
      "Epoch 1373/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.2022 - accuracy: 0.9250 - val_loss: 0.6184 - val_accuracy: 0.8000\n",
      "Epoch 1374/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 0.1908 - accuracy: 0.9250 - val_loss: 0.6287 - val_accuracy: 0.7500\n",
      "Epoch 1375/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 0.2180 - accuracy: 0.9250 - val_loss: 0.6459 - val_accuracy: 0.7500\n",
      "Epoch 1376/2000\n",
      "80/80 [==============================] - 0s 141us/sample - loss: 0.2227 - accuracy: 0.9000 - val_loss: 0.6758 - val_accuracy: 0.8000\n",
      "Epoch 1377/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.2005 - accuracy: 0.9250 - val_loss: 0.6146 - val_accuracy: 0.8000\n",
      "Epoch 1378/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2006 - accuracy: 0.9375 - val_loss: 0.5680 - val_accuracy: 0.8000\n",
      "Epoch 1379/2000\n",
      "80/80 [==============================] - 0s 130us/sample - loss: 0.2013 - accuracy: 0.9375 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
      "Epoch 1380/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2005 - accuracy: 0.9625 - val_loss: 0.6525 - val_accuracy: 0.8000\n",
      "Epoch 1381/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.2005 - accuracy: 0.9250 - val_loss: 0.6329 - val_accuracy: 0.8000\n",
      "Epoch 1382/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.2039 - accuracy: 0.9125 - val_loss: 0.6075 - val_accuracy: 0.7500\n",
      "Epoch 1383/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2053 - accuracy: 0.9250 - val_loss: 0.6377 - val_accuracy: 0.7500\n",
      "Epoch 1384/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2032 - accuracy: 0.9375 - val_loss: 0.6006 - val_accuracy: 0.7500\n",
      "Epoch 1385/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2065 - accuracy: 0.9250 - val_loss: 0.5785 - val_accuracy: 0.8000\n",
      "Epoch 1386/2000\n",
      "80/80 [==============================] - 0s 77us/sample - loss: 0.2001 - accuracy: 0.9250 - val_loss: 0.6397 - val_accuracy: 0.8000\n",
      "Epoch 1387/2000\n",
      "80/80 [==============================] - 0s 488us/sample - loss: 0.1964 - accuracy: 0.9250 - val_loss: 0.6433 - val_accuracy: 0.8000\n",
      "Epoch 1388/2000\n",
      "80/80 [==============================] - 0s 474us/sample - loss: 0.2076 - accuracy: 0.9250 - val_loss: 0.6301 - val_accuracy: 0.7500\n",
      "Epoch 1389/2000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.2057 - accuracy: 0.9500 - val_loss: 0.6467 - val_accuracy: 0.8000\n",
      "Epoch 1390/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.1928 - accuracy: 0.9250 - val_loss: 0.6485 - val_accuracy: 0.8000\n",
      "Epoch 1391/2000\n",
      "80/80 [==============================] - 0s 207us/sample - loss: 0.2016 - accuracy: 0.9250 - val_loss: 0.5986 - val_accuracy: 0.7500\n",
      "Epoch 1392/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.1984 - accuracy: 0.9500 - val_loss: 0.5859 - val_accuracy: 0.7500\n",
      "Epoch 1393/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.1958 - accuracy: 0.9250 - val_loss: 0.6221 - val_accuracy: 0.7500\n",
      "Epoch 1394/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.1951 - accuracy: 0.9250 - val_loss: 0.5929 - val_accuracy: 0.8000\n",
      "Epoch 1395/2000\n",
      "80/80 [==============================] - 0s 163us/sample - loss: 0.1998 - accuracy: 0.9375 - val_loss: 0.6053 - val_accuracy: 0.7500\n",
      "Epoch 1396/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1943 - accuracy: 0.9500 - val_loss: 0.6735 - val_accuracy: 0.8000\n",
      "Epoch 1397/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.2085 - accuracy: 0.9375 - val_loss: 0.5592 - val_accuracy: 0.8000\n",
      "Epoch 1398/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.1956 - accuracy: 0.9375 - val_loss: 0.5729 - val_accuracy: 0.7500\n",
      "Epoch 1399/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.2044 - accuracy: 0.9375 - val_loss: 0.6187 - val_accuracy: 0.8000\n",
      "Epoch 1400/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.1975 - accuracy: 0.9250 - val_loss: 0.6460 - val_accuracy: 0.8000\n",
      "Epoch 1401/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.1969 - accuracy: 0.9250 - val_loss: 0.6267 - val_accuracy: 0.7500\n",
      "Epoch 1402/2000\n",
      "80/80 [==============================] - 0s 62us/sample - loss: 0.1940 - accuracy: 0.9250 - val_loss: 0.5474 - val_accuracy: 0.8000\n",
      "Epoch 1403/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.1963 - accuracy: 0.9375 - val_loss: 0.5610 - val_accuracy: 0.8000\n",
      "Epoch 1404/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.1988 - accuracy: 0.9375 - val_loss: 0.6030 - val_accuracy: 0.8000\n",
      "Epoch 1405/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 0.1940 - accuracy: 0.9375 - val_loss: 0.5916 - val_accuracy: 0.8000\n",
      "Epoch 1406/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.1927 - accuracy: 0.9500 - val_loss: 0.6010 - val_accuracy: 0.7500\n",
      "Epoch 1407/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.1935 - accuracy: 0.9375 - val_loss: 0.5923 - val_accuracy: 0.7500\n",
      "Epoch 1408/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.1923 - accuracy: 0.9500 - val_loss: 0.5571 - val_accuracy: 0.8000\n",
      "Epoch 1409/2000\n",
      "80/80 [==============================] - 0s 216us/sample - loss: 0.1979 - accuracy: 0.9500 - val_loss: 0.5792 - val_accuracy: 0.8000\n",
      "Epoch 1410/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.2009 - accuracy: 0.9250 - val_loss: 0.5879 - val_accuracy: 0.8000\n",
      "Epoch 1411/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.1939 - accuracy: 0.9375 - val_loss: 0.5690 - val_accuracy: 0.8000\n",
      "Epoch 1412/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2031 - accuracy: 0.9375 - val_loss: 0.5482 - val_accuracy: 0.8000\n",
      "Epoch 1413/2000\n",
      "80/80 [==============================] - 0s 147us/sample - loss: 0.1976 - accuracy: 0.9250 - val_loss: 0.5494 - val_accuracy: 0.7500\n",
      "Epoch 1414/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.1953 - accuracy: 0.9375 - val_loss: 0.6212 - val_accuracy: 0.8000\n",
      "Epoch 1415/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2053 - accuracy: 0.9250 - val_loss: 0.6186 - val_accuracy: 0.7500\n",
      "Epoch 1416/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.1929 - accuracy: 0.9250 - val_loss: 0.5553 - val_accuracy: 0.8000\n",
      "Epoch 1417/2000\n",
      "80/80 [==============================] - 0s 497us/sample - loss: 0.2177 - accuracy: 0.9250 - val_loss: 0.5387 - val_accuracy: 0.8000\n",
      "Epoch 1418/2000\n",
      "80/80 [==============================] - 0s 279us/sample - loss: 0.1894 - accuracy: 0.9500 - val_loss: 0.6756 - val_accuracy: 0.7500\n",
      "Epoch 1419/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.2272 - accuracy: 0.9500 - val_loss: 0.5269 - val_accuracy: 0.8000\n",
      "Epoch 1420/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.2509 - accuracy: 0.9375 - val_loss: 0.6719 - val_accuracy: 0.7500\n",
      "Epoch 1421/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2270 - accuracy: 0.9375 - val_loss: 0.9151 - val_accuracy: 0.8000\n",
      "Epoch 1422/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2704 - accuracy: 0.9250 - val_loss: 1.1471 - val_accuracy: 0.6500\n",
      "Epoch 1423/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.2708 - accuracy: 0.9250 - val_loss: 0.8699 - val_accuracy: 0.7500\n",
      "Epoch 1424/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2278 - accuracy: 0.9000 - val_loss: 0.7417 - val_accuracy: 0.7500\n",
      "Epoch 1425/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.2378 - accuracy: 0.9125 - val_loss: 0.5990 - val_accuracy: 0.7500\n",
      "Epoch 1426/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2030 - accuracy: 0.9375 - val_loss: 0.6880 - val_accuracy: 0.7500\n",
      "Epoch 1427/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2360 - accuracy: 0.9375 - val_loss: 0.5664 - val_accuracy: 0.7500\n",
      "Epoch 1428/2000\n",
      "80/80 [==============================] - 0s 77us/sample - loss: 0.2112 - accuracy: 0.9500 - val_loss: 0.6208 - val_accuracy: 0.7500\n",
      "Epoch 1429/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2074 - accuracy: 0.9375 - val_loss: 0.7143 - val_accuracy: 0.8000\n",
      "Epoch 1430/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2334 - accuracy: 0.9125 - val_loss: 0.7683 - val_accuracy: 0.7500\n",
      "Epoch 1431/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.2042 - accuracy: 0.9250 - val_loss: 0.6425 - val_accuracy: 0.7500\n",
      "Epoch 1432/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2051 - accuracy: 0.9375 - val_loss: 0.5658 - val_accuracy: 0.7500\n",
      "Epoch 1433/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.1985 - accuracy: 0.9375 - val_loss: 0.5930 - val_accuracy: 0.8000\n",
      "Epoch 1434/2000\n",
      "80/80 [==============================] - 0s 223us/sample - loss: 0.2040 - accuracy: 0.9500 - val_loss: 0.5330 - val_accuracy: 0.8000\n",
      "Epoch 1435/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.1955 - accuracy: 0.9500 - val_loss: 0.6080 - val_accuracy: 0.7500\n",
      "Epoch 1436/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2029 - accuracy: 0.9125 - val_loss: 0.6462 - val_accuracy: 0.7500\n",
      "Epoch 1437/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2046 - accuracy: 0.9250 - val_loss: 0.6061 - val_accuracy: 0.7500\n",
      "Epoch 1438/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.1967 - accuracy: 0.9500 - val_loss: 0.5797 - val_accuracy: 0.8000\n",
      "Epoch 1439/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.1923 - accuracy: 0.9375 - val_loss: 0.5912 - val_accuracy: 0.7500\n",
      "Epoch 1440/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2251 - accuracy: 0.9250 - val_loss: 0.6008 - val_accuracy: 0.7500\n",
      "Epoch 1441/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.1927 - accuracy: 0.9125 - val_loss: 0.6090 - val_accuracy: 0.7500\n",
      "Epoch 1442/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2190 - accuracy: 0.9375 - val_loss: 0.6434 - val_accuracy: 0.8000\n",
      "Epoch 1443/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.1910 - accuracy: 0.9250 - val_loss: 0.6873 - val_accuracy: 0.7500\n",
      "Epoch 1444/2000\n",
      "80/80 [==============================] - 0s 77us/sample - loss: 0.1988 - accuracy: 0.9250 - val_loss: 0.6871 - val_accuracy: 0.8000\n",
      "Epoch 1445/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.1954 - accuracy: 0.9250 - val_loss: 0.6388 - val_accuracy: 0.8000\n",
      "Epoch 1446/2000\n",
      "80/80 [==============================] - 0s 599us/sample - loss: 0.1947 - accuracy: 0.9250 - val_loss: 0.6180 - val_accuracy: 0.8000\n",
      "Epoch 1447/2000\n",
      "80/80 [==============================] - 0s 288us/sample - loss: 0.1952 - accuracy: 0.9375 - val_loss: 0.6089 - val_accuracy: 0.8000\n",
      "Epoch 1448/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 0.1938 - accuracy: 0.9375 - val_loss: 0.6314 - val_accuracy: 0.8000\n",
      "Epoch 1449/2000\n",
      "80/80 [==============================] - 0s 250us/sample - loss: 0.2033 - accuracy: 0.9250 - val_loss: 0.5709 - val_accuracy: 0.7500\n",
      "Epoch 1450/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.1929 - accuracy: 0.9500 - val_loss: 0.5904 - val_accuracy: 0.8000\n",
      "Epoch 1451/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.1951 - accuracy: 0.9250 - val_loss: 0.6354 - val_accuracy: 0.8000\n",
      "Epoch 1452/2000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.1969 - accuracy: 0.9250 - val_loss: 0.6173 - val_accuracy: 0.8000\n",
      "Epoch 1453/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.1955 - accuracy: 0.9375 - val_loss: 0.5985 - val_accuracy: 0.8000\n",
      "Epoch 1454/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.1943 - accuracy: 0.9375 - val_loss: 0.6249 - val_accuracy: 0.7500\n",
      "Epoch 1455/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.1933 - accuracy: 0.9250 - val_loss: 0.5887 - val_accuracy: 0.8000\n",
      "Epoch 1456/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.1959 - accuracy: 0.9500 - val_loss: 0.6043 - val_accuracy: 0.7500\n",
      "Epoch 1457/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2069 - accuracy: 0.9125 - val_loss: 0.6554 - val_accuracy: 0.8000\n",
      "Epoch 1458/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.1966 - accuracy: 0.9250 - val_loss: 0.6081 - val_accuracy: 0.7500\n",
      "Epoch 1459/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.2022 - accuracy: 0.9250 - val_loss: 0.5375 - val_accuracy: 0.8000\n",
      "Epoch 1460/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.1951 - accuracy: 0.9375 - val_loss: 0.5384 - val_accuracy: 0.7500\n",
      "Epoch 1461/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2316 - accuracy: 0.9250 - val_loss: 0.6123 - val_accuracy: 0.8000\n",
      "Epoch 1462/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.2093 - accuracy: 0.9250 - val_loss: 0.8978 - val_accuracy: 0.6500\n",
      "Epoch 1463/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2381 - accuracy: 0.9250 - val_loss: 0.7009 - val_accuracy: 0.7500\n",
      "Epoch 1464/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2278 - accuracy: 0.9000 - val_loss: 0.6567 - val_accuracy: 0.7500\n",
      "Epoch 1465/2000\n",
      "80/80 [==============================] - 0s 231us/sample - loss: 0.2280 - accuracy: 0.9375 - val_loss: 0.6449 - val_accuracy: 0.7500\n",
      "Epoch 1466/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1871 - accuracy: 0.96 - 0s 98us/sample - loss: 0.2013 - accuracy: 0.9375 - val_loss: 0.6941 - val_accuracy: 0.8000\n",
      "Epoch 1467/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2069 - accuracy: 0.9375 - val_loss: 0.5720 - val_accuracy: 0.7500\n",
      "Epoch 1468/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2005 - accuracy: 0.9500 - val_loss: 0.6092 - val_accuracy: 0.7500\n",
      "Epoch 1469/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 0.2112 - accuracy: 0.9375 - val_loss: 0.6886 - val_accuracy: 0.8000\n",
      "Epoch 1470/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2045 - accuracy: 0.9250 - val_loss: 0.7800 - val_accuracy: 0.7500\n",
      "Epoch 1471/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2123 - accuracy: 0.9375 - val_loss: 0.6843 - val_accuracy: 0.8000\n",
      "Epoch 1472/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.1951 - accuracy: 0.9375 - val_loss: 0.6225 - val_accuracy: 0.7500\n",
      "Epoch 1473/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.2226 - accuracy: 0.9250 - val_loss: 0.5814 - val_accuracy: 0.8000\n",
      "Epoch 1474/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.1971 - accuracy: 0.9500 - val_loss: 0.6356 - val_accuracy: 0.7500\n",
      "Epoch 1475/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 0.1963 - accuracy: 0.9250 - val_loss: 0.7063 - val_accuracy: 0.7500\n",
      "Epoch 1476/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 0.1992 - accuracy: 0.9250 - val_loss: 0.6432 - val_accuracy: 0.8000\n",
      "Epoch 1477/2000\n",
      "80/80 [==============================] - 0s 624us/sample - loss: 0.2190 - accuracy: 0.9125 - val_loss: 0.6279 - val_accuracy: 0.7500\n",
      "Epoch 1478/2000\n",
      "80/80 [==============================] - 0s 202us/sample - loss: 0.2134 - accuracy: 0.8875 - val_loss: 0.6470 - val_accuracy: 0.7500\n",
      "Epoch 1479/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.1989 - accuracy: 0.9250 - val_loss: 0.5793 - val_accuracy: 0.8000\n",
      "Epoch 1480/2000\n",
      "80/80 [==============================] - 0s 200us/sample - loss: 0.2073 - accuracy: 0.9375 - val_loss: 0.5159 - val_accuracy: 0.8000\n",
      "Epoch 1481/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.1973 - accuracy: 0.9500 - val_loss: 0.6132 - val_accuracy: 0.8000\n",
      "Epoch 1482/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2075 - accuracy: 0.9375 - val_loss: 0.6253 - val_accuracy: 0.8000\n",
      "Epoch 1483/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.1923 - accuracy: 0.9125 - val_loss: 0.6514 - val_accuracy: 0.7500\n",
      "Epoch 1484/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2079 - accuracy: 0.9000 - val_loss: 0.6843 - val_accuracy: 0.7500\n",
      "Epoch 1485/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2019 - accuracy: 0.9125 - val_loss: 0.6731 - val_accuracy: 0.8000\n",
      "Epoch 1486/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.1939 - accuracy: 0.9125 - val_loss: 0.5890 - val_accuracy: 0.8000\n",
      "Epoch 1487/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2018 - accuracy: 0.9250 - val_loss: 0.5660 - val_accuracy: 0.7500\n",
      "Epoch 1488/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.1931 - accuracy: 0.9375 - val_loss: 0.5867 - val_accuracy: 0.8000\n",
      "Epoch 1489/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.1941 - accuracy: 0.9250 - val_loss: 0.6255 - val_accuracy: 0.8000\n",
      "Epoch 1490/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.1923 - accuracy: 0.9375 - val_loss: 0.6044 - val_accuracy: 0.8000\n",
      "Epoch 1491/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 0.1946 - accuracy: 0.9125 - val_loss: 0.5954 - val_accuracy: 0.8000\n",
      "Epoch 1492/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2057 - accuracy: 0.9000 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 1493/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.1914 - accuracy: 0.9250 - val_loss: 0.6382 - val_accuracy: 0.8000\n",
      "Epoch 1494/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2051 - accuracy: 0.9250 - val_loss: 0.6010 - val_accuracy: 0.8000\n",
      "Epoch 1495/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.1919 - accuracy: 0.9250 - val_loss: 0.5813 - val_accuracy: 0.8000\n",
      "Epoch 1496/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.1937 - accuracy: 0.9375 - val_loss: 0.6069 - val_accuracy: 0.7500\n",
      "Epoch 1497/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.2041 - accuracy: 0.9375 - val_loss: 0.6378 - val_accuracy: 0.8000\n",
      "Epoch 1498/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.1897 - accuracy: 0.9250 - val_loss: 0.7054 - val_accuracy: 0.8000\n",
      "Epoch 1499/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.2260 - accuracy: 0.9375 - val_loss: 0.6591 - val_accuracy: 0.7500\n",
      "Epoch 1500/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.1946 - accuracy: 0.9125 - val_loss: 0.6056 - val_accuracy: 0.7500\n",
      "Epoch 1501/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2206 - accuracy: 0.9250 - val_loss: 0.6528 - val_accuracy: 0.8000\n",
      "Epoch 1502/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.1879 - accuracy: 0.9500 - val_loss: 0.8930 - val_accuracy: 0.7500\n",
      "Epoch 1503/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.2518 - accuracy: 0.9250 - val_loss: 0.7060 - val_accuracy: 0.8000\n",
      "Epoch 1504/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.1941 - accuracy: 0.9375 - val_loss: 0.6582 - val_accuracy: 0.7500\n",
      "Epoch 1505/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2072 - accuracy: 0.9250 - val_loss: 0.6066 - val_accuracy: 0.8000\n",
      "Epoch 1506/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.1900 - accuracy: 0.9375 - val_loss: 0.6089 - val_accuracy: 0.7500\n",
      "Epoch 1507/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.2006 - accuracy: 0.9375 - val_loss: 0.5779 - val_accuracy: 0.7500\n",
      "Epoch 1508/2000\n",
      "80/80 [==============================] - 0s 254us/sample - loss: 0.1962 - accuracy: 0.9375 - val_loss: 0.6022 - val_accuracy: 0.7500\n",
      "Epoch 1509/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.1967 - accuracy: 0.9375 - val_loss: 0.6310 - val_accuracy: 0.8000\n",
      "Epoch 1510/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.1963 - accuracy: 0.9500 - val_loss: 0.6381 - val_accuracy: 0.8000\n",
      "Epoch 1511/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.1909 - accuracy: 0.9250 - val_loss: 0.6780 - val_accuracy: 0.7500\n",
      "Epoch 1512/2000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.2006 - accuracy: 0.9250 - val_loss: 0.6357 - val_accuracy: 0.8000\n",
      "Epoch 1513/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.1948 - accuracy: 0.9375 - val_loss: 0.6026 - val_accuracy: 0.7500\n",
      "Epoch 1514/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.1944 - accuracy: 0.9375 - val_loss: 0.6155 - val_accuracy: 0.7500\n",
      "Epoch 1515/2000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.1998 - accuracy: 0.9250 - val_loss: 0.6153 - val_accuracy: 0.7500\n",
      "Epoch 1516/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.1962 - accuracy: 0.9250 - val_loss: 0.5588 - val_accuracy: 0.8000\n",
      "Epoch 1517/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.1894 - accuracy: 0.9375 - val_loss: 0.5841 - val_accuracy: 0.8000\n",
      "Epoch 1518/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.1992 - accuracy: 0.9250 - val_loss: 0.5904 - val_accuracy: 0.8000\n",
      "Epoch 1519/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.1961 - accuracy: 0.9500 - val_loss: 0.5566 - val_accuracy: 0.7500\n",
      "Epoch 1520/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2106 - accuracy: 0.9250 - val_loss: 0.5807 - val_accuracy: 0.8000\n",
      "Epoch 1521/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.1895 - accuracy: 0.9500 - val_loss: 0.5609 - val_accuracy: 0.8000\n",
      "Epoch 1522/2000\n",
      "80/80 [==============================] - 0s 216us/sample - loss: 0.1920 - accuracy: 0.9500 - val_loss: 0.5499 - val_accuracy: 0.8000\n",
      "Epoch 1523/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 0.1978 - accuracy: 0.9375 - val_loss: 0.5666 - val_accuracy: 0.8000\n",
      "Epoch 1524/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.2048 - accuracy: 0.9375 - val_loss: 0.5538 - val_accuracy: 0.8000\n",
      "Epoch 1525/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.1926 - accuracy: 0.9250 - val_loss: 0.6245 - val_accuracy: 0.8000\n",
      "Epoch 1526/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.1991 - accuracy: 0.9250 - val_loss: 0.5863 - val_accuracy: 0.8000\n",
      "Epoch 1527/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.1919 - accuracy: 0.9500 - val_loss: 0.5767 - val_accuracy: 0.8000\n",
      "Epoch 1528/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.1926 - accuracy: 0.9375 - val_loss: 0.5897 - val_accuracy: 0.8000\n",
      "Epoch 1529/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.2153 - accuracy: 0.9250 - val_loss: 0.6065 - val_accuracy: 0.8000\n",
      "Epoch 1530/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.1908 - accuracy: 0.9500 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
      "Epoch 1531/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2142 - accuracy: 0.9250 - val_loss: 0.5540 - val_accuracy: 0.8000\n",
      "Epoch 1532/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.1904 - accuracy: 0.9375 - val_loss: 0.6473 - val_accuracy: 0.8000\n",
      "Epoch 1533/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2045 - accuracy: 0.9250 - val_loss: 0.6392 - val_accuracy: 0.8000\n",
      "Epoch 1534/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.1891 - accuracy: 0.9125 - val_loss: 0.5741 - val_accuracy: 0.7500\n",
      "Epoch 1535/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.2264 - accuracy: 0.9375 - val_loss: 0.5640 - val_accuracy: 0.8000\n",
      "Epoch 1536/2000\n",
      "80/80 [==============================] - 0s 707us/sample - loss: 0.2017 - accuracy: 0.9375 - val_loss: 0.6727 - val_accuracy: 0.8000\n",
      "Epoch 1537/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.2018 - accuracy: 0.9375 - val_loss: 0.5990 - val_accuracy: 0.8000\n",
      "Epoch 1538/2000\n",
      "80/80 [==============================] - 0s 272us/sample - loss: 0.2001 - accuracy: 0.9375 - val_loss: 0.5792 - val_accuracy: 0.7500\n",
      "Epoch 1539/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.1945 - accuracy: 0.9500 - val_loss: 0.6212 - val_accuracy: 0.8000\n",
      "Epoch 1540/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.1952 - accuracy: 0.9250 - val_loss: 0.6373 - val_accuracy: 0.8000\n",
      "Epoch 1541/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.1973 - accuracy: 0.9250 - val_loss: 0.5912 - val_accuracy: 0.8000\n",
      "Epoch 1542/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.1881 - accuracy: 0.9500 - val_loss: 0.5632 - val_accuracy: 0.8000\n",
      "Epoch 1543/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.1986 - accuracy: 0.9500 - val_loss: 0.5971 - val_accuracy: 0.8000\n",
      "Epoch 1544/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2001 - accuracy: 0.9125 - val_loss: 0.6746 - val_accuracy: 0.8000\n",
      "Epoch 1545/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.1900 - accuracy: 0.9250 - val_loss: 0.6118 - val_accuracy: 0.7500\n",
      "Epoch 1546/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2221 - accuracy: 0.9375 - val_loss: 0.6006 - val_accuracy: 0.7500\n",
      "Epoch 1547/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.1918 - accuracy: 0.9375 - val_loss: 0.6816 - val_accuracy: 0.8000\n",
      "Epoch 1548/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.2137 - accuracy: 0.9375 - val_loss: 0.5865 - val_accuracy: 0.8000\n",
      "Epoch 1549/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.1893 - accuracy: 0.9500 - val_loss: 0.5238 - val_accuracy: 0.8000\n",
      "Epoch 1550/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.1993 - accuracy: 0.9500 - val_loss: 0.5812 - val_accuracy: 0.7500\n",
      "Epoch 1551/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.1902 - accuracy: 0.9250 - val_loss: 0.6652 - val_accuracy: 0.8000\n",
      "Epoch 1552/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2219 - accuracy: 0.9250 - val_loss: 0.7094 - val_accuracy: 0.8000\n",
      "Epoch 1553/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.2029 - accuracy: 0.9125 - val_loss: 0.6538 - val_accuracy: 0.7500\n",
      "Epoch 1554/2000\n",
      "80/80 [==============================] - 0s 274us/sample - loss: 0.2117 - accuracy: 0.9250 - val_loss: 0.6444 - val_accuracy: 0.8000\n",
      "Epoch 1555/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.1957 - accuracy: 0.9375 - val_loss: 0.7059 - val_accuracy: 0.8000\n",
      "Epoch 1556/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2061 - accuracy: 0.9250 - val_loss: 0.5626 - val_accuracy: 0.8000\n",
      "Epoch 1557/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.1975 - accuracy: 0.9500 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
      "Epoch 1558/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1981 - accuracy: 0.9375 - val_loss: 0.6327 - val_accuracy: 0.8000\n",
      "Epoch 1559/2000\n",
      "80/80 [==============================] - 0s 26us/sample - loss: 0.2095 - accuracy: 0.9250 - val_loss: 0.7685 - val_accuracy: 0.8000\n",
      "Epoch 1560/2000\n",
      "80/80 [==============================] - 0s 206us/sample - loss: 0.2213 - accuracy: 0.9500 - val_loss: 0.6140 - val_accuracy: 0.8000\n",
      "Epoch 1561/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2089 - accuracy: 0.9375 - val_loss: 0.6001 - val_accuracy: 0.7500\n",
      "Epoch 1562/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.2082 - accuracy: 0.9250 - val_loss: 0.6253 - val_accuracy: 0.7500\n",
      "Epoch 1563/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.1948 - accuracy: 0.9250 - val_loss: 0.6914 - val_accuracy: 0.8000\n",
      "Epoch 1564/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.1967 - accuracy: 0.9250 - val_loss: 0.5733 - val_accuracy: 0.8000\n",
      "Epoch 1565/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.2011 - accuracy: 0.9500 - val_loss: 0.5813 - val_accuracy: 0.8000\n",
      "Epoch 1566/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2021 - accuracy: 0.9250 - val_loss: 0.7106 - val_accuracy: 0.8000\n",
      "Epoch 1567/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2017 - accuracy: 0.9250 - val_loss: 0.6972 - val_accuracy: 0.7500\n",
      "Epoch 1568/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 0.2006 - accuracy: 0.9250 - val_loss: 0.6308 - val_accuracy: 0.8000\n",
      "Epoch 1569/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.1905 - accuracy: 0.9500 - val_loss: 0.5924 - val_accuracy: 0.8000\n",
      "Epoch 1570/2000\n",
      "80/80 [==============================] - 0s 355us/sample - loss: 0.1921 - accuracy: 0.9500 - val_loss: 0.5716 - val_accuracy: 0.8000\n",
      "Epoch 1571/2000\n",
      "80/80 [==============================] - 0s 458us/sample - loss: 0.1914 - accuracy: 0.9500 - val_loss: 0.5460 - val_accuracy: 0.8000\n",
      "Epoch 1572/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.1895 - accuracy: 0.9500 - val_loss: 0.5795 - val_accuracy: 0.8000\n",
      "Epoch 1573/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.1935 - accuracy: 0.9500 - val_loss: 0.6028 - val_accuracy: 0.8000\n",
      "Epoch 1574/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.1991 - accuracy: 0.9250 - val_loss: 0.6063 - val_accuracy: 0.7500\n",
      "Epoch 1575/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.1919 - accuracy: 0.9375 - val_loss: 0.6331 - val_accuracy: 0.8000\n",
      "Epoch 1576/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.1920 - accuracy: 0.9250 - val_loss: 0.6175 - val_accuracy: 0.8000\n",
      "Epoch 1577/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.1931 - accuracy: 0.9250 - val_loss: 0.5546 - val_accuracy: 0.8000\n",
      "Epoch 1578/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.1898 - accuracy: 0.9375 - val_loss: 0.5489 - val_accuracy: 0.8000\n",
      "Epoch 1579/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.1874 - accuracy: 0.9500 - val_loss: 0.6008 - val_accuracy: 0.8000\n",
      "Epoch 1580/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.1907 - accuracy: 0.9375 - val_loss: 0.6135 - val_accuracy: 0.8000\n",
      "Epoch 1581/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.1888 - accuracy: 0.9500 - val_loss: 0.5811 - val_accuracy: 0.8000\n",
      "Epoch 1582/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.1909 - accuracy: 0.9500 - val_loss: 0.5686 - val_accuracy: 0.8000\n",
      "Epoch 1583/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.1859 - accuracy: 0.9500 - val_loss: 0.6085 - val_accuracy: 0.8000\n",
      "Epoch 1584/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.1974 - accuracy: 0.9250 - val_loss: 0.6147 - val_accuracy: 0.8000\n",
      "Epoch 1585/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.1957 - accuracy: 0.9250 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
      "Epoch 1586/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.2026 - accuracy: 0.9375 - val_loss: 0.5749 - val_accuracy: 0.7500\n",
      "Epoch 1587/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.1929 - accuracy: 0.9375 - val_loss: 0.6668 - val_accuracy: 0.8000\n",
      "Epoch 1588/2000\n",
      "80/80 [==============================] - 0s 224us/sample - loss: 0.2056 - accuracy: 0.9375 - val_loss: 0.6832 - val_accuracy: 0.8000\n",
      "Epoch 1589/2000\n",
      "80/80 [==============================] - 0s 140us/sample - loss: 0.1920 - accuracy: 0.9375 - val_loss: 0.6172 - val_accuracy: 0.7500\n",
      "Epoch 1590/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.2294 - accuracy: 0.9250 - val_loss: 0.6452 - val_accuracy: 0.7500\n",
      "Epoch 1591/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.2010 - accuracy: 0.9250 - val_loss: 0.7106 - val_accuracy: 0.8000\n",
      "Epoch 1592/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.2524 - accuracy: 0.9500 - val_loss: 0.7759 - val_accuracy: 0.8000\n",
      "Epoch 1593/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.2047 - accuracy: 0.9250 - val_loss: 0.5747 - val_accuracy: 0.7500\n",
      "Epoch 1594/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.2530 - accuracy: 0.9125 - val_loss: 0.5996 - val_accuracy: 0.7500\n",
      "Epoch 1595/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.1947 - accuracy: 0.9375 - val_loss: 0.8121 - val_accuracy: 0.8000\n",
      "Epoch 1596/2000\n",
      "80/80 [==============================] - 0s 135us/sample - loss: 0.2267 - accuracy: 0.9375 - val_loss: 0.7434 - val_accuracy: 0.7500\n",
      "Epoch 1597/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2187 - accuracy: 0.9000 - val_loss: 0.6504 - val_accuracy: 0.7500\n",
      "Epoch 1598/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.1986 - accuracy: 0.9250 - val_loss: 0.6149 - val_accuracy: 0.8000\n",
      "Epoch 1599/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2051 - accuracy: 0.9250 - val_loss: 0.6377 - val_accuracy: 0.8000\n",
      "Epoch 1600/2000\n",
      "80/80 [==============================] - 0s 516us/sample - loss: 0.2124 - accuracy: 0.9500 - val_loss: 0.5696 - val_accuracy: 0.8000\n",
      "Epoch 1601/2000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.1914 - accuracy: 0.9375 - val_loss: 0.6724 - val_accuracy: 0.8000\n",
      "Epoch 1602/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2007 - accuracy: 0.9250 - val_loss: 0.7467 - val_accuracy: 0.8000\n",
      "Epoch 1603/2000\n",
      "80/80 [==============================] - 0s 180us/sample - loss: 0.2136 - accuracy: 0.9375 - val_loss: 0.6650 - val_accuracy: 0.7500\n",
      "Epoch 1604/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.1987 - accuracy: 0.9250 - val_loss: 0.5973 - val_accuracy: 0.8000\n",
      "Epoch 1605/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.1852 - accuracy: 0.9375 - val_loss: 0.5865 - val_accuracy: 0.8000\n",
      "Epoch 1606/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.2166 - accuracy: 0.93 - 0s 259us/sample - loss: 0.1962 - accuracy: 0.9375 - val_loss: 0.5307 - val_accuracy: 0.8000\n",
      "Epoch 1607/2000\n",
      "80/80 [==============================] - 0s 163us/sample - loss: 0.1908 - accuracy: 0.9500 - val_loss: 0.5010 - val_accuracy: 0.8000\n",
      "Epoch 1608/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.2113 - accuracy: 0.9375 - val_loss: 0.5980 - val_accuracy: 0.7500\n",
      "Epoch 1609/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.1967 - accuracy: 0.9250 - val_loss: 0.7419 - val_accuracy: 0.8000\n",
      "Epoch 1610/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2056 - accuracy: 0.9375 - val_loss: 0.6657 - val_accuracy: 0.8000\n",
      "Epoch 1611/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 0.2022 - accuracy: 0.9125 - val_loss: 0.5801 - val_accuracy: 0.7500\n",
      "Epoch 1612/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2018 - accuracy: 0.9375 - val_loss: 0.5690 - val_accuracy: 0.8000\n",
      "Epoch 1613/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.1896 - accuracy: 0.9375 - val_loss: 0.5852 - val_accuracy: 0.7500\n",
      "Epoch 1614/2000\n",
      "80/80 [==============================] - 0s 77us/sample - loss: 0.1952 - accuracy: 0.9375 - val_loss: 0.6280 - val_accuracy: 0.8000\n",
      "Epoch 1615/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.1965 - accuracy: 0.9250 - val_loss: 0.6609 - val_accuracy: 0.8000\n",
      "Epoch 1616/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.1980 - accuracy: 0.9375 - val_loss: 0.5938 - val_accuracy: 0.8000\n",
      "Epoch 1617/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.2099 - accuracy: 0.9125 - val_loss: 0.6019 - val_accuracy: 0.8000\n",
      "Epoch 1618/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.1896 - accuracy: 0.9250 - val_loss: 0.6654 - val_accuracy: 0.8000\n",
      "Epoch 1619/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.1996 - accuracy: 0.9375 - val_loss: 0.5980 - val_accuracy: 0.7500\n",
      "Epoch 1620/2000\n",
      "80/80 [==============================] - 0s 60us/sample - loss: 0.1882 - accuracy: 0.9375 - val_loss: 0.5754 - val_accuracy: 0.7500\n",
      "Epoch 1621/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 0.1996 - accuracy: 0.9250 - val_loss: 0.5712 - val_accuracy: 0.7500\n",
      "Epoch 1622/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.1884 - accuracy: 0.9375 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
      "Epoch 1623/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.2024 - accuracy: 0.9375 - val_loss: 0.5954 - val_accuracy: 0.8000\n",
      "Epoch 1624/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.1971 - accuracy: 0.9250 - val_loss: 0.7086 - val_accuracy: 0.8000\n",
      "Epoch 1625/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.2107 - accuracy: 0.9250 - val_loss: 0.6459 - val_accuracy: 0.8000\n",
      "Epoch 1626/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.1969 - accuracy: 0.9375 - val_loss: 0.6423 - val_accuracy: 0.8000\n",
      "Epoch 1627/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.1916 - accuracy: 0.9250 - val_loss: 0.5889 - val_accuracy: 0.8000\n",
      "Epoch 1628/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.1860 - accuracy: 0.9375 - val_loss: 0.5250 - val_accuracy: 0.7500\n",
      "Epoch 1629/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2006 - accuracy: 0.9500 - val_loss: 0.5464 - val_accuracy: 0.8000\n",
      "Epoch 1630/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1923 - accuracy: 0.9500 - val_loss: 0.6150 - val_accuracy: 0.8000\n",
      "Epoch 1631/2000\n",
      "80/80 [==============================] - 0s 748us/sample - loss: 0.1917 - accuracy: 0.9375 - val_loss: 0.6064 - val_accuracy: 0.8000\n",
      "Epoch 1632/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.1873 - accuracy: 0.9375 - val_loss: 0.6152 - val_accuracy: 0.8000\n",
      "Epoch 1633/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.1878 - accuracy: 0.9500 - val_loss: 0.6020 - val_accuracy: 0.8000\n",
      "Epoch 1634/2000\n",
      "80/80 [==============================] - 0s 299us/sample - loss: 0.1903 - accuracy: 0.9375 - val_loss: 0.5909 - val_accuracy: 0.7500\n",
      "Epoch 1635/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2074 - accuracy: 0.9250 - val_loss: 0.5768 - val_accuracy: 0.8000\n",
      "Epoch 1636/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.1892 - accuracy: 0.9375 - val_loss: 0.5533 - val_accuracy: 0.8000\n",
      "Epoch 1637/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.1911 - accuracy: 0.9375 - val_loss: 0.6166 - val_accuracy: 0.8000\n",
      "Epoch 1638/2000\n",
      "80/80 [==============================] - 0s 158us/sample - loss: 0.1866 - accuracy: 0.9375 - val_loss: 0.6032 - val_accuracy: 0.8000\n",
      "Epoch 1639/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.1890 - accuracy: 0.9500 - val_loss: 0.6002 - val_accuracy: 0.8000\n",
      "Epoch 1640/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.1883 - accuracy: 0.9250 - val_loss: 0.6216 - val_accuracy: 0.8000\n",
      "Epoch 1641/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.1982 - accuracy: 0.9125 - val_loss: 0.5874 - val_accuracy: 0.8000\n",
      "Epoch 1642/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 0.1904 - accuracy: 0.9250 - val_loss: 0.6123 - val_accuracy: 0.8000\n",
      "Epoch 1643/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.1872 - accuracy: 0.9250 - val_loss: 0.5700 - val_accuracy: 0.8000\n",
      "Epoch 1644/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.1902 - accuracy: 0.9375 - val_loss: 0.5976 - val_accuracy: 0.8000\n",
      "Epoch 1645/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.1917 - accuracy: 0.9250 - val_loss: 0.6496 - val_accuracy: 0.8000\n",
      "Epoch 1646/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.1922 - accuracy: 0.9250 - val_loss: 0.6906 - val_accuracy: 0.8000\n",
      "Epoch 1647/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.1978 - accuracy: 0.9250 - val_loss: 0.6057 - val_accuracy: 0.8000\n",
      "Epoch 1648/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.1876 - accuracy: 0.9375 - val_loss: 0.5930 - val_accuracy: 0.8000\n",
      "Epoch 1649/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.1928 - accuracy: 0.9375 - val_loss: 0.6165 - val_accuracy: 0.8000\n",
      "Epoch 1650/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.1885 - accuracy: 0.9375 - val_loss: 0.6327 - val_accuracy: 0.8000\n",
      "Epoch 1651/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.1885 - accuracy: 0.9375 - val_loss: 0.6313 - val_accuracy: 0.7500\n",
      "Epoch 1652/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.1863 - accuracy: 0.9375 - val_loss: 0.6289 - val_accuracy: 0.7500\n",
      "Epoch 1653/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.1943 - accuracy: 0.9250 - val_loss: 0.5829 - val_accuracy: 0.8000\n",
      "Epoch 1654/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.1855 - accuracy: 0.9500 - val_loss: 0.5652 - val_accuracy: 0.7500\n",
      "Epoch 1655/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.1973 - accuracy: 0.9375 - val_loss: 0.6136 - val_accuracy: 0.8000\n",
      "Epoch 1656/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.1883 - accuracy: 0.9375 - val_loss: 0.7627 - val_accuracy: 0.8000\n",
      "Epoch 1657/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2140 - accuracy: 0.9375 - val_loss: 0.6369 - val_accuracy: 0.8000\n",
      "Epoch 1658/2000\n",
      "80/80 [==============================] - 0s 489us/sample - loss: 0.1837 - accuracy: 0.9500 - val_loss: 0.5993 - val_accuracy: 0.7500\n",
      "Epoch 1659/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.2131 - accuracy: 0.9250 - val_loss: 0.6294 - val_accuracy: 0.8000\n",
      "Epoch 1660/2000\n",
      "80/80 [==============================] - 0s 133us/sample - loss: 0.2070 - accuracy: 0.9250 - val_loss: 0.8262 - val_accuracy: 0.8000\n",
      "Epoch 1661/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.2250 - accuracy: 0.9250 - val_loss: 0.6582 - val_accuracy: 0.8000\n",
      "Epoch 1662/2000\n",
      "80/80 [==============================] - 0s 125us/sample - loss: 0.1947 - accuracy: 0.9250 - val_loss: 0.6103 - val_accuracy: 0.8000\n",
      "Epoch 1663/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.1900 - accuracy: 0.9375 - val_loss: 0.5839 - val_accuracy: 0.8000\n",
      "Epoch 1664/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.1959 - accuracy: 0.9250 - val_loss: 0.5670 - val_accuracy: 0.8000\n",
      "Epoch 1665/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.2420 - accuracy: 0.90 - 0s 92us/sample - loss: 0.1968 - accuracy: 0.9375 - val_loss: 0.5177 - val_accuracy: 0.8000\n",
      "Epoch 1666/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.1873 - accuracy: 0.9375 - val_loss: 0.5768 - val_accuracy: 0.8000\n",
      "Epoch 1667/2000\n",
      "80/80 [==============================] - 0s 77us/sample - loss: 0.1897 - accuracy: 0.9375 - val_loss: 0.5774 - val_accuracy: 0.7500\n",
      "Epoch 1668/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.1862 - accuracy: 0.9375 - val_loss: 0.5752 - val_accuracy: 0.8000\n",
      "Epoch 1669/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.1873 - accuracy: 0.9375 - val_loss: 0.5746 - val_accuracy: 0.8000\n",
      "Epoch 1670/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 0.1902 - accuracy: 0.9375 - val_loss: 0.5928 - val_accuracy: 0.8000\n",
      "Epoch 1671/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.1925 - accuracy: 0.9250 - val_loss: 0.6293 - val_accuracy: 0.8000\n",
      "Epoch 1672/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.1871 - accuracy: 0.9250 - val_loss: 0.5757 - val_accuracy: 0.8000\n",
      "Epoch 1673/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.1855 - accuracy: 0.9375 - val_loss: 0.5553 - val_accuracy: 0.8000\n",
      "Epoch 1674/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.1850 - accuracy: 0.9500 - val_loss: 0.5662 - val_accuracy: 0.8000\n",
      "Epoch 1675/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.1905 - accuracy: 0.9375 - val_loss: 0.5736 - val_accuracy: 0.8000\n",
      "Epoch 1676/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.1887 - accuracy: 0.9375 - val_loss: 0.5769 - val_accuracy: 0.8000\n",
      "Epoch 1677/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.1978 - accuracy: 0.9500 - val_loss: 0.5955 - val_accuracy: 0.7500\n",
      "Epoch 1678/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2009 - accuracy: 0.9250 - val_loss: 0.6508 - val_accuracy: 0.8000\n",
      "Epoch 1679/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.1900 - accuracy: 0.9250 - val_loss: 0.5949 - val_accuracy: 0.8000\n",
      "Epoch 1680/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.1914 - accuracy: 0.9500 - val_loss: 0.5657 - val_accuracy: 0.8000\n",
      "Epoch 1681/2000\n",
      "80/80 [==============================] - 0s 244us/sample - loss: 0.1895 - accuracy: 0.9250 - val_loss: 0.6033 - val_accuracy: 0.8000\n",
      "Epoch 1682/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.1916 - accuracy: 0.9375 - val_loss: 0.5514 - val_accuracy: 0.8000\n",
      "Epoch 1683/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.1886 - accuracy: 0.9500 - val_loss: 0.5791 - val_accuracy: 0.8000\n",
      "Epoch 1684/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.1851 - accuracy: 0.9500 - val_loss: 0.5806 - val_accuracy: 0.8000\n",
      "Epoch 1685/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.1879 - accuracy: 0.9375 - val_loss: 0.5998 - val_accuracy: 0.7500\n",
      "Epoch 1686/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.1924 - accuracy: 0.9250 - val_loss: 0.6418 - val_accuracy: 0.8000\n",
      "Epoch 1687/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.1895 - accuracy: 0.9375 - val_loss: 0.6895 - val_accuracy: 0.8000\n",
      "Epoch 1688/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2098 - accuracy: 0.9500 - val_loss: 0.5492 - val_accuracy: 0.8000\n",
      "Epoch 1689/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.1918 - accuracy: 0.9500 - val_loss: 0.5791 - val_accuracy: 0.7500\n",
      "Epoch 1690/2000\n",
      "80/80 [==============================] - 0s 600us/sample - loss: 0.2015 - accuracy: 0.9250 - val_loss: 0.6685 - val_accuracy: 0.8000\n",
      "Epoch 1691/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.1980 - accuracy: 0.9375 - val_loss: 0.6770 - val_accuracy: 0.8000\n",
      "Epoch 1692/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.2123 - accuracy: 0.9125 - val_loss: 0.6085 - val_accuracy: 0.8000\n",
      "Epoch 1693/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.2040 - accuracy: 0.9125 - val_loss: 0.6460 - val_accuracy: 0.8000\n",
      "Epoch 1694/2000\n",
      "80/80 [==============================] - 0s 161us/sample - loss: 0.1917 - accuracy: 0.9500 - val_loss: 0.5244 - val_accuracy: 0.8000\n",
      "Epoch 1695/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 0.2010 - accuracy: 0.9375 - val_loss: 0.5357 - val_accuracy: 0.8000\n",
      "Epoch 1696/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.1870 - accuracy: 0.9375 - val_loss: 0.6295 - val_accuracy: 0.8000\n",
      "Epoch 1697/2000\n",
      "80/80 [==============================] - 0s 131us/sample - loss: 0.1943 - accuracy: 0.9250 - val_loss: 0.6128 - val_accuracy: 0.8000\n",
      "Epoch 1698/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.2001 - accuracy: 0.9250 - val_loss: 0.5751 - val_accuracy: 0.7500\n",
      "Epoch 1699/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.2041 - accuracy: 0.9125 - val_loss: 0.6329 - val_accuracy: 0.8000\n",
      "Epoch 1700/2000\n",
      "80/80 [==============================] - 0s 126us/sample - loss: 0.1933 - accuracy: 0.9375 - val_loss: 0.5335 - val_accuracy: 0.8000\n",
      "Epoch 1701/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2131 - accuracy: 0.9250 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
      "Epoch 1702/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2040 - accuracy: 0.9125 - val_loss: 0.6655 - val_accuracy: 0.8000\n",
      "Epoch 1703/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.1951 - accuracy: 0.9250 - val_loss: 0.5416 - val_accuracy: 0.8000\n",
      "Epoch 1704/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.1967 - accuracy: 0.9500 - val_loss: 0.5476 - val_accuracy: 0.8000\n",
      "Epoch 1705/2000\n",
      "80/80 [==============================] - 0s 68us/sample - loss: 0.1966 - accuracy: 0.9375 - val_loss: 0.6203 - val_accuracy: 0.8000\n",
      "Epoch 1706/2000\n",
      "80/80 [==============================] - 0s 138us/sample - loss: 0.1882 - accuracy: 0.9375 - val_loss: 0.6045 - val_accuracy: 0.8000\n",
      "Epoch 1707/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.1816 - accuracy: 0.9500 - val_loss: 0.5587 - val_accuracy: 0.8000\n",
      "Epoch 1708/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.2063 - accuracy: 0.9250 - val_loss: 0.5792 - val_accuracy: 0.8000\n",
      "Epoch 1709/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.1789 - accuracy: 0.9625 - val_loss: 0.7823 - val_accuracy: 0.8000\n",
      "Epoch 1710/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.2247 - accuracy: 0.9500 - val_loss: 0.6484 - val_accuracy: 0.8000\n",
      "Epoch 1711/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.1797 - accuracy: 0.9375 - val_loss: 0.6615 - val_accuracy: 0.7500\n",
      "Epoch 1712/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.2371 - accuracy: 0.9250 - val_loss: 0.6329 - val_accuracy: 0.8000\n",
      "Epoch 1713/2000\n",
      "80/80 [==============================] - 0s 260us/sample - loss: 0.2019 - accuracy: 0.9250 - val_loss: 0.7186 - val_accuracy: 0.8000\n",
      "Epoch 1714/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2179 - accuracy: 0.9375 - val_loss: 0.5670 - val_accuracy: 0.7500\n",
      "Epoch 1715/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.1937 - accuracy: 0.9500 - val_loss: 0.5728 - val_accuracy: 0.8000\n",
      "Epoch 1716/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.1981 - accuracy: 0.9375 - val_loss: 0.5972 - val_accuracy: 0.8000\n",
      "Epoch 1717/2000\n",
      "80/80 [==============================] - 0s 465us/sample - loss: 0.1991 - accuracy: 0.9250 - val_loss: 0.6512 - val_accuracy: 0.7500\n",
      "Epoch 1718/2000\n",
      "80/80 [==============================] - 0s 208us/sample - loss: 0.1876 - accuracy: 0.9375 - val_loss: 0.6243 - val_accuracy: 0.8000\n",
      "Epoch 1719/2000\n",
      "80/80 [==============================] - 0s 226us/sample - loss: 0.2008 - accuracy: 0.9250 - val_loss: 0.6088 - val_accuracy: 0.8000\n",
      "Epoch 1720/2000\n",
      "80/80 [==============================] - 0s 123us/sample - loss: 0.1950 - accuracy: 0.9375 - val_loss: 0.6709 - val_accuracy: 0.8000\n",
      "Epoch 1721/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.1982 - accuracy: 0.9250 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
      "Epoch 1722/2000\n",
      "80/80 [==============================] - 0s 188us/sample - loss: 0.2215 - accuracy: 0.9375 - val_loss: 0.5361 - val_accuracy: 0.8000\n",
      "Epoch 1723/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.1829 - accuracy: 0.9500 - val_loss: 0.6979 - val_accuracy: 0.8000\n",
      "Epoch 1724/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2195 - accuracy: 0.9375 - val_loss: 0.6746 - val_accuracy: 0.8000\n",
      "Epoch 1725/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.1973 - accuracy: 0.9375 - val_loss: 0.6209 - val_accuracy: 0.7500\n",
      "Epoch 1726/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 0.1953 - accuracy: 0.9500 - val_loss: 0.5957 - val_accuracy: 0.8000\n",
      "Epoch 1727/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 0.1882 - accuracy: 0.9500 - val_loss: 0.6031 - val_accuracy: 0.8000\n",
      "Epoch 1728/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.1903 - accuracy: 0.9375 - val_loss: 0.5774 - val_accuracy: 0.8000\n",
      "Epoch 1729/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.1855 - accuracy: 0.9375 - val_loss: 0.6208 - val_accuracy: 0.8000\n",
      "Epoch 1730/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.1908 - accuracy: 0.9250 - val_loss: 0.6393 - val_accuracy: 0.8000\n",
      "Epoch 1731/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.1854 - accuracy: 0.9250 - val_loss: 0.5888 - val_accuracy: 0.8000\n",
      "Epoch 1732/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.1899 - accuracy: 0.9500 - val_loss: 0.5776 - val_accuracy: 0.8000\n",
      "Epoch 1733/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 0.1811 - accuracy: 0.9375 - val_loss: 0.6308 - val_accuracy: 0.8000\n",
      "Epoch 1734/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.1916 - accuracy: 0.9375 - val_loss: 0.5520 - val_accuracy: 0.8000\n",
      "Epoch 1735/2000\n",
      "80/80 [==============================] - 0s 71us/sample - loss: 0.1892 - accuracy: 0.9500 - val_loss: 0.5299 - val_accuracy: 0.8000\n",
      "Epoch 1736/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.1853 - accuracy: 0.9625 - val_loss: 0.6154 - val_accuracy: 0.8000\n",
      "Epoch 1737/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.1909 - accuracy: 0.9250 - val_loss: 0.6351 - val_accuracy: 0.8000\n",
      "Epoch 1738/2000\n",
      "80/80 [==============================] - 0s 60us/sample - loss: 0.1863 - accuracy: 0.9250 - val_loss: 0.5892 - val_accuracy: 0.8000\n",
      "Epoch 1739/2000\n",
      "80/80 [==============================] - 0s 190us/sample - loss: 0.1936 - accuracy: 0.9375 - val_loss: 0.5837 - val_accuracy: 0.8000\n",
      "Epoch 1740/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 0.1785 - accuracy: 0.9375 - val_loss: 0.6607 - val_accuracy: 0.8000\n",
      "Epoch 1741/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2270 - accuracy: 0.9250 - val_loss: 0.6010 - val_accuracy: 0.8000\n",
      "Epoch 1742/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 0.1924 - accuracy: 0.9125 - val_loss: 0.5681 - val_accuracy: 0.7500\n",
      "Epoch 1743/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.2252 - accuracy: 0.9125 - val_loss: 0.6222 - val_accuracy: 0.8000\n",
      "Epoch 1744/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.2187 - accuracy: 0.9125 - val_loss: 0.7773 - val_accuracy: 0.8000\n",
      "Epoch 1745/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.2023 - accuracy: 0.9250 - val_loss: 0.5777 - val_accuracy: 0.8000\n",
      "Epoch 1746/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.2029 - accuracy: 0.9500 - val_loss: 0.5478 - val_accuracy: 0.7500\n",
      "Epoch 1747/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.1945 - accuracy: 0.9500 - val_loss: 0.6207 - val_accuracy: 0.7500\n",
      "Epoch 1748/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 0.1844 - accuracy: 0.9375 - val_loss: 0.6834 - val_accuracy: 0.8000\n",
      "Epoch 1749/2000\n",
      "80/80 [==============================] - 0s 201us/sample - loss: 0.1914 - accuracy: 0.9250 - val_loss: 0.6307 - val_accuracy: 0.8000\n",
      "Epoch 1750/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.1843 - accuracy: 0.9375 - val_loss: 0.6173 - val_accuracy: 0.7500\n",
      "Epoch 1751/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.1982 - accuracy: 0.9250 - val_loss: 0.6254 - val_accuracy: 0.8000\n",
      "Epoch 1752/2000\n",
      "80/80 [==============================] - 0s 72us/sample - loss: 0.1848 - accuracy: 0.9375 - val_loss: 0.6660 - val_accuracy: 0.8000\n",
      "Epoch 1753/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.1945 - accuracy: 0.9250 - val_loss: 0.6270 - val_accuracy: 0.8000\n",
      "Epoch 1754/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 0.1886 - accuracy: 0.9250 - val_loss: 0.5694 - val_accuracy: 0.8000\n",
      "Epoch 1755/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 0.1861 - accuracy: 0.9375 - val_loss: 0.5383 - val_accuracy: 0.8000\n",
      "Epoch 1756/2000\n",
      "80/80 [==============================] - 0s 182us/sample - loss: 0.1907 - accuracy: 0.9375 - val_loss: 0.5853 - val_accuracy: 0.8000\n",
      "Epoch 1757/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.1846 - accuracy: 0.9375 - val_loss: 0.5893 - val_accuracy: 0.8000\n",
      "Epoch 1758/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1861 - accuracy: 0.9375 - val_loss: 0.5736 - val_accuracy: 0.8000\n",
      "Epoch 1759/2000\n",
      "80/80 [==============================] - 0s 75us/sample - loss: 0.1836 - accuracy: 0.9375 - val_loss: 0.5757 - val_accuracy: 0.7500\n",
      "Epoch 1760/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.1893 - accuracy: 0.9500 - val_loss: 0.5745 - val_accuracy: 0.8000\n",
      "Epoch 1761/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.1895 - accuracy: 0.9500 - val_loss: 0.5596 - val_accuracy: 0.8000\n",
      "Epoch 1762/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.1852 - accuracy: 0.9500 - val_loss: 0.5879 - val_accuracy: 0.8000\n",
      "Epoch 1763/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.1860 - accuracy: 0.9500 - val_loss: 0.5805 - val_accuracy: 0.8000\n",
      "Epoch 1764/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.1922 - accuracy: 0.9500 - val_loss: 0.5948 - val_accuracy: 0.8000\n",
      "Epoch 1765/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.1816 - accuracy: 0.9250 - val_loss: 0.6682 - val_accuracy: 0.8000\n",
      "Epoch 1766/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.1973 - accuracy: 0.9375 - val_loss: 0.5991 - val_accuracy: 0.8000\n",
      "Epoch 1767/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.1831 - accuracy: 0.9375 - val_loss: 0.5384 - val_accuracy: 0.8000\n",
      "Epoch 1768/2000\n",
      "80/80 [==============================] - 0s 198us/sample - loss: 0.1919 - accuracy: 0.9500 - val_loss: 0.5801 - val_accuracy: 0.8000\n",
      "Epoch 1769/2000\n",
      "80/80 [==============================] - 0s 394us/sample - loss: 0.1885 - accuracy: 0.9250 - val_loss: 0.6586 - val_accuracy: 0.8000\n",
      "Epoch 1770/2000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.1877 - accuracy: 0.9250 - val_loss: 0.5729 - val_accuracy: 0.8000\n",
      "Epoch 1771/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.1835 - accuracy: 0.9375 - val_loss: 0.5396 - val_accuracy: 0.8000\n",
      "Epoch 1772/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.1884 - accuracy: 0.9500 - val_loss: 0.5818 - val_accuracy: 0.8000\n",
      "Epoch 1773/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1868 - accuracy: 0.9375 - val_loss: 0.6372 - val_accuracy: 0.8000\n",
      "Epoch 1774/2000\n",
      "80/80 [==============================] - 0s 520us/sample - loss: 0.1864 - accuracy: 0.9375 - val_loss: 0.5763 - val_accuracy: 0.8000\n",
      "Epoch 1775/2000\n",
      "80/80 [==============================] - 0s 169us/sample - loss: 0.1968 - accuracy: 0.9375 - val_loss: 0.5922 - val_accuracy: 0.8000\n",
      "Epoch 1776/2000\n",
      "80/80 [==============================] - 0s 139us/sample - loss: 0.1914 - accuracy: 0.9500 - val_loss: 0.6499 - val_accuracy: 0.8000\n",
      "Epoch 1777/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1987 - accuracy: 0.9250 - val_loss: 0.5751 - val_accuracy: 0.8000\n",
      "Epoch 1778/2000\n",
      "80/80 [==============================] - 0s 278us/sample - loss: 0.1848 - accuracy: 0.9375 - val_loss: 0.5643 - val_accuracy: 0.8000\n",
      "Epoch 1779/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.1855 - accuracy: 0.9375 - val_loss: 0.5355 - val_accuracy: 0.8500\n",
      "Epoch 1780/2000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.1884 - accuracy: 0.9375 - val_loss: 0.5447 - val_accuracy: 0.8000\n",
      "Epoch 1781/2000\n",
      "80/80 [==============================] - 0s 145us/sample - loss: 0.1833 - accuracy: 0.9500 - val_loss: 0.5960 - val_accuracy: 0.8500\n",
      "Epoch 1782/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.1858 - accuracy: 0.9375 - val_loss: 0.6376 - val_accuracy: 0.8000\n",
      "Epoch 1783/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.90 - 0s 88us/sample - loss: 0.1903 - accuracy: 0.9250 - val_loss: 0.6108 - val_accuracy: 0.8000\n",
      "Epoch 1784/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.1873 - accuracy: 0.9375 - val_loss: 0.5694 - val_accuracy: 0.8000\n",
      "Epoch 1785/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.1867 - accuracy: 0.9500 - val_loss: 0.5944 - val_accuracy: 0.8000\n",
      "Epoch 1786/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.1937 - accuracy: 0.9375 - val_loss: 0.5819 - val_accuracy: 0.7500\n",
      "Epoch 1787/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.1827 - accuracy: 0.9375 - val_loss: 0.5945 - val_accuracy: 0.8000\n",
      "Epoch 1788/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.1882 - accuracy: 0.9375 - val_loss: 0.6228 - val_accuracy: 0.8000\n",
      "Epoch 1789/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.1838 - accuracy: 0.9250 - val_loss: 0.6375 - val_accuracy: 0.8000\n",
      "Epoch 1790/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.1861 - accuracy: 0.9250 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
      "Epoch 1791/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.1852 - accuracy: 0.9375 - val_loss: 0.5384 - val_accuracy: 0.8000\n",
      "Epoch 1792/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.2008 - accuracy: 0.9500 - val_loss: 0.5319 - val_accuracy: 0.8000\n",
      "Epoch 1793/2000\n",
      "80/80 [==============================] - 0s 120us/sample - loss: 0.1940 - accuracy: 0.9500 - val_loss: 0.7198 - val_accuracy: 0.8000\n",
      "Epoch 1794/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.2055 - accuracy: 0.9375 - val_loss: 0.6748 - val_accuracy: 0.7500\n",
      "Epoch 1795/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.1890 - accuracy: 0.9375 - val_loss: 0.5641 - val_accuracy: 0.8000\n",
      "Epoch 1796/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 0.1962 - accuracy: 0.9375 - val_loss: 0.5385 - val_accuracy: 0.8000\n",
      "Epoch 1797/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.1847 - accuracy: 0.9500 - val_loss: 0.5344 - val_accuracy: 0.8000\n",
      "Epoch 1798/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.1878 - accuracy: 0.9500 - val_loss: 0.6023 - val_accuracy: 0.8000\n",
      "Epoch 1799/2000\n",
      "80/80 [==============================] - 0s 269us/sample - loss: 0.1877 - accuracy: 0.9250 - val_loss: 0.6956 - val_accuracy: 0.8000\n",
      "Epoch 1800/2000\n",
      "80/80 [==============================] - 0s 109us/sample - loss: 0.1931 - accuracy: 0.9375 - val_loss: 0.6234 - val_accuracy: 0.8000\n",
      "Epoch 1801/2000\n",
      "80/80 [==============================] - 0s 136us/sample - loss: 0.1855 - accuracy: 0.9250 - val_loss: 0.5629 - val_accuracy: 0.8000\n",
      "Epoch 1802/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.1884 - accuracy: 0.9375 - val_loss: 0.5668 - val_accuracy: 0.8000\n",
      "Epoch 1803/2000\n",
      "80/80 [==============================] - 0s 224us/sample - loss: 0.1970 - accuracy: 0.9375 - val_loss: 0.5329 - val_accuracy: 0.7500\n",
      "Epoch 1804/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.1803 - accuracy: 0.9500 - val_loss: 0.6331 - val_accuracy: 0.8000\n",
      "Epoch 1805/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.1886 - accuracy: 0.9375 - val_loss: 0.6828 - val_accuracy: 0.8000\n",
      "Epoch 1806/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.1875 - accuracy: 0.9250 - val_loss: 0.6444 - val_accuracy: 0.8000\n",
      "Epoch 1807/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.1889 - accuracy: 0.9500 - val_loss: 0.5798 - val_accuracy: 0.8000\n",
      "Epoch 1808/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.1853 - accuracy: 0.9500 - val_loss: 0.5486 - val_accuracy: 0.8000\n",
      "Epoch 1809/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.1830 - accuracy: 0.9500 - val_loss: 0.5312 - val_accuracy: 0.8000\n",
      "Epoch 1810/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.1870 - accuracy: 0.9500 - val_loss: 0.5663 - val_accuracy: 0.8000\n",
      "Epoch 1811/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.1867 - accuracy: 0.9375 - val_loss: 0.6440 - val_accuracy: 0.8000\n",
      "Epoch 1812/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.1890 - accuracy: 0.9375 - val_loss: 0.6030 - val_accuracy: 0.8000\n",
      "Epoch 1813/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 0.1859 - accuracy: 0.9375 - val_loss: 0.5878 - val_accuracy: 0.8000\n",
      "Epoch 1814/2000\n",
      "80/80 [==============================] - 0s 245us/sample - loss: 0.1864 - accuracy: 0.9375 - val_loss: 0.6334 - val_accuracy: 0.8000\n",
      "Epoch 1815/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.1836 - accuracy: 0.9375 - val_loss: 0.5940 - val_accuracy: 0.8000\n",
      "Epoch 1816/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.1833 - accuracy: 0.9375 - val_loss: 0.5385 - val_accuracy: 0.8000\n",
      "Epoch 1817/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.1862 - accuracy: 0.9500 - val_loss: 0.5444 - val_accuracy: 0.8000\n",
      "Epoch 1818/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.1834 - accuracy: 0.9375 - val_loss: 0.5671 - val_accuracy: 0.7500\n",
      "Epoch 1819/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.1908 - accuracy: 0.9375 - val_loss: 0.5815 - val_accuracy: 0.8000\n",
      "Epoch 1820/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.1799 - accuracy: 0.9375 - val_loss: 0.5437 - val_accuracy: 0.8000\n",
      "Epoch 1821/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.2049 - accuracy: 0.9250 - val_loss: 0.5972 - val_accuracy: 0.8000\n",
      "Epoch 1822/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.1993 - accuracy: 0.9375 - val_loss: 0.6303 - val_accuracy: 0.7500\n",
      "Epoch 1823/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.1896 - accuracy: 0.9375 - val_loss: 0.5886 - val_accuracy: 0.7500\n",
      "Epoch 1824/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.1875 - accuracy: 0.9500 - val_loss: 0.6292 - val_accuracy: 0.7500\n",
      "Epoch 1825/2000\n",
      "80/80 [==============================] - 0s 134us/sample - loss: 0.1915 - accuracy: 0.9250 - val_loss: 0.6722 - val_accuracy: 0.8000\n",
      "Epoch 1826/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.1898 - accuracy: 0.9250 - val_loss: 0.5447 - val_accuracy: 0.8000\n",
      "Epoch 1827/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.1841 - accuracy: 0.9625 - val_loss: 0.5154 - val_accuracy: 0.8000\n",
      "Epoch 1828/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.1901 - accuracy: 0.9500 - val_loss: 0.5936 - val_accuracy: 0.7500\n",
      "Epoch 1829/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.1813 - accuracy: 0.9500 - val_loss: 0.6540 - val_accuracy: 0.8000\n",
      "Epoch 1830/2000\n",
      "80/80 [==============================] - 0s 219us/sample - loss: 0.1853 - accuracy: 0.9250 - val_loss: 0.6379 - val_accuracy: 0.8000\n",
      "Epoch 1831/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.1892 - accuracy: 0.9375 - val_loss: 0.6067 - val_accuracy: 0.8000\n",
      "Epoch 1832/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.1825 - accuracy: 0.9375 - val_loss: 0.6360 - val_accuracy: 0.8000\n",
      "Epoch 1833/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.1894 - accuracy: 0.9250 - val_loss: 0.5796 - val_accuracy: 0.8000\n",
      "Epoch 1834/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.1838 - accuracy: 0.9375 - val_loss: 0.5357 - val_accuracy: 0.8000\n",
      "Epoch 1835/2000\n",
      "80/80 [==============================] - 0s 115us/sample - loss: 0.1843 - accuracy: 0.9250 - val_loss: 0.5700 - val_accuracy: 0.8000\n",
      "Epoch 1836/2000\n",
      "80/80 [==============================] - 0s 29us/sample - loss: 0.1812 - accuracy: 0.9375 - val_loss: 0.5926 - val_accuracy: 0.8000\n",
      "Epoch 1837/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.1828 - accuracy: 0.9375 - val_loss: 0.5895 - val_accuracy: 0.8000\n",
      "Epoch 1838/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.1818 - accuracy: 0.9500 - val_loss: 0.5568 - val_accuracy: 0.8000\n",
      "Epoch 1839/2000\n",
      "80/80 [==============================] - 0s 77us/sample - loss: 0.1995 - accuracy: 0.9375 - val_loss: 0.5597 - val_accuracy: 0.8000\n",
      "Epoch 1840/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.1838 - accuracy: 0.9375 - val_loss: 0.6283 - val_accuracy: 0.8000\n",
      "Epoch 1841/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.1952 - accuracy: 0.9250 - val_loss: 0.5494 - val_accuracy: 0.8000\n",
      "Epoch 1842/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.1902 - accuracy: 0.9625 - val_loss: 0.5580 - val_accuracy: 0.8000\n",
      "Epoch 1843/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.1815 - accuracy: 0.9500 - val_loss: 0.5681 - val_accuracy: 0.8000\n",
      "Epoch 1844/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.1913 - accuracy: 0.9500 - val_loss: 0.6045 - val_accuracy: 0.8000\n",
      "Epoch 1845/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.1949 - accuracy: 0.9250 - val_loss: 0.6520 - val_accuracy: 0.8000\n",
      "Epoch 1846/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.1910 - accuracy: 0.9375 - val_loss: 0.5608 - val_accuracy: 0.8000\n",
      "Epoch 1847/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.1875 - accuracy: 0.9500 - val_loss: 0.5437 - val_accuracy: 0.8000\n",
      "Epoch 1848/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.1813 - accuracy: 0.9500 - val_loss: 0.6277 - val_accuracy: 0.8000\n",
      "Epoch 1849/2000\n",
      "80/80 [==============================] - 0s 222us/sample - loss: 0.2043 - accuracy: 0.9375 - val_loss: 0.5722 - val_accuracy: 0.8000\n",
      "Epoch 1850/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.1896 - accuracy: 0.9375 - val_loss: 0.6050 - val_accuracy: 0.7500\n",
      "Epoch 1851/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2240 - accuracy: 0.9375 - val_loss: 0.6416 - val_accuracy: 0.8000\n",
      "Epoch 1852/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.1831 - accuracy: 0.9375 - val_loss: 0.7113 - val_accuracy: 0.8000\n",
      "Epoch 1853/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.1937 - accuracy: 0.9250 - val_loss: 0.6319 - val_accuracy: 0.8000\n",
      "Epoch 1854/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2011 - accuracy: 0.9250 - val_loss: 0.5559 - val_accuracy: 0.7500\n",
      "Epoch 1855/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2088 - accuracy: 0.9375 - val_loss: 0.6337 - val_accuracy: 0.8000\n",
      "Epoch 1856/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.1895 - accuracy: 0.9375 - val_loss: 0.6349 - val_accuracy: 0.8000\n",
      "Epoch 1857/2000\n",
      "80/80 [==============================] - 0s 94us/sample - loss: 0.1859 - accuracy: 0.9375 - val_loss: 0.5799 - val_accuracy: 0.8000\n",
      "Epoch 1858/2000\n",
      "80/80 [==============================] - 0s 86us/sample - loss: 0.1828 - accuracy: 0.9500 - val_loss: 0.5826 - val_accuracy: 0.7500\n",
      "Epoch 1859/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.2092 - accuracy: 0.9250 - val_loss: 0.6026 - val_accuracy: 0.7500\n",
      "Epoch 1860/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.1887 - accuracy: 0.9375 - val_loss: 0.6419 - val_accuracy: 0.8000\n",
      "Epoch 1861/2000\n",
      "80/80 [==============================] - 0s 708us/sample - loss: 0.1877 - accuracy: 0.9250 - val_loss: 0.6726 - val_accuracy: 0.8000\n",
      "Epoch 1862/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2033 - accuracy: 0.9250 - val_loss: 0.5608 - val_accuracy: 0.8000\n",
      "Epoch 1863/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.1848 - accuracy: 0.9500 - val_loss: 0.5831 - val_accuracy: 0.8000\n",
      "Epoch 1864/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.1850 - accuracy: 0.9375 - val_loss: 0.5478 - val_accuracy: 0.8000\n",
      "Epoch 1865/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.1964 - accuracy: 0.9250 - val_loss: 0.5727 - val_accuracy: 0.7500\n",
      "Epoch 1866/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.1848 - accuracy: 0.9125 - val_loss: 0.7136 - val_accuracy: 0.8000\n",
      "Epoch 1867/2000\n",
      "80/80 [==============================] - 0s 104us/sample - loss: 0.2002 - accuracy: 0.9375 - val_loss: 0.6991 - val_accuracy: 0.8000\n",
      "Epoch 1868/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.1916 - accuracy: 0.9125 - val_loss: 0.6011 - val_accuracy: 0.8000\n",
      "Epoch 1869/2000\n",
      "80/80 [==============================] - 0s 70us/sample - loss: 0.1847 - accuracy: 0.9375 - val_loss: 0.5640 - val_accuracy: 0.8000\n",
      "Epoch 1870/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.1837 - accuracy: 0.9500 - val_loss: 0.5716 - val_accuracy: 0.8000\n",
      "Epoch 1871/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.1920 - accuracy: 0.9375 - val_loss: 0.5764 - val_accuracy: 0.8000\n",
      "Epoch 1872/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.1830 - accuracy: 0.9375 - val_loss: 0.5549 - val_accuracy: 0.8000\n",
      "Epoch 1873/2000\n",
      "80/80 [==============================] - 0s 121us/sample - loss: 0.2006 - accuracy: 0.9375 - val_loss: 0.6011 - val_accuracy: 0.7500\n",
      "Epoch 1874/2000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.1846 - accuracy: 0.9375 - val_loss: 0.6916 - val_accuracy: 0.8000\n",
      "Epoch 1875/2000\n",
      "80/80 [==============================] - 0s 34us/sample - loss: 0.2210 - accuracy: 0.9375 - val_loss: 0.7326 - val_accuracy: 0.8000\n",
      "Epoch 1876/2000\n",
      "80/80 [==============================] - 0s 186us/sample - loss: 0.2082 - accuracy: 0.9250 - val_loss: 0.5685 - val_accuracy: 0.8000\n",
      "Epoch 1877/2000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.1985 - accuracy: 0.9250 - val_loss: 0.6113 - val_accuracy: 0.8500\n",
      "Epoch 1878/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.2096 - accuracy: 0.9375 - val_loss: 0.8155 - val_accuracy: 0.8000\n",
      "Epoch 1879/2000\n",
      "80/80 [==============================] - 0s 103us/sample - loss: 0.2006 - accuracy: 0.9500 - val_loss: 0.6628 - val_accuracy: 0.7500\n",
      "Epoch 1880/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.2384 - accuracy: 0.9125 - val_loss: 0.6216 - val_accuracy: 0.7500\n",
      "Epoch 1881/2000\n",
      "80/80 [==============================] - 0s 88us/sample - loss: 0.1947 - accuracy: 0.9250 - val_loss: 0.7187 - val_accuracy: 0.8000\n",
      "Epoch 1882/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.2476 - accuracy: 0.9250 - val_loss: 0.7426 - val_accuracy: 0.8000\n",
      "Epoch 1883/2000\n",
      "80/80 [==============================] - 0s 81us/sample - loss: 0.1833 - accuracy: 0.9500 - val_loss: 0.6611 - val_accuracy: 0.7500\n",
      "Epoch 1884/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2503 - accuracy: 0.9375 - val_loss: 0.6999 - val_accuracy: 0.7500\n",
      "Epoch 1885/2000\n",
      "80/80 [==============================] - 0s 419us/sample - loss: 0.2333 - accuracy: 0.8875 - val_loss: 0.7471 - val_accuracy: 0.8000\n",
      "Epoch 1886/2000\n",
      "80/80 [==============================] - 0s 151us/sample - loss: 0.1982 - accuracy: 0.9375 - val_loss: 0.6127 - val_accuracy: 0.8000\n",
      "Epoch 1887/2000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.1834 - accuracy: 0.9500 - val_loss: 0.5341 - val_accuracy: 0.8000\n",
      "Epoch 1888/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.1872 - accuracy: 0.9500 - val_loss: 0.5757 - val_accuracy: 0.8000\n",
      "Epoch 1889/2000\n",
      "80/80 [==============================] - 0s 20us/sample - loss: 0.1937 - accuracy: 0.9375 - val_loss: 0.6012 - val_accuracy: 0.8000\n",
      "Epoch 1890/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.1917 - accuracy: 0.9250 - val_loss: 0.6159 - val_accuracy: 0.8000\n",
      "Epoch 1891/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.1816 - accuracy: 0.9375 - val_loss: 0.6635 - val_accuracy: 0.8000\n",
      "Epoch 1892/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.1847 - accuracy: 0.9250 - val_loss: 0.6368 - val_accuracy: 0.8000\n",
      "Epoch 1893/2000\n",
      "80/80 [==============================] - 0s 97us/sample - loss: 0.1905 - accuracy: 0.9375 - val_loss: 0.5485 - val_accuracy: 0.8000\n",
      "Epoch 1894/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.1853 - accuracy: 0.9500 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
      "Epoch 1895/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.1951 - accuracy: 0.9500 - val_loss: 0.6126 - val_accuracy: 0.8000\n",
      "Epoch 1896/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.1818 - accuracy: 0.9500 - val_loss: 0.6035 - val_accuracy: 0.8000\n",
      "Epoch 1897/2000\n",
      "80/80 [==============================] - 0s 74us/sample - loss: 0.1821 - accuracy: 0.9375 - val_loss: 0.5839 - val_accuracy: 0.8000\n",
      "Epoch 1898/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.1827 - accuracy: 0.9500 - val_loss: 0.5435 - val_accuracy: 0.8000\n",
      "Epoch 1899/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 0.1836 - accuracy: 0.9500 - val_loss: 0.6058 - val_accuracy: 0.8000\n",
      "Epoch 1900/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.1872 - accuracy: 0.9250 - val_loss: 0.6514 - val_accuracy: 0.8000\n",
      "Epoch 1901/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 0.1846 - accuracy: 0.9375 - val_loss: 0.5835 - val_accuracy: 0.8000\n",
      "Epoch 1902/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.1827 - accuracy: 0.9625 - val_loss: 0.5621 - val_accuracy: 0.7500\n",
      "Epoch 1903/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.1830 - accuracy: 0.9500 - val_loss: 0.5976 - val_accuracy: 0.7500\n",
      "Epoch 1904/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.1814 - accuracy: 0.9375 - val_loss: 0.5657 - val_accuracy: 0.8000\n",
      "Epoch 1905/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.1951 - accuracy: 0.9375 - val_loss: 0.5681 - val_accuracy: 0.7500\n",
      "Epoch 1906/2000\n",
      "80/80 [==============================] - 0s 117us/sample - loss: 0.1924 - accuracy: 0.9500 - val_loss: 0.6393 - val_accuracy: 0.8000\n",
      "Epoch 1907/2000\n",
      "80/80 [==============================] - 0s 129us/sample - loss: 0.1847 - accuracy: 0.9250 - val_loss: 0.6290 - val_accuracy: 0.8500\n",
      "Epoch 1908/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.1828 - accuracy: 0.9375 - val_loss: 0.5780 - val_accuracy: 0.8000\n",
      "Epoch 1909/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.1849 - accuracy: 0.9500 - val_loss: 0.5834 - val_accuracy: 0.8000\n",
      "Epoch 1910/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.1804 - accuracy: 0.9375 - val_loss: 0.5931 - val_accuracy: 0.8000\n",
      "Epoch 1911/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.1868 - accuracy: 0.9375 - val_loss: 0.5733 - val_accuracy: 0.8000\n",
      "Epoch 1912/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.1791 - accuracy: 0.9375 - val_loss: 0.6327 - val_accuracy: 0.8000\n",
      "Epoch 1913/2000\n",
      "80/80 [==============================] - 0s 91us/sample - loss: 0.1868 - accuracy: 0.9250 - val_loss: 0.5835 - val_accuracy: 0.8000\n",
      "Epoch 1914/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 0.1804 - accuracy: 0.9500 - val_loss: 0.5271 - val_accuracy: 0.8000\n",
      "Epoch 1915/2000\n",
      "80/80 [==============================] - 0s 78us/sample - loss: 0.1888 - accuracy: 0.9500 - val_loss: 0.5492 - val_accuracy: 0.8000\n",
      "Epoch 1916/2000\n",
      "80/80 [==============================] - 0s 346us/sample - loss: 0.1794 - accuracy: 0.9500 - val_loss: 0.5971 - val_accuracy: 0.8000\n",
      "Epoch 1917/2000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.1842 - accuracy: 0.9500 - val_loss: 0.6209 - val_accuracy: 0.8000\n",
      "Epoch 1918/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.1797 - accuracy: 0.9375 - val_loss: 0.5826 - val_accuracy: 0.7500\n",
      "Epoch 1919/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.1913 - accuracy: 0.9375 - val_loss: 0.6013 - val_accuracy: 0.8000\n",
      "Epoch 1920/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2038 - accuracy: 0.9125 - val_loss: 0.5856 - val_accuracy: 0.8000\n",
      "Epoch 1921/2000\n",
      "80/80 [==============================] - 0s 101us/sample - loss: 0.1799 - accuracy: 0.9625 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
      "Epoch 1922/2000\n",
      "80/80 [==============================] - 0s 118us/sample - loss: 0.1880 - accuracy: 0.9500 - val_loss: 0.6121 - val_accuracy: 0.7500\n",
      "Epoch 1923/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.1865 - accuracy: 0.9375 - val_loss: 0.6750 - val_accuracy: 0.8000\n",
      "Epoch 1924/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.1858 - accuracy: 0.9250 - val_loss: 0.5500 - val_accuracy: 0.8000\n",
      "Epoch 1925/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.1942 - accuracy: 0.9500 - val_loss: 0.5473 - val_accuracy: 0.8000\n",
      "Epoch 1926/2000\n",
      "80/80 [==============================] - 0s 111us/sample - loss: 0.1963 - accuracy: 0.9500 - val_loss: 0.6819 - val_accuracy: 0.8000\n",
      "Epoch 1927/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.1921 - accuracy: 0.9250 - val_loss: 0.6574 - val_accuracy: 0.7500\n",
      "Epoch 1928/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.1944 - accuracy: 0.9375 - val_loss: 0.6764 - val_accuracy: 0.7500\n",
      "Epoch 1929/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 0.1824 - accuracy: 0.9375 - val_loss: 0.6472 - val_accuracy: 0.8000\n",
      "Epoch 1930/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.1911 - accuracy: 0.9375 - val_loss: 0.6079 - val_accuracy: 0.8000\n",
      "Epoch 1931/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.1851 - accuracy: 0.9375 - val_loss: 0.5111 - val_accuracy: 0.8000\n",
      "Epoch 1932/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.2095 - accuracy: 0.9375 - val_loss: 0.5730 - val_accuracy: 0.8000\n",
      "Epoch 1933/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.1735 - accuracy: 0.9500 - val_loss: 0.7415 - val_accuracy: 0.8000\n",
      "Epoch 1934/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.2096 - accuracy: 0.9375 - val_loss: 0.6570 - val_accuracy: 0.8000\n",
      "Epoch 1935/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.1727 - accuracy: 0.9250 - val_loss: 0.6661 - val_accuracy: 0.7500\n",
      "Epoch 1936/2000\n",
      "80/80 [==============================] - 0s 106us/sample - loss: 0.2639 - accuracy: 0.9250 - val_loss: 0.6896 - val_accuracy: 0.7500\n",
      "Epoch 1937/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.1830 - accuracy: 0.9500 - val_loss: 0.9616 - val_accuracy: 0.7000\n",
      "Epoch 1938/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2573 - accuracy: 0.9250 - val_loss: 0.6533 - val_accuracy: 0.7500\n",
      "Epoch 1939/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.1820 - accuracy: 0.9625 - val_loss: 0.5946 - val_accuracy: 0.7500\n",
      "Epoch 1940/2000\n",
      "80/80 [==============================] - 0s 80us/sample - loss: 0.1901 - accuracy: 0.9375 - val_loss: 0.6061 - val_accuracy: 0.8000\n",
      "Epoch 1941/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.1873 - accuracy: 0.9375 - val_loss: 0.6482 - val_accuracy: 0.8000\n",
      "Epoch 1942/2000\n",
      "80/80 [==============================] - 0s 518us/sample - loss: 0.1794 - accuracy: 0.9375 - val_loss: 0.5958 - val_accuracy: 0.7500\n",
      "Epoch 1943/2000\n",
      "80/80 [==============================] - 0s 132us/sample - loss: 0.1961 - accuracy: 0.9250 - val_loss: 0.5909 - val_accuracy: 0.7500\n",
      "Epoch 1944/2000\n",
      "80/80 [==============================] - 0s 119us/sample - loss: 0.1920 - accuracy: 0.9375 - val_loss: 0.6022 - val_accuracy: 0.8000\n",
      "Epoch 1945/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.1812 - accuracy: 0.9375 - val_loss: 0.6197 - val_accuracy: 0.8000\n",
      "Epoch 1946/2000\n",
      "80/80 [==============================] - 0s 150us/sample - loss: 0.1811 - accuracy: 0.9375 - val_loss: 0.6103 - val_accuracy: 0.8000\n",
      "Epoch 1947/2000\n",
      "80/80 [==============================] - 0s 113us/sample - loss: 0.1932 - accuracy: 0.9375 - val_loss: 0.5309 - val_accuracy: 0.8500\n",
      "Epoch 1948/2000\n",
      "80/80 [==============================] - 0s 95us/sample - loss: 0.1879 - accuracy: 0.9500 - val_loss: 0.5568 - val_accuracy: 0.8000\n",
      "Epoch 1949/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.1887 - accuracy: 0.9375 - val_loss: 0.4900 - val_accuracy: 0.8000\n",
      "Epoch 1950/2000\n",
      "80/80 [==============================] - 0s 98us/sample - loss: 0.1970 - accuracy: 0.9500 - val_loss: 0.5733 - val_accuracy: 0.7500\n",
      "Epoch 1951/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.1892 - accuracy: 0.9500 - val_loss: 0.8264 - val_accuracy: 0.8000\n",
      "Epoch 1952/2000\n",
      "80/80 [==============================] - 0s 92us/sample - loss: 0.2191 - accuracy: 0.9375 - val_loss: 0.8834 - val_accuracy: 0.8000\n",
      "Epoch 1953/2000\n",
      "80/80 [==============================] - 0s 99us/sample - loss: 0.1989 - accuracy: 0.9375 - val_loss: 0.7053 - val_accuracy: 0.7500\n",
      "Epoch 1954/2000\n",
      "80/80 [==============================] - 0s 105us/sample - loss: 0.2210 - accuracy: 0.9125 - val_loss: 0.5800 - val_accuracy: 0.7500\n",
      "Epoch 1955/2000\n",
      "80/80 [==============================] - 0s 87us/sample - loss: 0.1970 - accuracy: 0.9250 - val_loss: 0.6120 - val_accuracy: 0.8000\n",
      "Epoch 1956/2000\n",
      "80/80 [==============================] - 0s 137us/sample - loss: 0.2050 - accuracy: 0.9500 - val_loss: 0.5239 - val_accuracy: 0.8000\n",
      "Epoch 1957/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2080 - accuracy: 0.9500 - val_loss: 0.5220 - val_accuracy: 0.8000\n",
      "Epoch 1958/2000\n",
      "80/80 [==============================] - 0s 127us/sample - loss: 0.1852 - accuracy: 0.9625 - val_loss: 0.6676 - val_accuracy: 0.8000\n",
      "Epoch 1959/2000\n",
      "80/80 [==============================] - 0s 110us/sample - loss: 0.2207 - accuracy: 0.9250 - val_loss: 0.6589 - val_accuracy: 0.8000\n",
      "Epoch 1960/2000\n",
      "80/80 [==============================] - 0s 90us/sample - loss: 0.2045 - accuracy: 0.9125 - val_loss: 0.6339 - val_accuracy: 0.7500\n",
      "Epoch 1961/2000\n",
      "80/80 [==============================] - 0s 102us/sample - loss: 0.2083 - accuracy: 0.9250 - val_loss: 0.6467 - val_accuracy: 0.7500\n",
      "Epoch 1962/2000\n",
      "80/80 [==============================] - 0s 79us/sample - loss: 0.1895 - accuracy: 0.9375 - val_loss: 0.7442 - val_accuracy: 0.8000\n",
      "Epoch 1963/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.1907 - accuracy: 0.9375 - val_loss: 0.6288 - val_accuracy: 0.8000\n",
      "Epoch 1964/2000\n",
      "80/80 [==============================] - 0s 116us/sample - loss: 0.1876 - accuracy: 0.9375 - val_loss: 0.6375 - val_accuracy: 0.7500\n",
      "Epoch 1965/2000\n",
      "80/80 [==============================] - 0s 114us/sample - loss: 0.2056 - accuracy: 0.9375 - val_loss: 0.6518 - val_accuracy: 0.8000\n",
      "Epoch 1966/2000\n",
      "80/80 [==============================] - 0s 84us/sample - loss: 0.1904 - accuracy: 0.9500 - val_loss: 0.6594 - val_accuracy: 0.8000\n",
      "Epoch 1967/2000\n",
      "80/80 [==============================] - 0s 108us/sample - loss: 0.1810 - accuracy: 0.9375 - val_loss: 0.6112 - val_accuracy: 0.7500\n",
      "Epoch 1968/2000\n",
      "80/80 [==============================] - 0s 76us/sample - loss: 0.2024 - accuracy: 0.9250 - val_loss: 0.6102 - val_accuracy: 0.8000\n",
      "Epoch 1969/2000\n",
      "80/80 [==============================] - 0s 93us/sample - loss: 0.1852 - accuracy: 0.9375 - val_loss: 0.6431 - val_accuracy: 0.8000\n",
      "Epoch 1970/2000\n",
      "80/80 [==============================] - 0s 122us/sample - loss: 0.1847 - accuracy: 0.9250 - val_loss: 0.5183 - val_accuracy: 0.8000\n",
      "Epoch 1971/2000\n",
      "80/80 [==============================] - 0s 74us/sample - loss: 0.1843 - accuracy: 0.9625 - val_loss: 0.5314 - val_accuracy: 0.7500\n",
      "Epoch 1972/2000\n",
      "80/80 [==============================] - 0s 142us/sample - loss: 0.1887 - accuracy: 0.9500 - val_loss: 0.6099 - val_accuracy: 0.8000\n",
      "Epoch 1973/2000\n",
      "80/80 [==============================] - 0s 475us/sample - loss: 0.1811 - accuracy: 0.9250 - val_loss: 0.6811 - val_accuracy: 0.8000\n",
      "Epoch 1974/2000\n",
      "80/80 [==============================] - 0s 293us/sample - loss: 0.1887 - accuracy: 0.9250 - val_loss: 0.6489 - val_accuracy: 0.8000\n",
      "Epoch 1975/2000\n",
      "80/80 [==============================] - 0s 69us/sample - loss: 0.1806 - accuracy: 0.9375 - val_loss: 0.5855 - val_accuracy: 0.8000\n",
      "Epoch 1976/2000\n",
      "80/80 [==============================] - 0s 156us/sample - loss: 0.1790 - accuracy: 0.9375 - val_loss: 0.5281 - val_accuracy: 0.8000\n",
      "Epoch 1977/2000\n",
      "80/80 [==============================] - 0s 83us/sample - loss: 0.1827 - accuracy: 0.9500 - val_loss: 0.5243 - val_accuracy: 0.8000\n",
      "Epoch 1978/2000\n",
      "80/80 [==============================] - 0s 37us/sample - loss: 0.1858 - accuracy: 0.9500 - val_loss: 0.5641 - val_accuracy: 0.8000\n",
      "Epoch 1979/2000\n",
      "80/80 [==============================] - 0s 163us/sample - loss: 0.1837 - accuracy: 0.9500 - val_loss: 0.5616 - val_accuracy: 0.8000\n",
      "Epoch 1980/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 0.1889 - accuracy: 0.9500 - val_loss: 0.5947 - val_accuracy: 0.7500\n",
      "Epoch 1981/2000\n",
      "80/80 [==============================] - 0s 253us/sample - loss: 0.1825 - accuracy: 0.9500 - val_loss: 0.6637 - val_accuracy: 0.8000\n",
      "Epoch 1982/2000\n",
      "80/80 [==============================] - 0s 0s/sample - loss: 0.2101 - accuracy: 0.9375 - val_loss: 0.6847 - val_accuracy: 0.8000\n",
      "Epoch 1983/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.1874 - accuracy: 0.9375 - val_loss: 0.5529 - val_accuracy: 0.7500\n",
      "Epoch 1984/2000\n",
      "80/80 [==============================] - 0s 82us/sample - loss: 0.2060 - accuracy: 0.9125 - val_loss: 0.6046 - val_accuracy: 0.7500\n",
      "Epoch 1985/2000\n",
      "80/80 [==============================] - 0s 96us/sample - loss: 0.1820 - accuracy: 0.9250 - val_loss: 0.8703 - val_accuracy: 0.8000\n",
      "Epoch 1986/2000\n",
      "80/80 [==============================] - 0s 144us/sample - loss: 0.2196 - accuracy: 0.9250 - val_loss: 0.7743 - val_accuracy: 0.8000\n",
      "Epoch 1987/2000\n",
      "80/80 [==============================] - 0s 85us/sample - loss: 0.2137 - accuracy: 0.8875 - val_loss: 0.6661 - val_accuracy: 0.7500\n",
      "Epoch 1988/2000\n",
      "80/80 [==============================] - 0s 89us/sample - loss: 0.1878 - accuracy: 0.9250 - val_loss: 0.6020 - val_accuracy: 0.8000\n",
      "Epoch 1989/2000\n",
      "80/80 [==============================] - 0s 112us/sample - loss: 0.1832 - accuracy: 0.9375 - val_loss: 0.5801 - val_accuracy: 0.8000\n",
      "Epoch 1990/2000\n",
      "80/80 [==============================] - 0s 100us/sample - loss: 0.1948 - accuracy: 0.9375 - val_loss: 0.4953 - val_accuracy: 0.8000\n",
      "Epoch 1991/2000\n",
      "80/80 [==============================] - 0s 45us/sample - loss: 0.1859 - accuracy: 0.9500 - val_loss: 0.5487 - val_accuracy: 0.8000\n",
      "Epoch 1992/2000\n",
      "80/80 [==============================] - 0s 208us/sample - loss: 0.1836 - accuracy: 0.9500 - val_loss: 0.6175 - val_accuracy: 0.8000\n",
      "Epoch 1993/2000\n",
      "80/80 [==============================] - 0s 197us/sample - loss: 0.1801 - accuracy: 0.9500 - val_loss: 0.6021 - val_accuracy: 0.8000\n",
      "Epoch 1994/2000\n",
      "80/80 [==============================] - 0s 170us/sample - loss: 0.1832 - accuracy: 0.9500 - val_loss: 0.5653 - val_accuracy: 0.8000\n",
      "Epoch 1995/2000\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1527 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1770 - accuracy: 0.9500 - val_loss: 0.6220 - val_accuracy: 0.8000\n",
      "Epoch 1996/2000\n",
      "80/80 [==============================] - 0s 143us/sample - loss: 0.1861 - accuracy: 0.9375 - val_loss: 0.6296 - val_accuracy: 0.8000\n",
      "Epoch 1997/2000\n",
      "80/80 [==============================] - 0s 128us/sample - loss: 0.1865 - accuracy: 0.9375 - val_loss: 0.5833 - val_accuracy: 0.8500\n",
      "Epoch 1998/2000\n",
      "80/80 [==============================] - 0s 124us/sample - loss: 0.1850 - accuracy: 0.9375 - val_loss: 0.5923 - val_accuracy: 0.8000\n",
      "Epoch 1999/2000\n",
      "80/80 [==============================] - 0s 107us/sample - loss: 0.1798 - accuracy: 0.9250 - val_loss: 0.6331 - val_accuracy: 0.8000\n",
      "Epoch 2000/2000\n",
      "80/80 [==============================] - 0s 146us/sample - loss: 0.1885 - accuracy: 0.9375 - val_loss: 0.5879 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy',optimizer=adam, metrics=['accuracy'])\n",
    "history2 = model2.fit(X, y, epochs=2000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x232ff6ae208>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
